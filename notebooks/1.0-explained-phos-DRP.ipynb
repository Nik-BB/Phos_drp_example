{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Response Prediction (DRP) using phosphoproteomics data\n",
    "\n",
    "## Problem Formulation \n",
    "\n",
    "The goal of DRP is to predict how effective different drugs are for different cancer types. \n",
    "Here we predict the I50 values, the concentration of a drug needed to inhibit the activity of a cell lie by 50%, as a measure of efficacy. \n",
    "We feed phosphoproteomics profiles of cell lines and simple column representaions of drugs though a neural network to do this. \n",
    "\n",
    "Consider the traning set $T = \\{ \\boldsymbol{x_{c,i}}, \\boldsymbol{x_{d,i}}, y_i\\}$ where \n",
    "$\\boldsymbol{x_{c,i}}$, $\\boldsymbol{x_{d,i}}$  are representation of the $i^{th}$ cell line and drug respectively and\n",
    " $y_i$ is the IC50 value associated with the $i^{th}$ cell line drug pair.\n",
    "\n",
    " Thus, we want to find a model, $M$, that takes $\\boldsymbol{x_{c,i}}$ and $\\boldsymbol{x_{d,i}}$ as inputs and predicts for the corresponding IC50 value $\\hat{y_i}$ such that $M(\\boldsymbol{x_{c,i}}, \\boldsymbol{x_{d,i}})=\\hat{y_i}$.\n",
    "\n",
    "We test the model on what is known as cell blind testing. This means that none of the cell lines in the testing set are in the training set. Cell blind testing simulates how a model would perform in a stratified medicine context. Where previous patents' responses to a set of drugs would be available for training and the goal would be to predict the response of a new patent to these drugs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('..')\n",
    "from src import create_dataset, utils, models, traning, eval_model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils' from 'c:\\\\Users\\\\Nik\\\\Documents\\\\PhD_code\\\\year2_code\\\\Phos_drp_example\\\\notebooks\\\\..\\\\src\\\\utils.py'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(models)\n",
    "reload(utils)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing \n",
    "\n",
    "Here we load in our input and truth value data. \n",
    "\n",
    "The input omics data is phosphoproteomics profiles of cancer cell lines. \n",
    "\n",
    "The input drug data is marker drug representations, these are unique one-hot encoded column vectors that do not contain any chemical properties.\n",
    "\n",
    "The  truth values describes how effective different drugs are at killing cell lines. Here we are using IC50 values for this.\n",
    "\n",
    "The IC50 values are from the GDSC1 database https://www.cancerrxgene.org/\n",
    "\n",
    "The omics data is from the  paper Drug ranking using machine learning systematically predicts the efficacy of anti-cancer drugs https://www.nature.com/articles/s41467-021-22170-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_dataset.DrpInputData(omic_types=['phos'])\n",
    "#Keps only cell lines that have truth value and omics profiles\n",
    "data.remove_disjoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col.name</th>\n",
       "      <th>KDM1A(S45);</th>\n",
       "      <th>KDM1A(T19);</th>\n",
       "      <th>ZFP91(S69);</th>\n",
       "      <th>INCENP(T150);</th>\n",
       "      <th>INCENP(T153);</th>\n",
       "      <th>INCENP(T153);INCENP(T135);</th>\n",
       "      <th>INCENP(M136);INCENP(T145);INCENP(S148);</th>\n",
       "      <th>EIF3J(S11);EIF3J(S13);</th>\n",
       "      <th>POLE4(S9);</th>\n",
       "      <th>SAMD1(T157);</th>\n",
       "      <th>...</th>\n",
       "      <th>CTDP1(T340);</th>\n",
       "      <th>EPS8L2(T572);</th>\n",
       "      <th>BEGAIN(S455);</th>\n",
       "      <th>HNRNPL(S52);</th>\n",
       "      <th>GMDS(T327);</th>\n",
       "      <th>BOD1L1(S482);BOD1L1(S484);</th>\n",
       "      <th>ARHGEF35(T193);</th>\n",
       "      <th>ARHGEF5(S184);</th>\n",
       "      <th>PSMB2(T148);</th>\n",
       "      <th>HSP90AA1(S476);</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CMK</th>\n",
       "      <td>-9.751659</td>\n",
       "      <td>-9.751659</td>\n",
       "      <td>6.298313</td>\n",
       "      <td>3.897353</td>\n",
       "      <td>6.801432</td>\n",
       "      <td>6.270551</td>\n",
       "      <td>0.925999</td>\n",
       "      <td>2.077243</td>\n",
       "      <td>-9.751659</td>\n",
       "      <td>8.603255</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.751659</td>\n",
       "      <td>-8.751659</td>\n",
       "      <td>4.683472</td>\n",
       "      <td>4.285402</td>\n",
       "      <td>-9.751659</td>\n",
       "      <td>-0.388355</td>\n",
       "      <td>-9.751659</td>\n",
       "      <td>-9.751659</td>\n",
       "      <td>0.575312</td>\n",
       "      <td>1.627607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLO-680N</th>\n",
       "      <td>-9.158429</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>4.479295</td>\n",
       "      <td>5.005041</td>\n",
       "      <td>6.620465</td>\n",
       "      <td>5.830401</td>\n",
       "      <td>0.765535</td>\n",
       "      <td>0.487229</td>\n",
       "      <td>-0.349235</td>\n",
       "      <td>7.013462</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>7.549977</td>\n",
       "      <td>5.488547</td>\n",
       "      <td>4.649615</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>1.263034</td>\n",
       "      <td>-2.403542</td>\n",
       "      <td>3.378512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GDM-1</th>\n",
       "      <td>-9.522178</td>\n",
       "      <td>-9.522178</td>\n",
       "      <td>2.807355</td>\n",
       "      <td>4.263786</td>\n",
       "      <td>6.313452</td>\n",
       "      <td>5.388925</td>\n",
       "      <td>0.356144</td>\n",
       "      <td>1.062812</td>\n",
       "      <td>3.184280</td>\n",
       "      <td>8.247928</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.522178</td>\n",
       "      <td>-8.522178</td>\n",
       "      <td>7.215484</td>\n",
       "      <td>4.935460</td>\n",
       "      <td>-0.954557</td>\n",
       "      <td>-0.948976</td>\n",
       "      <td>-9.522178</td>\n",
       "      <td>-9.522178</td>\n",
       "      <td>1.952334</td>\n",
       "      <td>3.320485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEL</th>\n",
       "      <td>-11.117787</td>\n",
       "      <td>0.641546</td>\n",
       "      <td>3.539779</td>\n",
       "      <td>3.805292</td>\n",
       "      <td>6.411765</td>\n",
       "      <td>5.724105</td>\n",
       "      <td>-11.117787</td>\n",
       "      <td>1.891419</td>\n",
       "      <td>-11.117787</td>\n",
       "      <td>8.733354</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.117787</td>\n",
       "      <td>0.333939</td>\n",
       "      <td>3.135535</td>\n",
       "      <td>4.209453</td>\n",
       "      <td>-1.577767</td>\n",
       "      <td>-11.117787</td>\n",
       "      <td>-11.117787</td>\n",
       "      <td>-11.117787</td>\n",
       "      <td>0.389567</td>\n",
       "      <td>3.279471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HL-60</th>\n",
       "      <td>-11.200250</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>5.420314</td>\n",
       "      <td>3.594549</td>\n",
       "      <td>4.385697</td>\n",
       "      <td>4.070426</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>4.852998</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>5.044394</td>\n",
       "      <td>...</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>-10.200250</td>\n",
       "      <td>7.209458</td>\n",
       "      <td>4.678072</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>-2.011588</td>\n",
       "      <td>2.536053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JHH-2</th>\n",
       "      <td>-10.000831</td>\n",
       "      <td>-10.000831</td>\n",
       "      <td>2.356419</td>\n",
       "      <td>2.653284</td>\n",
       "      <td>4.659352</td>\n",
       "      <td>3.273661</td>\n",
       "      <td>-10.000831</td>\n",
       "      <td>-9.000831</td>\n",
       "      <td>-10.000831</td>\n",
       "      <td>6.195348</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.000831</td>\n",
       "      <td>7.845490</td>\n",
       "      <td>5.852249</td>\n",
       "      <td>2.985500</td>\n",
       "      <td>4.270529</td>\n",
       "      <td>-10.000831</td>\n",
       "      <td>4.153805</td>\n",
       "      <td>3.292782</td>\n",
       "      <td>-10.000831</td>\n",
       "      <td>2.545968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JHH-4</th>\n",
       "      <td>1.790772</td>\n",
       "      <td>-9.532825</td>\n",
       "      <td>4.705917</td>\n",
       "      <td>4.863014</td>\n",
       "      <td>6.920043</td>\n",
       "      <td>6.361926</td>\n",
       "      <td>1.773996</td>\n",
       "      <td>0.743300</td>\n",
       "      <td>-9.532825</td>\n",
       "      <td>6.137504</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.532825</td>\n",
       "      <td>5.529509</td>\n",
       "      <td>6.375853</td>\n",
       "      <td>3.877744</td>\n",
       "      <td>1.713696</td>\n",
       "      <td>-9.532825</td>\n",
       "      <td>2.839960</td>\n",
       "      <td>0.773996</td>\n",
       "      <td>-9.532825</td>\n",
       "      <td>3.336283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KASUMI-1</th>\n",
       "      <td>-10.480357</td>\n",
       "      <td>-10.480357</td>\n",
       "      <td>5.850999</td>\n",
       "      <td>3.267641</td>\n",
       "      <td>5.040923</td>\n",
       "      <td>4.307480</td>\n",
       "      <td>-10.480357</td>\n",
       "      <td>1.989139</td>\n",
       "      <td>-10.480357</td>\n",
       "      <td>8.485829</td>\n",
       "      <td>...</td>\n",
       "      <td>2.427606</td>\n",
       "      <td>1.914832</td>\n",
       "      <td>-1.416192</td>\n",
       "      <td>2.998196</td>\n",
       "      <td>-10.480357</td>\n",
       "      <td>2.292782</td>\n",
       "      <td>-10.480357</td>\n",
       "      <td>-10.480357</td>\n",
       "      <td>-10.480357</td>\n",
       "      <td>-10.480357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KG-1</th>\n",
       "      <td>-10.582840</td>\n",
       "      <td>-10.582840</td>\n",
       "      <td>6.659542</td>\n",
       "      <td>1.531395</td>\n",
       "      <td>4.475776</td>\n",
       "      <td>3.744231</td>\n",
       "      <td>-10.582840</td>\n",
       "      <td>2.742006</td>\n",
       "      <td>-10.582840</td>\n",
       "      <td>7.156842</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.582840</td>\n",
       "      <td>-1.130833</td>\n",
       "      <td>6.456160</td>\n",
       "      <td>3.523562</td>\n",
       "      <td>4.201634</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>-10.582840</td>\n",
       "      <td>-10.582840</td>\n",
       "      <td>2.223423</td>\n",
       "      <td>2.223423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMOE-2</th>\n",
       "      <td>4.572890</td>\n",
       "      <td>1.778209</td>\n",
       "      <td>5.472455</td>\n",
       "      <td>3.517276</td>\n",
       "      <td>5.602310</td>\n",
       "      <td>4.672462</td>\n",
       "      <td>-10.602894</td>\n",
       "      <td>3.121015</td>\n",
       "      <td>0.871844</td>\n",
       "      <td>7.660353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887525</td>\n",
       "      <td>1.541338</td>\n",
       "      <td>4.222650</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>-10.602894</td>\n",
       "      <td>-10.602894</td>\n",
       "      <td>-10.602894</td>\n",
       "      <td>-10.602894</td>\n",
       "      <td>-10.602894</td>\n",
       "      <td>2.639232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-140</th>\n",
       "      <td>4.560715</td>\n",
       "      <td>1.839960</td>\n",
       "      <td>5.220330</td>\n",
       "      <td>4.603009</td>\n",
       "      <td>6.483205</td>\n",
       "      <td>5.776159</td>\n",
       "      <td>0.815575</td>\n",
       "      <td>0.944109</td>\n",
       "      <td>-8.895395</td>\n",
       "      <td>7.277055</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.895395</td>\n",
       "      <td>-7.895395</td>\n",
       "      <td>7.338959</td>\n",
       "      <td>4.185867</td>\n",
       "      <td>2.025029</td>\n",
       "      <td>-8.895395</td>\n",
       "      <td>-8.895395</td>\n",
       "      <td>-8.895395</td>\n",
       "      <td>-8.895395</td>\n",
       "      <td>4.542258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-150</th>\n",
       "      <td>-0.187707</td>\n",
       "      <td>-9.305860</td>\n",
       "      <td>5.343464</td>\n",
       "      <td>4.842727</td>\n",
       "      <td>6.554896</td>\n",
       "      <td>5.790772</td>\n",
       "      <td>1.480265</td>\n",
       "      <td>1.064593</td>\n",
       "      <td>-0.302226</td>\n",
       "      <td>6.613237</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.305860</td>\n",
       "      <td>8.042754</td>\n",
       "      <td>5.239474</td>\n",
       "      <td>4.596935</td>\n",
       "      <td>2.555816</td>\n",
       "      <td>-9.305860</td>\n",
       "      <td>2.664483</td>\n",
       "      <td>-9.305860</td>\n",
       "      <td>-9.305860</td>\n",
       "      <td>3.596935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-410</th>\n",
       "      <td>3.857981</td>\n",
       "      <td>2.604071</td>\n",
       "      <td>4.371702</td>\n",
       "      <td>3.364861</td>\n",
       "      <td>5.472230</td>\n",
       "      <td>4.638193</td>\n",
       "      <td>-8.923140</td>\n",
       "      <td>-0.282684</td>\n",
       "      <td>-8.923140</td>\n",
       "      <td>7.137504</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.923140</td>\n",
       "      <td>7.101188</td>\n",
       "      <td>6.366252</td>\n",
       "      <td>4.995485</td>\n",
       "      <td>2.776104</td>\n",
       "      <td>-8.923140</td>\n",
       "      <td>4.329124</td>\n",
       "      <td>-8.923140</td>\n",
       "      <td>-0.249822</td>\n",
       "      <td>4.638074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-450</th>\n",
       "      <td>3.392317</td>\n",
       "      <td>2.467279</td>\n",
       "      <td>4.868012</td>\n",
       "      <td>4.406152</td>\n",
       "      <td>6.408622</td>\n",
       "      <td>5.865482</td>\n",
       "      <td>-8.739276</td>\n",
       "      <td>3.040892</td>\n",
       "      <td>-8.739276</td>\n",
       "      <td>6.543805</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.739276</td>\n",
       "      <td>7.502235</td>\n",
       "      <td>6.070389</td>\n",
       "      <td>4.472488</td>\n",
       "      <td>-0.112475</td>\n",
       "      <td>-8.739276</td>\n",
       "      <td>3.295723</td>\n",
       "      <td>1.111031</td>\n",
       "      <td>-8.739276</td>\n",
       "      <td>3.160275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-510</th>\n",
       "      <td>-9.993459</td>\n",
       "      <td>-9.993459</td>\n",
       "      <td>2.623160</td>\n",
       "      <td>2.220634</td>\n",
       "      <td>4.935506</td>\n",
       "      <td>4.232736</td>\n",
       "      <td>-9.993459</td>\n",
       "      <td>-2.005892</td>\n",
       "      <td>-9.993459</td>\n",
       "      <td>5.482203</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.993459</td>\n",
       "      <td>3.226509</td>\n",
       "      <td>4.363872</td>\n",
       "      <td>-9.993459</td>\n",
       "      <td>-9.993459</td>\n",
       "      <td>-9.993459</td>\n",
       "      <td>-9.993459</td>\n",
       "      <td>-9.993459</td>\n",
       "      <td>-9.993459</td>\n",
       "      <td>-9.993459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-520</th>\n",
       "      <td>2.735522</td>\n",
       "      <td>2.238787</td>\n",
       "      <td>5.006298</td>\n",
       "      <td>4.992315</td>\n",
       "      <td>7.073204</td>\n",
       "      <td>6.312928</td>\n",
       "      <td>1.835924</td>\n",
       "      <td>1.711495</td>\n",
       "      <td>-8.649639</td>\n",
       "      <td>8.070389</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.649639</td>\n",
       "      <td>4.094236</td>\n",
       "      <td>2.308154</td>\n",
       "      <td>4.112700</td>\n",
       "      <td>-8.649639</td>\n",
       "      <td>-8.649639</td>\n",
       "      <td>1.321928</td>\n",
       "      <td>2.372952</td>\n",
       "      <td>-8.649639</td>\n",
       "      <td>2.443607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-70</th>\n",
       "      <td>3.305971</td>\n",
       "      <td>1.028569</td>\n",
       "      <td>5.482266</td>\n",
       "      <td>3.181413</td>\n",
       "      <td>5.489895</td>\n",
       "      <td>5.040101</td>\n",
       "      <td>-9.002310</td>\n",
       "      <td>1.389567</td>\n",
       "      <td>-9.002310</td>\n",
       "      <td>6.287251</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.002310</td>\n",
       "      <td>4.841973</td>\n",
       "      <td>6.965807</td>\n",
       "      <td>4.672425</td>\n",
       "      <td>1.220330</td>\n",
       "      <td>-9.002310</td>\n",
       "      <td>3.744161</td>\n",
       "      <td>-9.002310</td>\n",
       "      <td>0.378512</td>\n",
       "      <td>4.972693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME-1</th>\n",
       "      <td>-11.664782</td>\n",
       "      <td>-11.664782</td>\n",
       "      <td>5.601013</td>\n",
       "      <td>3.990955</td>\n",
       "      <td>6.404290</td>\n",
       "      <td>5.581653</td>\n",
       "      <td>-11.664782</td>\n",
       "      <td>4.172327</td>\n",
       "      <td>1.516015</td>\n",
       "      <td>8.440454</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.664782</td>\n",
       "      <td>1.580294</td>\n",
       "      <td>5.385442</td>\n",
       "      <td>3.981853</td>\n",
       "      <td>-0.210897</td>\n",
       "      <td>-11.664782</td>\n",
       "      <td>-11.664782</td>\n",
       "      <td>-11.664782</td>\n",
       "      <td>0.356144</td>\n",
       "      <td>2.657640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML-2</th>\n",
       "      <td>4.357552</td>\n",
       "      <td>-11.163384</td>\n",
       "      <td>6.364748</td>\n",
       "      <td>4.525443</td>\n",
       "      <td>6.407523</td>\n",
       "      <td>5.659068</td>\n",
       "      <td>-11.163384</td>\n",
       "      <td>3.857981</td>\n",
       "      <td>-11.163384</td>\n",
       "      <td>7.607330</td>\n",
       "      <td>...</td>\n",
       "      <td>3.572890</td>\n",
       "      <td>1.454176</td>\n",
       "      <td>1.110363</td>\n",
       "      <td>4.857981</td>\n",
       "      <td>-11.163384</td>\n",
       "      <td>-11.163384</td>\n",
       "      <td>-11.163384</td>\n",
       "      <td>-11.163384</td>\n",
       "      <td>-11.163384</td>\n",
       "      <td>4.061776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOLM-13</th>\n",
       "      <td>3.301588</td>\n",
       "      <td>-10.427743</td>\n",
       "      <td>5.125185</td>\n",
       "      <td>0.766151</td>\n",
       "      <td>1.945674</td>\n",
       "      <td>1.104824</td>\n",
       "      <td>-10.427743</td>\n",
       "      <td>2.381283</td>\n",
       "      <td>-10.427743</td>\n",
       "      <td>1.879990</td>\n",
       "      <td>...</td>\n",
       "      <td>1.541019</td>\n",
       "      <td>1.310762</td>\n",
       "      <td>5.197118</td>\n",
       "      <td>3.632268</td>\n",
       "      <td>0.641546</td>\n",
       "      <td>-10.427743</td>\n",
       "      <td>-10.427743</td>\n",
       "      <td>-10.427743</td>\n",
       "      <td>-10.427743</td>\n",
       "      <td>2.232661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONO-MAC-6</th>\n",
       "      <td>-12.369326</td>\n",
       "      <td>-12.369326</td>\n",
       "      <td>-0.668435</td>\n",
       "      <td>2.220388</td>\n",
       "      <td>4.158706</td>\n",
       "      <td>3.722487</td>\n",
       "      <td>-12.369326</td>\n",
       "      <td>3.742006</td>\n",
       "      <td>-12.369326</td>\n",
       "      <td>6.361066</td>\n",
       "      <td>...</td>\n",
       "      <td>2.987321</td>\n",
       "      <td>1.534062</td>\n",
       "      <td>5.467475</td>\n",
       "      <td>3.887525</td>\n",
       "      <td>2.622930</td>\n",
       "      <td>-12.369326</td>\n",
       "      <td>-12.369326</td>\n",
       "      <td>-12.369326</td>\n",
       "      <td>-12.369326</td>\n",
       "      <td>2.877744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV-4-11</th>\n",
       "      <td>4.300124</td>\n",
       "      <td>0.948601</td>\n",
       "      <td>1.382391</td>\n",
       "      <td>4.388878</td>\n",
       "      <td>5.232321</td>\n",
       "      <td>4.161980</td>\n",
       "      <td>-9.776750</td>\n",
       "      <td>3.106013</td>\n",
       "      <td>-9.776750</td>\n",
       "      <td>7.641691</td>\n",
       "      <td>...</td>\n",
       "      <td>3.066950</td>\n",
       "      <td>-8.776750</td>\n",
       "      <td>6.598425</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>-0.023270</td>\n",
       "      <td>0.713696</td>\n",
       "      <td>-9.776750</td>\n",
       "      <td>-9.776750</td>\n",
       "      <td>1.599318</td>\n",
       "      <td>2.459432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB4</th>\n",
       "      <td>4.026800</td>\n",
       "      <td>1.678072</td>\n",
       "      <td>6.088947</td>\n",
       "      <td>4.972787</td>\n",
       "      <td>7.700440</td>\n",
       "      <td>6.841722</td>\n",
       "      <td>-8.923140</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>-8.923140</td>\n",
       "      <td>8.457791</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.923140</td>\n",
       "      <td>-7.923140</td>\n",
       "      <td>4.858083</td>\n",
       "      <td>3.157044</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>1.327687</td>\n",
       "      <td>-8.923140</td>\n",
       "      <td>-8.923140</td>\n",
       "      <td>0.887525</td>\n",
       "      <td>3.243364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOMO-1</th>\n",
       "      <td>-10.225936</td>\n",
       "      <td>-10.225936</td>\n",
       "      <td>5.736086</td>\n",
       "      <td>1.465105</td>\n",
       "      <td>4.621173</td>\n",
       "      <td>4.143230</td>\n",
       "      <td>-10.225936</td>\n",
       "      <td>2.356144</td>\n",
       "      <td>-10.225936</td>\n",
       "      <td>5.892391</td>\n",
       "      <td>...</td>\n",
       "      <td>6.289097</td>\n",
       "      <td>1.646163</td>\n",
       "      <td>6.572283</td>\n",
       "      <td>4.044394</td>\n",
       "      <td>1.084064</td>\n",
       "      <td>-10.225936</td>\n",
       "      <td>-10.225936</td>\n",
       "      <td>-10.225936</td>\n",
       "      <td>-10.225936</td>\n",
       "      <td>3.350497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI-AML2</th>\n",
       "      <td>-8.881720</td>\n",
       "      <td>-8.881720</td>\n",
       "      <td>4.271276</td>\n",
       "      <td>4.153977</td>\n",
       "      <td>6.552746</td>\n",
       "      <td>6.046142</td>\n",
       "      <td>-8.881720</td>\n",
       "      <td>1.184039</td>\n",
       "      <td>-8.881720</td>\n",
       "      <td>7.106432</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.881720</td>\n",
       "      <td>0.335849</td>\n",
       "      <td>6.447744</td>\n",
       "      <td>4.472488</td>\n",
       "      <td>1.280956</td>\n",
       "      <td>-8.881720</td>\n",
       "      <td>-8.881720</td>\n",
       "      <td>-8.881720</td>\n",
       "      <td>-8.881720</td>\n",
       "      <td>0.839960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI-AML3</th>\n",
       "      <td>3.129283</td>\n",
       "      <td>-8.714823</td>\n",
       "      <td>6.495056</td>\n",
       "      <td>2.847997</td>\n",
       "      <td>5.271650</td>\n",
       "      <td>4.356144</td>\n",
       "      <td>-8.714823</td>\n",
       "      <td>-7.714823</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>7.164907</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.714823</td>\n",
       "      <td>-7.714823</td>\n",
       "      <td>5.067381</td>\n",
       "      <td>3.655352</td>\n",
       "      <td>-8.714823</td>\n",
       "      <td>-8.714823</td>\n",
       "      <td>-8.714823</td>\n",
       "      <td>-8.714823</td>\n",
       "      <td>4.350497</td>\n",
       "      <td>2.560715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI-AML5</th>\n",
       "      <td>4.247928</td>\n",
       "      <td>1.731183</td>\n",
       "      <td>5.205940</td>\n",
       "      <td>4.400538</td>\n",
       "      <td>6.535120</td>\n",
       "      <td>5.348374</td>\n",
       "      <td>-10.002310</td>\n",
       "      <td>1.339137</td>\n",
       "      <td>-2.351074</td>\n",
       "      <td>8.298750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.288034</td>\n",
       "      <td>5.816625</td>\n",
       "      <td>3.560715</td>\n",
       "      <td>-10.002310</td>\n",
       "      <td>-10.002310</td>\n",
       "      <td>-10.002310</td>\n",
       "      <td>-10.002310</td>\n",
       "      <td>-10.002310</td>\n",
       "      <td>2.364572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI-M1</th>\n",
       "      <td>-10.188417</td>\n",
       "      <td>-0.042457</td>\n",
       "      <td>6.341452</td>\n",
       "      <td>4.169994</td>\n",
       "      <td>6.690429</td>\n",
       "      <td>5.789230</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.112176</td>\n",
       "      <td>-0.004335</td>\n",
       "      <td>9.224002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187707</td>\n",
       "      <td>-0.309615</td>\n",
       "      <td>4.875289</td>\n",
       "      <td>4.822730</td>\n",
       "      <td>1.490570</td>\n",
       "      <td>-10.188417</td>\n",
       "      <td>-10.188417</td>\n",
       "      <td>-10.188417</td>\n",
       "      <td>0.632268</td>\n",
       "      <td>2.124328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OE19</th>\n",
       "      <td>3.877744</td>\n",
       "      <td>2.127633</td>\n",
       "      <td>5.325171</td>\n",
       "      <td>4.643944</td>\n",
       "      <td>6.426626</td>\n",
       "      <td>5.485476</td>\n",
       "      <td>-0.232769</td>\n",
       "      <td>0.774840</td>\n",
       "      <td>4.350497</td>\n",
       "      <td>7.264912</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.352253</td>\n",
       "      <td>7.632268</td>\n",
       "      <td>6.141494</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>-9.352253</td>\n",
       "      <td>3.954196</td>\n",
       "      <td>-9.352253</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>3.350497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OE33</th>\n",
       "      <td>3.485427</td>\n",
       "      <td>3.065228</td>\n",
       "      <td>5.427372</td>\n",
       "      <td>3.797160</td>\n",
       "      <td>6.166945</td>\n",
       "      <td>5.449608</td>\n",
       "      <td>-9.459893</td>\n",
       "      <td>-0.622776</td>\n",
       "      <td>-9.459893</td>\n",
       "      <td>7.746178</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.459893</td>\n",
       "      <td>4.301588</td>\n",
       "      <td>5.198612</td>\n",
       "      <td>4.812498</td>\n",
       "      <td>2.855990</td>\n",
       "      <td>-9.459893</td>\n",
       "      <td>2.384050</td>\n",
       "      <td>2.906891</td>\n",
       "      <td>-9.459893</td>\n",
       "      <td>3.446256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P31-FUJ</th>\n",
       "      <td>3.102658</td>\n",
       "      <td>-10.928754</td>\n",
       "      <td>2.330558</td>\n",
       "      <td>3.632328</td>\n",
       "      <td>6.164505</td>\n",
       "      <td>5.341986</td>\n",
       "      <td>-10.928754</td>\n",
       "      <td>2.941106</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>7.606590</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.928754</td>\n",
       "      <td>-9.928754</td>\n",
       "      <td>5.432959</td>\n",
       "      <td>4.459432</td>\n",
       "      <td>-10.928754</td>\n",
       "      <td>0.378512</td>\n",
       "      <td>-10.928754</td>\n",
       "      <td>-10.928754</td>\n",
       "      <td>-10.928754</td>\n",
       "      <td>2.277985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL-21</th>\n",
       "      <td>2.739848</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>-0.036896</td>\n",
       "      <td>3.495695</td>\n",
       "      <td>5.784766</td>\n",
       "      <td>4.853996</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>-2.212568</td>\n",
       "      <td>3.221877</td>\n",
       "      <td>7.482203</td>\n",
       "      <td>...</td>\n",
       "      <td>3.321928</td>\n",
       "      <td>-1.152805</td>\n",
       "      <td>6.299025</td>\n",
       "      <td>4.990955</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>2.589763</td>\n",
       "      <td>2.790772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIG-M5</th>\n",
       "      <td>-0.005782</td>\n",
       "      <td>-10.587273</td>\n",
       "      <td>2.403268</td>\n",
       "      <td>4.716991</td>\n",
       "      <td>6.134426</td>\n",
       "      <td>5.127633</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>1.553361</td>\n",
       "      <td>-10.587273</td>\n",
       "      <td>6.613237</td>\n",
       "      <td>...</td>\n",
       "      <td>1.389567</td>\n",
       "      <td>-9.587273</td>\n",
       "      <td>5.207420</td>\n",
       "      <td>4.026800</td>\n",
       "      <td>1.269033</td>\n",
       "      <td>0.275007</td>\n",
       "      <td>-10.587273</td>\n",
       "      <td>-10.587273</td>\n",
       "      <td>1.531069</td>\n",
       "      <td>2.773996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK-HEP-1</th>\n",
       "      <td>-9.324238</td>\n",
       "      <td>-9.324238</td>\n",
       "      <td>4.786701</td>\n",
       "      <td>4.322041</td>\n",
       "      <td>5.672187</td>\n",
       "      <td>4.433064</td>\n",
       "      <td>-9.324238</td>\n",
       "      <td>-8.324238</td>\n",
       "      <td>-9.324238</td>\n",
       "      <td>5.827819</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.324238</td>\n",
       "      <td>4.709842</td>\n",
       "      <td>6.172327</td>\n",
       "      <td>-9.324238</td>\n",
       "      <td>4.008989</td>\n",
       "      <td>-9.324238</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>-9.324238</td>\n",
       "      <td>-9.324238</td>\n",
       "      <td>5.904484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKM-1</th>\n",
       "      <td>3.510962</td>\n",
       "      <td>-10.257376</td>\n",
       "      <td>4.848998</td>\n",
       "      <td>4.365273</td>\n",
       "      <td>6.618973</td>\n",
       "      <td>5.757290</td>\n",
       "      <td>-10.257376</td>\n",
       "      <td>1.341417</td>\n",
       "      <td>5.371559</td>\n",
       "      <td>7.284477</td>\n",
       "      <td>...</td>\n",
       "      <td>1.613532</td>\n",
       "      <td>-9.257376</td>\n",
       "      <td>4.082362</td>\n",
       "      <td>3.935460</td>\n",
       "      <td>-10.257376</td>\n",
       "      <td>2.327687</td>\n",
       "      <td>-10.257376</td>\n",
       "      <td>-10.257376</td>\n",
       "      <td>3.364572</td>\n",
       "      <td>2.403268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-182</th>\n",
       "      <td>2.726831</td>\n",
       "      <td>1.063503</td>\n",
       "      <td>-0.332716</td>\n",
       "      <td>4.070565</td>\n",
       "      <td>6.346816</td>\n",
       "      <td>5.711551</td>\n",
       "      <td>-8.937215</td>\n",
       "      <td>-0.002830</td>\n",
       "      <td>-8.937215</td>\n",
       "      <td>6.437960</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.937215</td>\n",
       "      <td>5.074677</td>\n",
       "      <td>6.461463</td>\n",
       "      <td>5.817623</td>\n",
       "      <td>2.987321</td>\n",
       "      <td>-8.937215</td>\n",
       "      <td>2.994580</td>\n",
       "      <td>3.405992</td>\n",
       "      <td>0.855990</td>\n",
       "      <td>5.783980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-387</th>\n",
       "      <td>-9.142035</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>3.607153</td>\n",
       "      <td>4.711592</td>\n",
       "      <td>5.925401</td>\n",
       "      <td>4.632371</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>-8.142035</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>6.383704</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>4.783980</td>\n",
       "      <td>6.199476</td>\n",
       "      <td>2.046142</td>\n",
       "      <td>3.837943</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>1.007196</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>3.632268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-398</th>\n",
       "      <td>2.403268</td>\n",
       "      <td>1.713696</td>\n",
       "      <td>0.380585</td>\n",
       "      <td>4.009156</td>\n",
       "      <td>5.612441</td>\n",
       "      <td>4.875289</td>\n",
       "      <td>-9.062746</td>\n",
       "      <td>-8.062746</td>\n",
       "      <td>3.963474</td>\n",
       "      <td>8.393176</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.062746</td>\n",
       "      <td>6.139551</td>\n",
       "      <td>-8.062746</td>\n",
       "      <td>4.145677</td>\n",
       "      <td>-9.062746</td>\n",
       "      <td>-9.062746</td>\n",
       "      <td>0.863938</td>\n",
       "      <td>-9.062746</td>\n",
       "      <td>1.070389</td>\n",
       "      <td>2.653060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-423</th>\n",
       "      <td>1.769772</td>\n",
       "      <td>0.790772</td>\n",
       "      <td>5.873050</td>\n",
       "      <td>4.087644</td>\n",
       "      <td>5.582560</td>\n",
       "      <td>4.832998</td>\n",
       "      <td>-1.123434</td>\n",
       "      <td>-7.868173</td>\n",
       "      <td>2.295723</td>\n",
       "      <td>8.499846</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.868173</td>\n",
       "      <td>8.450386</td>\n",
       "      <td>0.772308</td>\n",
       "      <td>4.017922</td>\n",
       "      <td>0.782409</td>\n",
       "      <td>-8.868173</td>\n",
       "      <td>4.217231</td>\n",
       "      <td>-8.868173</td>\n",
       "      <td>-8.868173</td>\n",
       "      <td>3.733354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-449</th>\n",
       "      <td>-10.361713</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>-0.144010</td>\n",
       "      <td>5.004951</td>\n",
       "      <td>5.659725</td>\n",
       "      <td>4.160275</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>-9.361713</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>6.797013</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>7.923625</td>\n",
       "      <td>6.591290</td>\n",
       "      <td>3.572890</td>\n",
       "      <td>4.385431</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>1.744161</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>4.472488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-475</th>\n",
       "      <td>-10.346606</td>\n",
       "      <td>-10.346606</td>\n",
       "      <td>4.737687</td>\n",
       "      <td>3.511059</td>\n",
       "      <td>5.514778</td>\n",
       "      <td>4.578985</td>\n",
       "      <td>-10.346606</td>\n",
       "      <td>-1.136797</td>\n",
       "      <td>-10.346606</td>\n",
       "      <td>6.116864</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.346606</td>\n",
       "      <td>7.961739</td>\n",
       "      <td>7.231701</td>\n",
       "      <td>3.419539</td>\n",
       "      <td>5.680887</td>\n",
       "      <td>-10.346606</td>\n",
       "      <td>3.119356</td>\n",
       "      <td>-10.346606</td>\n",
       "      <td>-10.346606</td>\n",
       "      <td>3.916477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THP-1</th>\n",
       "      <td>3.560715</td>\n",
       "      <td>-12.012705</td>\n",
       "      <td>5.699885</td>\n",
       "      <td>4.348374</td>\n",
       "      <td>6.466468</td>\n",
       "      <td>5.350506</td>\n",
       "      <td>-12.012705</td>\n",
       "      <td>1.406124</td>\n",
       "      <td>3.523562</td>\n",
       "      <td>7.360189</td>\n",
       "      <td>...</td>\n",
       "      <td>3.158660</td>\n",
       "      <td>1.170080</td>\n",
       "      <td>2.313246</td>\n",
       "      <td>1.757023</td>\n",
       "      <td>-12.012705</td>\n",
       "      <td>-12.012705</td>\n",
       "      <td>-12.012705</td>\n",
       "      <td>-12.012705</td>\n",
       "      <td>-12.012705</td>\n",
       "      <td>1.646163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 22804 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col.name    KDM1A(S45);  KDM1A(T19);  ZFP91(S69);  INCENP(T150);  \\\n",
       "CMK           -9.751659    -9.751659     6.298313       3.897353   \n",
       "COLO-680N     -9.158429    -9.158429     4.479295       5.005041   \n",
       "GDM-1         -9.522178    -9.522178     2.807355       4.263786   \n",
       "HEL          -11.117787     0.641546     3.539779       3.805292   \n",
       "HL-60        -11.200250   -11.200250     5.420314       3.594549   \n",
       "JHH-2        -10.000831   -10.000831     2.356419       2.653284   \n",
       "JHH-4          1.790772    -9.532825     4.705917       4.863014   \n",
       "KASUMI-1     -10.480357   -10.480357     5.850999       3.267641   \n",
       "KG-1         -10.582840   -10.582840     6.659542       1.531395   \n",
       "KMOE-2         4.572890     1.778209     5.472455       3.517276   \n",
       "KYSE-140       4.560715     1.839960     5.220330       4.603009   \n",
       "KYSE-150      -0.187707    -9.305860     5.343464       4.842727   \n",
       "KYSE-410       3.857981     2.604071     4.371702       3.364861   \n",
       "KYSE-450       3.392317     2.467279     4.868012       4.406152   \n",
       "KYSE-510      -9.993459    -9.993459     2.623160       2.220634   \n",
       "KYSE-520       2.735522     2.238787     5.006298       4.992315   \n",
       "KYSE-70        3.305971     1.028569     5.482266       3.181413   \n",
       "ME-1         -11.664782   -11.664782     5.601013       3.990955   \n",
       "ML-2           4.357552   -11.163384     6.364748       4.525443   \n",
       "MOLM-13        3.301588   -10.427743     5.125185       0.766151   \n",
       "MONO-MAC-6   -12.369326   -12.369326    -0.668435       2.220388   \n",
       "MV-4-11        4.300124     0.948601     1.382391       4.388878   \n",
       "NB4            4.026800     1.678072     6.088947       4.972787   \n",
       "NOMO-1       -10.225936   -10.225936     5.736086       1.465105   \n",
       "OCI-AML2      -8.881720    -8.881720     4.271276       4.153977   \n",
       "OCI-AML3       3.129283    -8.714823     6.495056       2.847997   \n",
       "OCI-AML5       4.247928     1.731183     5.205940       4.400538   \n",
       "OCI-M1       -10.188417    -0.042457     6.341452       4.169994   \n",
       "OE19           3.877744     2.127633     5.325171       4.643944   \n",
       "OE33           3.485427     3.065228     5.427372       3.797160   \n",
       "P31-FUJ        3.102658   -10.928754     2.330558       3.632328   \n",
       "PL-21          2.739848    -9.158429    -0.036896       3.495695   \n",
       "SIG-M5        -0.005782   -10.587273     2.403268       4.716991   \n",
       "SK-HEP-1      -9.324238    -9.324238     4.786701       4.322041   \n",
       "SKM-1          3.510962   -10.257376     4.848998       4.365273   \n",
       "SNU-182        2.726831     1.063503    -0.332716       4.070565   \n",
       "SNU-387       -9.142035    -9.142035     3.607153       4.711592   \n",
       "SNU-398        2.403268     1.713696     0.380585       4.009156   \n",
       "SNU-423        1.769772     0.790772     5.873050       4.087644   \n",
       "SNU-449      -10.361713   -10.361713    -0.144010       5.004951   \n",
       "SNU-475      -10.346606   -10.346606     4.737687       3.511059   \n",
       "THP-1          3.560715   -12.012705     5.699885       4.348374   \n",
       "\n",
       "col.name    INCENP(T153);  INCENP(T153);INCENP(T135);  \\\n",
       "CMK              6.801432                    6.270551   \n",
       "COLO-680N        6.620465                    5.830401   \n",
       "GDM-1            6.313452                    5.388925   \n",
       "HEL              6.411765                    5.724105   \n",
       "HL-60            4.385697                    4.070426   \n",
       "JHH-2            4.659352                    3.273661   \n",
       "JHH-4            6.920043                    6.361926   \n",
       "KASUMI-1         5.040923                    4.307480   \n",
       "KG-1             4.475776                    3.744231   \n",
       "KMOE-2           5.602310                    4.672462   \n",
       "KYSE-140         6.483205                    5.776159   \n",
       "KYSE-150         6.554896                    5.790772   \n",
       "KYSE-410         5.472230                    4.638193   \n",
       "KYSE-450         6.408622                    5.865482   \n",
       "KYSE-510         4.935506                    4.232736   \n",
       "KYSE-520         7.073204                    6.312928   \n",
       "KYSE-70          5.489895                    5.040101   \n",
       "ME-1             6.404290                    5.581653   \n",
       "ML-2             6.407523                    5.659068   \n",
       "MOLM-13          1.945674                    1.104824   \n",
       "MONO-MAC-6       4.158706                    3.722487   \n",
       "MV-4-11          5.232321                    4.161980   \n",
       "NB4              7.700440                    6.841722   \n",
       "NOMO-1           4.621173                    4.143230   \n",
       "OCI-AML2         6.552746                    6.046142   \n",
       "OCI-AML3         5.271650                    4.356144   \n",
       "OCI-AML5         6.535120                    5.348374   \n",
       "OCI-M1           6.690429                    5.789230   \n",
       "OE19             6.426626                    5.485476   \n",
       "OE33             6.166945                    5.449608   \n",
       "P31-FUJ          6.164505                    5.341986   \n",
       "PL-21            5.784766                    4.853996   \n",
       "SIG-M5           6.134426                    5.127633   \n",
       "SK-HEP-1         5.672187                    4.433064   \n",
       "SKM-1            6.618973                    5.757290   \n",
       "SNU-182          6.346816                    5.711551   \n",
       "SNU-387          5.925401                    4.632371   \n",
       "SNU-398          5.612441                    4.875289   \n",
       "SNU-423          5.582560                    4.832998   \n",
       "SNU-449          5.659725                    4.160275   \n",
       "SNU-475          5.514778                    4.578985   \n",
       "THP-1            6.466468                    5.350506   \n",
       "\n",
       "col.name    INCENP(M136);INCENP(T145);INCENP(S148);  EIF3J(S11);EIF3J(S13);  \\\n",
       "CMK                                        0.925999                2.077243   \n",
       "COLO-680N                                  0.765535                0.487229   \n",
       "GDM-1                                      0.356144                1.062812   \n",
       "HEL                                      -11.117787                1.891419   \n",
       "HL-60                                    -11.200250                4.852998   \n",
       "JHH-2                                    -10.000831               -9.000831   \n",
       "JHH-4                                      1.773996                0.743300   \n",
       "KASUMI-1                                 -10.480357                1.989139   \n",
       "KG-1                                     -10.582840                2.742006   \n",
       "KMOE-2                                   -10.602894                3.121015   \n",
       "KYSE-140                                   0.815575                0.944109   \n",
       "KYSE-150                                   1.480265                1.064593   \n",
       "KYSE-410                                  -8.923140               -0.282684   \n",
       "KYSE-450                                  -8.739276                3.040892   \n",
       "KYSE-510                                  -9.993459               -2.005892   \n",
       "KYSE-520                                   1.835924                1.711495   \n",
       "KYSE-70                                   -9.002310                1.389567   \n",
       "ME-1                                     -11.664782                4.172327   \n",
       "ML-2                                     -11.163384                3.857981   \n",
       "MOLM-13                                  -10.427743                2.381283   \n",
       "MONO-MAC-6                               -12.369326                3.742006   \n",
       "MV-4-11                                   -9.776750                3.106013   \n",
       "NB4                                       -8.923140                0.002969   \n",
       "NOMO-1                                   -10.225936                2.356144   \n",
       "OCI-AML2                                  -8.881720                1.184039   \n",
       "OCI-AML3                                  -8.714823               -7.714823   \n",
       "OCI-AML5                                 -10.002310                1.339137   \n",
       "OCI-M1                                     0.695994                0.112176   \n",
       "OE19                                      -0.232769                0.774840   \n",
       "OE33                                      -9.459893               -0.622776   \n",
       "P31-FUJ                                  -10.928754                2.941106   \n",
       "PL-21                                     -9.158429               -2.212568   \n",
       "SIG-M5                                     0.189034                1.553361   \n",
       "SK-HEP-1                                  -9.324238               -8.324238   \n",
       "SKM-1                                    -10.257376                1.341417   \n",
       "SNU-182                                   -8.937215               -0.002830   \n",
       "SNU-387                                   -9.142035               -8.142035   \n",
       "SNU-398                                   -9.062746               -8.062746   \n",
       "SNU-423                                   -1.123434               -7.868173   \n",
       "SNU-449                                  -10.361713               -9.361713   \n",
       "SNU-475                                  -10.346606               -1.136797   \n",
       "THP-1                                    -12.012705                1.406124   \n",
       "\n",
       "col.name    POLE4(S9);  SAMD1(T157);  ...  CTDP1(T340);  EPS8L2(T572);  \\\n",
       "CMK          -9.751659      8.603255  ...     -9.751659      -8.751659   \n",
       "COLO-680N    -0.349235      7.013462  ...     -9.158429       7.549977   \n",
       "GDM-1         3.184280      8.247928  ...     -9.522178      -8.522178   \n",
       "HEL         -11.117787      8.733354  ...    -11.117787       0.333939   \n",
       "HL-60       -11.200250      5.044394  ...      3.584963     -10.200250   \n",
       "JHH-2       -10.000831      6.195348  ...    -10.000831       7.845490   \n",
       "JHH-4        -9.532825      6.137504  ...     -9.532825       5.529509   \n",
       "KASUMI-1    -10.480357      8.485829  ...      2.427606       1.914832   \n",
       "KG-1        -10.582840      7.156842  ...    -10.582840      -1.130833   \n",
       "KMOE-2        0.871844      7.660353  ...      0.887525       1.541338   \n",
       "KYSE-140     -8.895395      7.277055  ...     -8.895395      -7.895395   \n",
       "KYSE-150     -0.302226      6.613237  ...     -9.305860       8.042754   \n",
       "KYSE-410     -8.923140      7.137504  ...     -8.923140       7.101188   \n",
       "KYSE-450     -8.739276      6.543805  ...     -8.739276       7.502235   \n",
       "KYSE-510     -9.993459      5.482203  ...     -9.993459       3.226509   \n",
       "KYSE-520     -8.649639      8.070389  ...     -8.649639       4.094236   \n",
       "KYSE-70      -9.002310      6.287251  ...     -9.002310       4.841973   \n",
       "ME-1          1.516015      8.440454  ...    -11.664782       1.580294   \n",
       "ML-2        -11.163384      7.607330  ...      3.572890       1.454176   \n",
       "MOLM-13     -10.427743      1.879990  ...      1.541019       1.310762   \n",
       "MONO-MAC-6  -12.369326      6.361066  ...      2.987321       1.534062   \n",
       "MV-4-11      -9.776750      7.641691  ...      3.066950      -8.776750   \n",
       "NB4          -8.923140      8.457791  ...     -8.923140      -7.923140   \n",
       "NOMO-1      -10.225936      5.892391  ...      6.289097       1.646163   \n",
       "OCI-AML2     -8.881720      7.106432  ...     -8.881720       0.335849   \n",
       "OCI-AML3      3.459432      7.164907  ...     -8.714823      -7.714823   \n",
       "OCI-AML5     -2.351074      8.298750  ...      0.321928       0.288034   \n",
       "OCI-M1       -0.004335      9.224002  ...     -0.187707      -0.309615   \n",
       "OE19          4.350497      7.264912  ...     -9.352253       7.632268   \n",
       "OE33         -9.459893      7.746178  ...     -9.459893       4.301588   \n",
       "P31-FUJ       0.731183      7.606590  ...    -10.928754      -9.928754   \n",
       "PL-21         3.221877      7.482203  ...      3.321928      -1.152805   \n",
       "SIG-M5      -10.587273      6.613237  ...      1.389567      -9.587273   \n",
       "SK-HEP-1     -9.324238      5.827819  ...     -9.324238       4.709842   \n",
       "SKM-1         5.371559      7.284477  ...      1.613532      -9.257376   \n",
       "SNU-182      -8.937215      6.437960  ...     -8.937215       5.074677   \n",
       "SNU-387      -9.142035      6.383704  ...     -9.142035       4.783980   \n",
       "SNU-398       3.963474      8.393176  ...     -9.062746       6.139551   \n",
       "SNU-423       2.295723      8.499846  ...     -8.868173       8.450386   \n",
       "SNU-449     -10.361713      6.797013  ...    -10.361713       7.923625   \n",
       "SNU-475     -10.346606      6.116864  ...    -10.346606       7.961739   \n",
       "THP-1         3.523562      7.360189  ...      3.158660       1.170080   \n",
       "\n",
       "col.name    BEGAIN(S455);  HNRNPL(S52);  GMDS(T327);  \\\n",
       "CMK              4.683472      4.285402    -9.751659   \n",
       "COLO-680N        5.488547      4.649615    -9.158429   \n",
       "GDM-1            7.215484      4.935460    -0.954557   \n",
       "HEL              3.135535      4.209453    -1.577767   \n",
       "HL-60            7.209458      4.678072   -11.200250   \n",
       "JHH-2            5.852249      2.985500     4.270529   \n",
       "JHH-4            6.375853      3.877744     1.713696   \n",
       "KASUMI-1        -1.416192      2.998196   -10.480357   \n",
       "KG-1             6.456160      3.523562     4.201634   \n",
       "KMOE-2           4.222650      3.459432   -10.602894   \n",
       "KYSE-140         7.338959      4.185867     2.025029   \n",
       "KYSE-150         5.239474      4.596935     2.555816   \n",
       "KYSE-410         6.366252      4.995485     2.776104   \n",
       "KYSE-450         6.070389      4.472488    -0.112475   \n",
       "KYSE-510         4.363872     -9.993459    -9.993459   \n",
       "KYSE-520         2.308154      4.112700    -8.649639   \n",
       "KYSE-70          6.965807      4.672425     1.220330   \n",
       "ME-1             5.385442      3.981853    -0.210897   \n",
       "ML-2             1.110363      4.857981   -11.163384   \n",
       "MOLM-13          5.197118      3.632268     0.641546   \n",
       "MONO-MAC-6       5.467475      3.887525     2.622930   \n",
       "MV-4-11          6.598425      3.459432    -0.023270   \n",
       "NB4              4.858083      3.157044     0.189034   \n",
       "NOMO-1           6.572283      4.044394     1.084064   \n",
       "OCI-AML2         6.447744      4.472488     1.280956   \n",
       "OCI-AML3         5.067381      3.655352    -8.714823   \n",
       "OCI-AML5         5.816625      3.560715   -10.002310   \n",
       "OCI-M1           4.875289      4.822730     1.490570   \n",
       "OE19             6.141494      3.459432     0.214125   \n",
       "OE33             5.198612      4.812498     2.855990   \n",
       "P31-FUJ          5.432959      4.459432   -10.928754   \n",
       "PL-21            6.299025      4.990955    -9.158429   \n",
       "SIG-M5           5.207420      4.026800     1.269033   \n",
       "SK-HEP-1         6.172327     -9.324238     4.008989   \n",
       "SKM-1            4.082362      3.935460   -10.257376   \n",
       "SNU-182          6.461463      5.817623     2.987321   \n",
       "SNU-387          6.199476      2.046142     3.837943   \n",
       "SNU-398         -8.062746      4.145677    -9.062746   \n",
       "SNU-423          0.772308      4.017922     0.782409   \n",
       "SNU-449          6.591290      3.572890     4.385431   \n",
       "SNU-475          7.231701      3.419539     5.680887   \n",
       "THP-1            2.313246      1.757023   -12.012705   \n",
       "\n",
       "col.name    BOD1L1(S482);BOD1L1(S484);  ARHGEF35(T193);  ARHGEF5(S184);  \\\n",
       "CMK                          -0.388355        -9.751659       -9.751659   \n",
       "COLO-680N                    -9.158429         0.214125        1.263034   \n",
       "GDM-1                        -0.948976        -9.522178       -9.522178   \n",
       "HEL                         -11.117787       -11.117787      -11.117787   \n",
       "HL-60                       -11.200250       -11.200250      -11.200250   \n",
       "JHH-2                       -10.000831         4.153805        3.292782   \n",
       "JHH-4                        -9.532825         2.839960        0.773996   \n",
       "KASUMI-1                      2.292782       -10.480357      -10.480357   \n",
       "KG-1                          0.137504       -10.582840      -10.582840   \n",
       "KMOE-2                      -10.602894       -10.602894      -10.602894   \n",
       "KYSE-140                     -8.895395        -8.895395       -8.895395   \n",
       "KYSE-150                     -9.305860         2.664483       -9.305860   \n",
       "KYSE-410                     -8.923140         4.329124       -8.923140   \n",
       "KYSE-450                     -8.739276         3.295723        1.111031   \n",
       "KYSE-510                     -9.993459        -9.993459       -9.993459   \n",
       "KYSE-520                     -8.649639         1.321928        2.372952   \n",
       "KYSE-70                      -9.002310         3.744161       -9.002310   \n",
       "ME-1                        -11.664782       -11.664782      -11.664782   \n",
       "ML-2                        -11.163384       -11.163384      -11.163384   \n",
       "MOLM-13                     -10.427743       -10.427743      -10.427743   \n",
       "MONO-MAC-6                  -12.369326       -12.369326      -12.369326   \n",
       "MV-4-11                       0.713696        -9.776750       -9.776750   \n",
       "NB4                           1.327687        -8.923140       -8.923140   \n",
       "NOMO-1                      -10.225936       -10.225936      -10.225936   \n",
       "OCI-AML2                     -8.881720        -8.881720       -8.881720   \n",
       "OCI-AML3                     -8.714823        -8.714823       -8.714823   \n",
       "OCI-AML5                    -10.002310       -10.002310      -10.002310   \n",
       "OCI-M1                      -10.188417       -10.188417      -10.188417   \n",
       "OE19                         -9.352253         3.954196       -9.352253   \n",
       "OE33                         -9.459893         2.384050        2.906891   \n",
       "P31-FUJ                       0.378512       -10.928754      -10.928754   \n",
       "PL-21                        -9.158429        -9.158429       -9.158429   \n",
       "SIG-M5                        0.275007       -10.587273      -10.587273   \n",
       "SK-HEP-1                     -9.324238         0.014355       -9.324238   \n",
       "SKM-1                         2.327687       -10.257376      -10.257376   \n",
       "SNU-182                      -8.937215         2.994580        3.405992   \n",
       "SNU-387                      -9.142035         1.007196       -9.142035   \n",
       "SNU-398                      -9.062746         0.863938       -9.062746   \n",
       "SNU-423                      -8.868173         4.217231       -8.868173   \n",
       "SNU-449                     -10.361713         1.744161      -10.361713   \n",
       "SNU-475                     -10.346606         3.119356      -10.346606   \n",
       "THP-1                       -12.012705       -12.012705      -12.012705   \n",
       "\n",
       "col.name    PSMB2(T148);  HSP90AA1(S476);  \n",
       "CMK             0.575312         1.627607  \n",
       "COLO-680N      -2.403542         3.378512  \n",
       "GDM-1           1.952334         3.320485  \n",
       "HEL             0.389567         3.279471  \n",
       "HL-60          -2.011588         2.536053  \n",
       "JHH-2         -10.000831         2.545968  \n",
       "JHH-4          -9.532825         3.336283  \n",
       "KASUMI-1      -10.480357       -10.480357  \n",
       "KG-1            2.223423         2.223423  \n",
       "KMOE-2        -10.602894         2.639232  \n",
       "KYSE-140       -8.895395         4.542258  \n",
       "KYSE-150       -9.305860         3.596935  \n",
       "KYSE-410       -0.249822         4.638074  \n",
       "KYSE-450       -8.739276         3.160275  \n",
       "KYSE-510       -9.993459        -9.993459  \n",
       "KYSE-520       -8.649639         2.443607  \n",
       "KYSE-70         0.378512         4.972693  \n",
       "ME-1            0.356144         2.657640  \n",
       "ML-2          -11.163384         4.061776  \n",
       "MOLM-13       -10.427743         2.232661  \n",
       "MONO-MAC-6    -12.369326         2.877744  \n",
       "MV-4-11         1.599318         2.459432  \n",
       "NB4             0.887525         3.243364  \n",
       "NOMO-1        -10.225936         3.350497  \n",
       "OCI-AML2       -8.881720         0.839960  \n",
       "OCI-AML3        4.350497         2.560715  \n",
       "OCI-AML5      -10.002310         2.364572  \n",
       "OCI-M1          0.632268         2.124328  \n",
       "OE19            0.189034         3.350497  \n",
       "OE33           -9.459893         3.446256  \n",
       "P31-FUJ       -10.928754         2.277985  \n",
       "PL-21           2.589763         2.790772  \n",
       "SIG-M5          1.531069         2.773996  \n",
       "SK-HEP-1       -9.324238         5.904484  \n",
       "SKM-1           3.364572         2.403268  \n",
       "SNU-182         0.855990         5.783980  \n",
       "SNU-387        -9.142035         3.632268  \n",
       "SNU-398         1.070389         2.653060  \n",
       "SNU-423        -8.868173         3.733354  \n",
       "SNU-449       -10.361713         4.472488  \n",
       "SNU-475       -10.346606         3.916477  \n",
       "THP-1         -12.012705         1.646163  \n",
       "\n",
       "[42 rows x 22804 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.phos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>(5Z)-7-Oxozeaenol</th>\n",
       "      <th>5-Fluorouracil</th>\n",
       "      <th>A-443654</th>\n",
       "      <th>A-770041</th>\n",
       "      <th>A-83-01</th>\n",
       "      <th>ACY-1215</th>\n",
       "      <th>AGI-6780</th>\n",
       "      <th>AICA Ribonucleotide</th>\n",
       "      <th>AKT inhibitor VIII</th>\n",
       "      <th>AR-42</th>\n",
       "      <th>...</th>\n",
       "      <th>YK-4-279</th>\n",
       "      <th>YM201636</th>\n",
       "      <th>Z-LLNle-CHO</th>\n",
       "      <th>ZG-10</th>\n",
       "      <th>ZM447439</th>\n",
       "      <th>ZSTK474</th>\n",
       "      <th>Zibotentan</th>\n",
       "      <th>eEF2K Inhibitor, A-484954</th>\n",
       "      <th>kb NB 142-70</th>\n",
       "      <th>rTRAIL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CMK</th>\n",
       "      <td>0.533605</td>\n",
       "      <td>1.356067</td>\n",
       "      <td>-1.225855</td>\n",
       "      <td>3.423778</td>\n",
       "      <td>4.279684</td>\n",
       "      <td>0.445262</td>\n",
       "      <td>0.883803</td>\n",
       "      <td>7.306995</td>\n",
       "      <td>1.628922</td>\n",
       "      <td>-2.703728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711090</td>\n",
       "      <td>1.010783</td>\n",
       "      <td>-0.168536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.327991</td>\n",
       "      <td>-1.569145</td>\n",
       "      <td>4.348476</td>\n",
       "      <td>4.607164</td>\n",
       "      <td>1.816375</td>\n",
       "      <td>-0.475125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLO-680N</th>\n",
       "      <td>1.729743</td>\n",
       "      <td>5.825205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.311197</td>\n",
       "      <td>1.541306</td>\n",
       "      <td>1.857318</td>\n",
       "      <td>7.779938</td>\n",
       "      <td>3.089514</td>\n",
       "      <td>4.383391</td>\n",
       "      <td>...</td>\n",
       "      <td>2.914492</td>\n",
       "      <td>4.505976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.786317</td>\n",
       "      <td>2.637072</td>\n",
       "      <td>5.998495</td>\n",
       "      <td>6.098361</td>\n",
       "      <td>2.709776</td>\n",
       "      <td>0.660982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GDM-1</th>\n",
       "      <td>-0.523250</td>\n",
       "      <td>0.919553</td>\n",
       "      <td>-0.689946</td>\n",
       "      <td>3.007763</td>\n",
       "      <td>3.101210</td>\n",
       "      <td>0.299259</td>\n",
       "      <td>1.086986</td>\n",
       "      <td>6.873515</td>\n",
       "      <td>0.480957</td>\n",
       "      <td>-2.204147</td>\n",
       "      <td>...</td>\n",
       "      <td>1.159891</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.785866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.944803</td>\n",
       "      <td>-2.732485</td>\n",
       "      <td>4.779900</td>\n",
       "      <td>4.951323</td>\n",
       "      <td>1.217470</td>\n",
       "      <td>-1.530039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEL</th>\n",
       "      <td>0.948509</td>\n",
       "      <td>0.096313</td>\n",
       "      <td>-0.847805</td>\n",
       "      <td>2.509067</td>\n",
       "      <td>4.442955</td>\n",
       "      <td>0.781370</td>\n",
       "      <td>1.223233</td>\n",
       "      <td>6.679720</td>\n",
       "      <td>2.108089</td>\n",
       "      <td>-2.640470</td>\n",
       "      <td>...</td>\n",
       "      <td>1.243856</td>\n",
       "      <td>1.034155</td>\n",
       "      <td>-0.259764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.877772</td>\n",
       "      <td>0.437604</td>\n",
       "      <td>4.329365</td>\n",
       "      <td>4.893941</td>\n",
       "      <td>2.141834</td>\n",
       "      <td>-2.435046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HL-60</th>\n",
       "      <td>1.426720</td>\n",
       "      <td>1.847379</td>\n",
       "      <td>0.275800</td>\n",
       "      <td>2.246344</td>\n",
       "      <td>4.317315</td>\n",
       "      <td>0.584272</td>\n",
       "      <td>0.977314</td>\n",
       "      <td>5.779418</td>\n",
       "      <td>2.343589</td>\n",
       "      <td>-2.105449</td>\n",
       "      <td>...</td>\n",
       "      <td>1.936856</td>\n",
       "      <td>2.055140</td>\n",
       "      <td>0.738669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933645</td>\n",
       "      <td>-0.935734</td>\n",
       "      <td>5.244023</td>\n",
       "      <td>5.293992</td>\n",
       "      <td>1.350463</td>\n",
       "      <td>-0.662189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JHH-2</th>\n",
       "      <td>1.250863</td>\n",
       "      <td>2.805717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.809860</td>\n",
       "      <td>1.352882</td>\n",
       "      <td>1.928683</td>\n",
       "      <td>8.068791</td>\n",
       "      <td>3.800954</td>\n",
       "      <td>-0.538916</td>\n",
       "      <td>...</td>\n",
       "      <td>1.615375</td>\n",
       "      <td>3.477278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.867514</td>\n",
       "      <td>2.235465</td>\n",
       "      <td>5.593274</td>\n",
       "      <td>5.498093</td>\n",
       "      <td>1.677161</td>\n",
       "      <td>-0.590448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JHH-4</th>\n",
       "      <td>1.728183</td>\n",
       "      <td>3.831835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.052734</td>\n",
       "      <td>1.682833</td>\n",
       "      <td>1.190176</td>\n",
       "      <td>8.236501</td>\n",
       "      <td>0.179473</td>\n",
       "      <td>-1.997605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555819</td>\n",
       "      <td>1.577455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.356895</td>\n",
       "      <td>0.038652</td>\n",
       "      <td>5.468000</td>\n",
       "      <td>5.148859</td>\n",
       "      <td>2.785413</td>\n",
       "      <td>-4.329280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KASUMI-1</th>\n",
       "      <td>-1.027736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.660142</td>\n",
       "      <td>3.912199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.942764</td>\n",
       "      <td>-0.691354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.495208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.322155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.806383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KG-1</th>\n",
       "      <td>-0.741724</td>\n",
       "      <td>3.220940</td>\n",
       "      <td>1.197924</td>\n",
       "      <td>3.882495</td>\n",
       "      <td>2.205678</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>1.062529</td>\n",
       "      <td>5.729228</td>\n",
       "      <td>2.041374</td>\n",
       "      <td>-2.120892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388608</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>1.712625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.642640</td>\n",
       "      <td>0.480226</td>\n",
       "      <td>5.296632</td>\n",
       "      <td>4.591654</td>\n",
       "      <td>1.126185</td>\n",
       "      <td>-0.319311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMOE-2</th>\n",
       "      <td>-1.408182</td>\n",
       "      <td>1.864702</td>\n",
       "      <td>-0.767405</td>\n",
       "      <td>3.672939</td>\n",
       "      <td>4.940030</td>\n",
       "      <td>0.952982</td>\n",
       "      <td>0.825652</td>\n",
       "      <td>5.761281</td>\n",
       "      <td>1.074860</td>\n",
       "      <td>-2.008743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063605</td>\n",
       "      <td>0.156328</td>\n",
       "      <td>0.065058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.380753</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>5.551606</td>\n",
       "      <td>5.178670</td>\n",
       "      <td>2.245417</td>\n",
       "      <td>-0.429986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-140</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.331959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.150266</td>\n",
       "      <td>1.761124</td>\n",
       "      <td>0.803499</td>\n",
       "      <td>7.426442</td>\n",
       "      <td>2.251768</td>\n",
       "      <td>4.507376</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.828009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.197055</td>\n",
       "      <td>2.565944</td>\n",
       "      <td>0.170628</td>\n",
       "      <td>5.858229</td>\n",
       "      <td>5.966919</td>\n",
       "      <td>2.051010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-150</th>\n",
       "      <td>1.662735</td>\n",
       "      <td>2.627787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.978554</td>\n",
       "      <td>1.518716</td>\n",
       "      <td>1.310803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.695080</td>\n",
       "      <td>1.297205</td>\n",
       "      <td>...</td>\n",
       "      <td>2.083632</td>\n",
       "      <td>3.201837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.283232</td>\n",
       "      <td>1.387340</td>\n",
       "      <td>2.151954</td>\n",
       "      <td>5.416370</td>\n",
       "      <td>5.249545</td>\n",
       "      <td>1.339347</td>\n",
       "      <td>-0.391131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-410</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.093395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.773214</td>\n",
       "      <td>2.458220</td>\n",
       "      <td>1.380653</td>\n",
       "      <td>8.197409</td>\n",
       "      <td>3.046256</td>\n",
       "      <td>0.621403</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.081026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.482879</td>\n",
       "      <td>1.946019</td>\n",
       "      <td>1.795210</td>\n",
       "      <td>5.700520</td>\n",
       "      <td>5.564766</td>\n",
       "      <td>3.278807</td>\n",
       "      <td>-0.174263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-450</th>\n",
       "      <td>1.708192</td>\n",
       "      <td>0.730114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.146699</td>\n",
       "      <td>1.843055</td>\n",
       "      <td>1.331103</td>\n",
       "      <td>7.030260</td>\n",
       "      <td>2.186776</td>\n",
       "      <td>-0.228737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675123</td>\n",
       "      <td>1.772179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.815542</td>\n",
       "      <td>1.656379</td>\n",
       "      <td>-0.136961</td>\n",
       "      <td>5.299022</td>\n",
       "      <td>5.415697</td>\n",
       "      <td>1.514705</td>\n",
       "      <td>-0.621766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-510</th>\n",
       "      <td>1.270910</td>\n",
       "      <td>2.959017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.980995</td>\n",
       "      <td>3.945018</td>\n",
       "      <td>1.284461</td>\n",
       "      <td>6.297521</td>\n",
       "      <td>1.638313</td>\n",
       "      <td>0.260998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264821</td>\n",
       "      <td>2.403061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.899052</td>\n",
       "      <td>2.200386</td>\n",
       "      <td>5.009180</td>\n",
       "      <td>4.805710</td>\n",
       "      <td>3.085656</td>\n",
       "      <td>-0.128006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-520</th>\n",
       "      <td>1.835441</td>\n",
       "      <td>5.154131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.950345</td>\n",
       "      <td>1.997504</td>\n",
       "      <td>1.820870</td>\n",
       "      <td>6.140748</td>\n",
       "      <td>2.285687</td>\n",
       "      <td>0.688666</td>\n",
       "      <td>...</td>\n",
       "      <td>2.385181</td>\n",
       "      <td>3.354208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.449447</td>\n",
       "      <td>-0.004960</td>\n",
       "      <td>6.032887</td>\n",
       "      <td>6.198309</td>\n",
       "      <td>2.835614</td>\n",
       "      <td>0.232361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYSE-70</th>\n",
       "      <td>1.779320</td>\n",
       "      <td>4.128157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.569888</td>\n",
       "      <td>2.386466</td>\n",
       "      <td>1.507585</td>\n",
       "      <td>7.971141</td>\n",
       "      <td>2.172689</td>\n",
       "      <td>0.100061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125930</td>\n",
       "      <td>3.255526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.847021</td>\n",
       "      <td>2.251856</td>\n",
       "      <td>5.847354</td>\n",
       "      <td>5.911172</td>\n",
       "      <td>3.101272</td>\n",
       "      <td>-0.147438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME-1</th>\n",
       "      <td>1.098778</td>\n",
       "      <td>4.836776</td>\n",
       "      <td>0.572957</td>\n",
       "      <td>3.598607</td>\n",
       "      <td>5.096781</td>\n",
       "      <td>0.883822</td>\n",
       "      <td>0.494791</td>\n",
       "      <td>5.810898</td>\n",
       "      <td>3.083477</td>\n",
       "      <td>-1.778289</td>\n",
       "      <td>...</td>\n",
       "      <td>4.866752</td>\n",
       "      <td>2.273347</td>\n",
       "      <td>0.429048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.034769</td>\n",
       "      <td>2.430355</td>\n",
       "      <td>5.180761</td>\n",
       "      <td>5.850990</td>\n",
       "      <td>2.577133</td>\n",
       "      <td>0.310728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML-2</th>\n",
       "      <td>-0.147830</td>\n",
       "      <td>1.153389</td>\n",
       "      <td>-1.711145</td>\n",
       "      <td>2.078653</td>\n",
       "      <td>3.513556</td>\n",
       "      <td>0.970969</td>\n",
       "      <td>1.266059</td>\n",
       "      <td>7.958668</td>\n",
       "      <td>1.355464</td>\n",
       "      <td>-1.095968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892247</td>\n",
       "      <td>0.384611</td>\n",
       "      <td>-0.740660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003397</td>\n",
       "      <td>-2.480524</td>\n",
       "      <td>4.633156</td>\n",
       "      <td>5.202085</td>\n",
       "      <td>1.211369</td>\n",
       "      <td>-2.439551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOLM-13</th>\n",
       "      <td>-3.685018</td>\n",
       "      <td>-0.178291</td>\n",
       "      <td>-2.615304</td>\n",
       "      <td>2.030008</td>\n",
       "      <td>5.132200</td>\n",
       "      <td>0.518841</td>\n",
       "      <td>1.718021</td>\n",
       "      <td>5.327248</td>\n",
       "      <td>0.215386</td>\n",
       "      <td>-2.614494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771665</td>\n",
       "      <td>0.939541</td>\n",
       "      <td>-0.009030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.167851</td>\n",
       "      <td>-2.141005</td>\n",
       "      <td>4.537480</td>\n",
       "      <td>5.383184</td>\n",
       "      <td>1.039353</td>\n",
       "      <td>-1.253816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONO-MAC-6</th>\n",
       "      <td>-2.891531</td>\n",
       "      <td>0.740719</td>\n",
       "      <td>-2.173102</td>\n",
       "      <td>3.374556</td>\n",
       "      <td>4.160101</td>\n",
       "      <td>0.867742</td>\n",
       "      <td>0.547786</td>\n",
       "      <td>5.861700</td>\n",
       "      <td>0.174110</td>\n",
       "      <td>-1.762432</td>\n",
       "      <td>...</td>\n",
       "      <td>1.567829</td>\n",
       "      <td>1.183417</td>\n",
       "      <td>0.207210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.552777</td>\n",
       "      <td>-1.172579</td>\n",
       "      <td>5.190366</td>\n",
       "      <td>5.452346</td>\n",
       "      <td>1.128982</td>\n",
       "      <td>-0.802139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV-4-11</th>\n",
       "      <td>-4.520314</td>\n",
       "      <td>0.055194</td>\n",
       "      <td>-3.013774</td>\n",
       "      <td>1.284595</td>\n",
       "      <td>3.105046</td>\n",
       "      <td>-0.475047</td>\n",
       "      <td>1.029561</td>\n",
       "      <td>4.679163</td>\n",
       "      <td>1.032703</td>\n",
       "      <td>-2.222242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314902</td>\n",
       "      <td>2.610276</td>\n",
       "      <td>-0.443039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.223299</td>\n",
       "      <td>-1.499318</td>\n",
       "      <td>4.950923</td>\n",
       "      <td>4.956109</td>\n",
       "      <td>0.053818</td>\n",
       "      <td>-0.549276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB4</th>\n",
       "      <td>-0.626887</td>\n",
       "      <td>0.823964</td>\n",
       "      <td>-0.951512</td>\n",
       "      <td>0.849124</td>\n",
       "      <td>4.197726</td>\n",
       "      <td>-0.538330</td>\n",
       "      <td>0.496776</td>\n",
       "      <td>6.148592</td>\n",
       "      <td>1.520312</td>\n",
       "      <td>-2.885982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861152</td>\n",
       "      <td>0.624432</td>\n",
       "      <td>2.680937</td>\n",
       "      <td>-0.962854</td>\n",
       "      <td>0.458815</td>\n",
       "      <td>-0.806139</td>\n",
       "      <td>4.661872</td>\n",
       "      <td>4.301545</td>\n",
       "      <td>0.870891</td>\n",
       "      <td>-0.944001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOMO-1</th>\n",
       "      <td>-0.207892</td>\n",
       "      <td>-0.133927</td>\n",
       "      <td>-1.210218</td>\n",
       "      <td>2.719749</td>\n",
       "      <td>4.563099</td>\n",
       "      <td>1.197032</td>\n",
       "      <td>1.938176</td>\n",
       "      <td>6.835251</td>\n",
       "      <td>2.356027</td>\n",
       "      <td>-1.554893</td>\n",
       "      <td>...</td>\n",
       "      <td>1.743214</td>\n",
       "      <td>1.720870</td>\n",
       "      <td>1.088031</td>\n",
       "      <td>0.247828</td>\n",
       "      <td>0.343920</td>\n",
       "      <td>-0.191586</td>\n",
       "      <td>5.663278</td>\n",
       "      <td>5.816351</td>\n",
       "      <td>1.299927</td>\n",
       "      <td>-2.055063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI-AML2</th>\n",
       "      <td>-3.554450</td>\n",
       "      <td>-0.617523</td>\n",
       "      <td>-1.977049</td>\n",
       "      <td>1.545620</td>\n",
       "      <td>3.780859</td>\n",
       "      <td>0.161098</td>\n",
       "      <td>0.552603</td>\n",
       "      <td>6.209193</td>\n",
       "      <td>1.873091</td>\n",
       "      <td>-2.108940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848545</td>\n",
       "      <td>1.036759</td>\n",
       "      <td>-0.080890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.393813</td>\n",
       "      <td>1.231421</td>\n",
       "      <td>4.478615</td>\n",
       "      <td>4.228503</td>\n",
       "      <td>0.333252</td>\n",
       "      <td>-1.131128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI-AML3</th>\n",
       "      <td>-1.512964</td>\n",
       "      <td>0.042845</td>\n",
       "      <td>-0.399858</td>\n",
       "      <td>3.854475</td>\n",
       "      <td>4.474187</td>\n",
       "      <td>0.815433</td>\n",
       "      <td>1.550232</td>\n",
       "      <td>6.808567</td>\n",
       "      <td>1.472186</td>\n",
       "      <td>-2.058665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977153</td>\n",
       "      <td>1.114317</td>\n",
       "      <td>0.134430</td>\n",
       "      <td>0.343307</td>\n",
       "      <td>1.272822</td>\n",
       "      <td>-1.368075</td>\n",
       "      <td>5.052712</td>\n",
       "      <td>5.217053</td>\n",
       "      <td>1.920269</td>\n",
       "      <td>-0.615349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI-AML5</th>\n",
       "      <td>-0.286965</td>\n",
       "      <td>0.128529</td>\n",
       "      <td>-1.698830</td>\n",
       "      <td>2.334416</td>\n",
       "      <td>3.940107</td>\n",
       "      <td>0.110020</td>\n",
       "      <td>1.454163</td>\n",
       "      <td>5.017175</td>\n",
       "      <td>0.525827</td>\n",
       "      <td>-2.565078</td>\n",
       "      <td>...</td>\n",
       "      <td>1.478292</td>\n",
       "      <td>1.132325</td>\n",
       "      <td>0.270761</td>\n",
       "      <td>0.321306</td>\n",
       "      <td>0.015744</td>\n",
       "      <td>-1.986312</td>\n",
       "      <td>5.015814</td>\n",
       "      <td>4.881314</td>\n",
       "      <td>1.225742</td>\n",
       "      <td>0.009582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI-M1</th>\n",
       "      <td>1.513660</td>\n",
       "      <td>2.213233</td>\n",
       "      <td>-0.261733</td>\n",
       "      <td>3.211289</td>\n",
       "      <td>4.121579</td>\n",
       "      <td>-0.073912</td>\n",
       "      <td>0.460530</td>\n",
       "      <td>7.964775</td>\n",
       "      <td>1.170130</td>\n",
       "      <td>-2.884648</td>\n",
       "      <td>...</td>\n",
       "      <td>1.223839</td>\n",
       "      <td>1.196009</td>\n",
       "      <td>-0.822345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.697292</td>\n",
       "      <td>-1.831926</td>\n",
       "      <td>4.425442</td>\n",
       "      <td>3.856172</td>\n",
       "      <td>1.636467</td>\n",
       "      <td>-1.514879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OE19</th>\n",
       "      <td>2.485073</td>\n",
       "      <td>5.195470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.992079</td>\n",
       "      <td>1.264268</td>\n",
       "      <td>2.202185</td>\n",
       "      <td>8.100369</td>\n",
       "      <td>3.144271</td>\n",
       "      <td>0.850105</td>\n",
       "      <td>...</td>\n",
       "      <td>2.051739</td>\n",
       "      <td>4.288135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.270485</td>\n",
       "      <td>4.648866</td>\n",
       "      <td>5.914648</td>\n",
       "      <td>5.963273</td>\n",
       "      <td>1.943778</td>\n",
       "      <td>-2.410936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OE33</th>\n",
       "      <td>1.396749</td>\n",
       "      <td>4.369297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.207418</td>\n",
       "      <td>1.910824</td>\n",
       "      <td>1.681424</td>\n",
       "      <td>7.305978</td>\n",
       "      <td>1.827047</td>\n",
       "      <td>-0.176358</td>\n",
       "      <td>...</td>\n",
       "      <td>2.704213</td>\n",
       "      <td>1.041807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.463503</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>5.638868</td>\n",
       "      <td>5.649411</td>\n",
       "      <td>2.329248</td>\n",
       "      <td>-1.887046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P31-FUJ</th>\n",
       "      <td>0.229826</td>\n",
       "      <td>4.115108</td>\n",
       "      <td>1.213700</td>\n",
       "      <td>3.217796</td>\n",
       "      <td>3.207246</td>\n",
       "      <td>2.080727</td>\n",
       "      <td>0.399621</td>\n",
       "      <td>6.628074</td>\n",
       "      <td>3.019493</td>\n",
       "      <td>-0.716139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761211</td>\n",
       "      <td>2.981959</td>\n",
       "      <td>1.904555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094303</td>\n",
       "      <td>2.783472</td>\n",
       "      <td>4.735159</td>\n",
       "      <td>4.852427</td>\n",
       "      <td>2.750824</td>\n",
       "      <td>-0.807437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL-21</th>\n",
       "      <td>0.425766</td>\n",
       "      <td>3.685632</td>\n",
       "      <td>-1.204719</td>\n",
       "      <td>3.663766</td>\n",
       "      <td>5.710606</td>\n",
       "      <td>1.119976</td>\n",
       "      <td>0.706049</td>\n",
       "      <td>6.753968</td>\n",
       "      <td>0.656571</td>\n",
       "      <td>-1.472648</td>\n",
       "      <td>...</td>\n",
       "      <td>1.429011</td>\n",
       "      <td>0.700225</td>\n",
       "      <td>0.758373</td>\n",
       "      <td>0.717630</td>\n",
       "      <td>1.221194</td>\n",
       "      <td>-1.886543</td>\n",
       "      <td>5.303540</td>\n",
       "      <td>5.474018</td>\n",
       "      <td>1.119345</td>\n",
       "      <td>-2.439226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIG-M5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.592577</td>\n",
       "      <td>-2.085567</td>\n",
       "      <td>1.303289</td>\n",
       "      <td>4.273109</td>\n",
       "      <td>-1.209320</td>\n",
       "      <td>0.539180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.435565</td>\n",
       "      <td>-2.619117</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.308939</td>\n",
       "      <td>-0.064120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.024837</td>\n",
       "      <td>4.256892</td>\n",
       "      <td>4.142592</td>\n",
       "      <td>-0.533106</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK-HEP-1</th>\n",
       "      <td>-1.014557</td>\n",
       "      <td>4.298647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.482910</td>\n",
       "      <td>3.135137</td>\n",
       "      <td>1.298728</td>\n",
       "      <td>7.390019</td>\n",
       "      <td>3.630528</td>\n",
       "      <td>-0.179036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512288</td>\n",
       "      <td>3.015056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.337170</td>\n",
       "      <td>4.092128</td>\n",
       "      <td>5.296785</td>\n",
       "      <td>5.310708</td>\n",
       "      <td>5.022002</td>\n",
       "      <td>-0.804948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKM-1</th>\n",
       "      <td>-1.960804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.497665</td>\n",
       "      <td>4.285884</td>\n",
       "      <td>4.816697</td>\n",
       "      <td>0.345486</td>\n",
       "      <td>1.857478</td>\n",
       "      <td>5.496339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.214227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.704731</td>\n",
       "      <td>0.326674</td>\n",
       "      <td>0.456698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.555885</td>\n",
       "      <td>1.333064</td>\n",
       "      <td>-0.571629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-182</th>\n",
       "      <td>0.558635</td>\n",
       "      <td>4.771461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.123074</td>\n",
       "      <td>1.565718</td>\n",
       "      <td>1.045564</td>\n",
       "      <td>7.561514</td>\n",
       "      <td>1.165819</td>\n",
       "      <td>-0.682361</td>\n",
       "      <td>...</td>\n",
       "      <td>1.778595</td>\n",
       "      <td>1.573550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.696012</td>\n",
       "      <td>-0.592782</td>\n",
       "      <td>5.532561</td>\n",
       "      <td>5.564559</td>\n",
       "      <td>2.360475</td>\n",
       "      <td>-0.617152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-387</th>\n",
       "      <td>1.898865</td>\n",
       "      <td>4.745748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.904071</td>\n",
       "      <td>1.125645</td>\n",
       "      <td>1.408825</td>\n",
       "      <td>8.413742</td>\n",
       "      <td>1.011214</td>\n",
       "      <td>-1.291804</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.384474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039362</td>\n",
       "      <td>3.372431</td>\n",
       "      <td>-0.723640</td>\n",
       "      <td>5.300638</td>\n",
       "      <td>5.744224</td>\n",
       "      <td>2.413022</td>\n",
       "      <td>-0.409098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-398</th>\n",
       "      <td>0.756616</td>\n",
       "      <td>2.657825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.265582</td>\n",
       "      <td>1.200988</td>\n",
       "      <td>1.366873</td>\n",
       "      <td>7.987582</td>\n",
       "      <td>1.777641</td>\n",
       "      <td>-0.556041</td>\n",
       "      <td>...</td>\n",
       "      <td>1.302611</td>\n",
       "      <td>0.541763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.966425</td>\n",
       "      <td>0.842154</td>\n",
       "      <td>5.015216</td>\n",
       "      <td>5.679248</td>\n",
       "      <td>1.402331</td>\n",
       "      <td>0.017235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-423</th>\n",
       "      <td>0.833294</td>\n",
       "      <td>2.193720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.723180</td>\n",
       "      <td>0.937943</td>\n",
       "      <td>1.741820</td>\n",
       "      <td>7.346311</td>\n",
       "      <td>1.380679</td>\n",
       "      <td>-1.106258</td>\n",
       "      <td>...</td>\n",
       "      <td>1.876159</td>\n",
       "      <td>2.568184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.525796</td>\n",
       "      <td>-1.210798</td>\n",
       "      <td>5.632841</td>\n",
       "      <td>5.677142</td>\n",
       "      <td>1.776408</td>\n",
       "      <td>0.201070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-449</th>\n",
       "      <td>1.252843</td>\n",
       "      <td>4.319306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.527701</td>\n",
       "      <td>3.033277</td>\n",
       "      <td>0.993495</td>\n",
       "      <td>8.215106</td>\n",
       "      <td>2.529572</td>\n",
       "      <td>0.823246</td>\n",
       "      <td>...</td>\n",
       "      <td>2.491209</td>\n",
       "      <td>2.782259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.795701</td>\n",
       "      <td>0.154287</td>\n",
       "      <td>5.804827</td>\n",
       "      <td>5.873908</td>\n",
       "      <td>2.681372</td>\n",
       "      <td>0.431085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-475</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.208757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.818451</td>\n",
       "      <td>1.018091</td>\n",
       "      <td>1.368863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.142099</td>\n",
       "      <td>-0.311237</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.563437</td>\n",
       "      <td>4.935431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.846582</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THP-1</th>\n",
       "      <td>2.397202</td>\n",
       "      <td>1.535533</td>\n",
       "      <td>1.257552</td>\n",
       "      <td>3.740002</td>\n",
       "      <td>5.111370</td>\n",
       "      <td>0.326588</td>\n",
       "      <td>0.522423</td>\n",
       "      <td>7.791265</td>\n",
       "      <td>1.890664</td>\n",
       "      <td>-1.964665</td>\n",
       "      <td>...</td>\n",
       "      <td>2.686216</td>\n",
       "      <td>1.571492</td>\n",
       "      <td>1.393290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.638836</td>\n",
       "      <td>0.299794</td>\n",
       "      <td>4.874206</td>\n",
       "      <td>4.883863</td>\n",
       "      <td>1.350108</td>\n",
       "      <td>-0.430828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "DRUG_NAME   (5Z)-7-Oxozeaenol  5-Fluorouracil  A-443654  A-770041   A-83-01  \\\n",
       "CMK                  0.533605        1.356067 -1.225855  3.423778  4.279684   \n",
       "COLO-680N            1.729743        5.825205       NaN       NaN  2.311197   \n",
       "GDM-1               -0.523250        0.919553 -0.689946  3.007763  3.101210   \n",
       "HEL                  0.948509        0.096313 -0.847805  2.509067  4.442955   \n",
       "HL-60                1.426720        1.847379  0.275800  2.246344  4.317315   \n",
       "JHH-2                1.250863        2.805717       NaN       NaN  4.809860   \n",
       "JHH-4                1.728183        3.831835       NaN       NaN  3.052734   \n",
       "KASUMI-1            -1.027736             NaN  1.660142  3.912199       NaN   \n",
       "KG-1                -0.741724        3.220940  1.197924  3.882495  2.205678   \n",
       "KMOE-2              -1.408182        1.864702 -0.767405  3.672939  4.940030   \n",
       "KYSE-140                  NaN        6.331959       NaN       NaN  3.150266   \n",
       "KYSE-150             1.662735        2.627787       NaN       NaN  2.978554   \n",
       "KYSE-410                  NaN        3.093395       NaN       NaN  3.773214   \n",
       "KYSE-450             1.708192        0.730114       NaN       NaN  3.146699   \n",
       "KYSE-510             1.270910        2.959017       NaN       NaN  2.980995   \n",
       "KYSE-520             1.835441        5.154131       NaN       NaN  4.950345   \n",
       "KYSE-70              1.779320        4.128157       NaN       NaN  3.569888   \n",
       "ME-1                 1.098778        4.836776  0.572957  3.598607  5.096781   \n",
       "ML-2                -0.147830        1.153389 -1.711145  2.078653  3.513556   \n",
       "MOLM-13             -3.685018       -0.178291 -2.615304  2.030008  5.132200   \n",
       "MONO-MAC-6          -2.891531        0.740719 -2.173102  3.374556  4.160101   \n",
       "MV-4-11             -4.520314        0.055194 -3.013774  1.284595  3.105046   \n",
       "NB4                 -0.626887        0.823964 -0.951512  0.849124  4.197726   \n",
       "NOMO-1              -0.207892       -0.133927 -1.210218  2.719749  4.563099   \n",
       "OCI-AML2            -3.554450       -0.617523 -1.977049  1.545620  3.780859   \n",
       "OCI-AML3            -1.512964        0.042845 -0.399858  3.854475  4.474187   \n",
       "OCI-AML5            -0.286965        0.128529 -1.698830  2.334416  3.940107   \n",
       "OCI-M1               1.513660        2.213233 -0.261733  3.211289  4.121579   \n",
       "OE19                 2.485073        5.195470       NaN       NaN  3.992079   \n",
       "OE33                 1.396749        4.369297       NaN       NaN  5.207418   \n",
       "P31-FUJ              0.229826        4.115108  1.213700  3.217796  3.207246   \n",
       "PL-21                0.425766        3.685632 -1.204719  3.663766  5.710606   \n",
       "SIG-M5                    NaN       -1.592577 -2.085567  1.303289  4.273109   \n",
       "SK-HEP-1            -1.014557        4.298647       NaN       NaN  4.482910   \n",
       "SKM-1               -1.960804             NaN  1.497665  4.285884  4.816697   \n",
       "SNU-182              0.558635        4.771461       NaN       NaN  4.123074   \n",
       "SNU-387              1.898865        4.745748       NaN       NaN  5.904071   \n",
       "SNU-398              0.756616        2.657825       NaN       NaN  4.265582   \n",
       "SNU-423              0.833294        2.193720       NaN       NaN  4.723180   \n",
       "SNU-449              1.252843        4.319306       NaN       NaN  4.527701   \n",
       "SNU-475                   NaN        3.208757       NaN       NaN  3.818451   \n",
       "THP-1                2.397202        1.535533  1.257552  3.740002  5.111370   \n",
       "\n",
       "DRUG_NAME   ACY-1215  AGI-6780  AICA Ribonucleotide  AKT inhibitor VIII  \\\n",
       "CMK         0.445262  0.883803             7.306995            1.628922   \n",
       "COLO-680N   1.541306  1.857318             7.779938            3.089514   \n",
       "GDM-1       0.299259  1.086986             6.873515            0.480957   \n",
       "HEL         0.781370  1.223233             6.679720            2.108089   \n",
       "HL-60       0.584272  0.977314             5.779418            2.343589   \n",
       "JHH-2       1.352882  1.928683             8.068791            3.800954   \n",
       "JHH-4       1.682833  1.190176             8.236501            0.179473   \n",
       "KASUMI-1         NaN       NaN             5.942764           -0.691354   \n",
       "KG-1        0.880823  1.062529             5.729228            2.041374   \n",
       "KMOE-2      0.952982  0.825652             5.761281            1.074860   \n",
       "KYSE-140    1.761124  0.803499             7.426442            2.251768   \n",
       "KYSE-150    1.518716  1.310803                  NaN            2.695080   \n",
       "KYSE-410    2.458220  1.380653             8.197409            3.046256   \n",
       "KYSE-450    1.843055  1.331103             7.030260            2.186776   \n",
       "KYSE-510    3.945018  1.284461             6.297521            1.638313   \n",
       "KYSE-520    1.997504  1.820870             6.140748            2.285687   \n",
       "KYSE-70     2.386466  1.507585             7.971141            2.172689   \n",
       "ME-1        0.883822  0.494791             5.810898            3.083477   \n",
       "ML-2        0.970969  1.266059             7.958668            1.355464   \n",
       "MOLM-13     0.518841  1.718021             5.327248            0.215386   \n",
       "MONO-MAC-6  0.867742  0.547786             5.861700            0.174110   \n",
       "MV-4-11    -0.475047  1.029561             4.679163            1.032703   \n",
       "NB4        -0.538330  0.496776             6.148592            1.520312   \n",
       "NOMO-1      1.197032  1.938176             6.835251            2.356027   \n",
       "OCI-AML2    0.161098  0.552603             6.209193            1.873091   \n",
       "OCI-AML3    0.815433  1.550232             6.808567            1.472186   \n",
       "OCI-AML5    0.110020  1.454163             5.017175            0.525827   \n",
       "OCI-M1     -0.073912  0.460530             7.964775            1.170130   \n",
       "OE19        1.264268  2.202185             8.100369            3.144271   \n",
       "OE33        1.910824  1.681424             7.305978            1.827047   \n",
       "P31-FUJ     2.080727  0.399621             6.628074            3.019493   \n",
       "PL-21       1.119976  0.706049             6.753968            0.656571   \n",
       "SIG-M5     -1.209320  0.539180                  NaN            0.435565   \n",
       "SK-HEP-1    3.135137  1.298728             7.390019            3.630528   \n",
       "SKM-1       0.345486  1.857478             5.496339                 NaN   \n",
       "SNU-182     1.565718  1.045564             7.561514            1.165819   \n",
       "SNU-387     1.125645  1.408825             8.413742            1.011214   \n",
       "SNU-398     1.200988  1.366873             7.987582            1.777641   \n",
       "SNU-423     0.937943  1.741820             7.346311            1.380679   \n",
       "SNU-449     3.033277  0.993495             8.215106            2.529572   \n",
       "SNU-475     1.018091  1.368863                  NaN            2.142099   \n",
       "THP-1       0.326588  0.522423             7.791265            1.890664   \n",
       "\n",
       "DRUG_NAME      AR-42  ...  YK-4-279  YM201636  Z-LLNle-CHO     ZG-10  \\\n",
       "CMK        -2.703728  ...  0.711090  1.010783    -0.168536       NaN   \n",
       "COLO-680N   4.383391  ...  2.914492  4.505976          NaN       NaN   \n",
       "GDM-1      -2.204147  ...  1.159891  0.016884     0.785866       NaN   \n",
       "HEL        -2.640470  ...  1.243856  1.034155    -0.259764       NaN   \n",
       "HL-60      -2.105449  ...  1.936856  2.055140     0.738669       NaN   \n",
       "JHH-2      -0.538916  ...  1.615375  3.477278          NaN       NaN   \n",
       "JHH-4      -1.997605  ...  0.555819  1.577455          NaN       NaN   \n",
       "KASUMI-1         NaN  ...  1.010631       NaN     1.495208       NaN   \n",
       "KG-1       -2.120892  ...  0.388608  0.935345     1.712625       NaN   \n",
       "KMOE-2     -2.008743  ... -0.063605  0.156328     0.065058       NaN   \n",
       "KYSE-140    4.507376  ...       NaN  1.828009          NaN  1.197055   \n",
       "KYSE-150    1.297205  ...  2.083632  3.201837          NaN  2.283232   \n",
       "KYSE-410    0.621403  ...       NaN  3.081026          NaN  1.482879   \n",
       "KYSE-450   -0.228737  ...  0.675123  1.772179          NaN  0.815542   \n",
       "KYSE-510    0.260998  ...  0.264821  2.403061          NaN       NaN   \n",
       "KYSE-520    0.688666  ...  2.385181  3.354208          NaN       NaN   \n",
       "KYSE-70     0.100061  ...  0.125930  3.255526          NaN       NaN   \n",
       "ME-1       -1.778289  ...  4.866752  2.273347     0.429048       NaN   \n",
       "ML-2       -1.095968  ...  0.892247  0.384611    -0.740660       NaN   \n",
       "MOLM-13    -2.614494  ...  0.771665  0.939541    -0.009030       NaN   \n",
       "MONO-MAC-6 -1.762432  ...  1.567829  1.183417     0.207210       NaN   \n",
       "MV-4-11    -2.222242  ...  0.314902  2.610276    -0.443039       NaN   \n",
       "NB4        -2.885982  ... -0.861152  0.624432     2.680937 -0.962854   \n",
       "NOMO-1     -1.554893  ...  1.743214  1.720870     1.088031  0.247828   \n",
       "OCI-AML2   -2.108940  ...  0.848545  1.036759    -0.080890       NaN   \n",
       "OCI-AML3   -2.058665  ...  0.977153  1.114317     0.134430  0.343307   \n",
       "OCI-AML5   -2.565078  ...  1.478292  1.132325     0.270761  0.321306   \n",
       "OCI-M1     -2.884648  ...  1.223839  1.196009    -0.822345       NaN   \n",
       "OE19        0.850105  ...  2.051739  4.288135          NaN       NaN   \n",
       "OE33       -0.176358  ...  2.704213  1.041807          NaN       NaN   \n",
       "P31-FUJ    -0.716139  ...  0.761211  2.981959     1.904555       NaN   \n",
       "PL-21      -1.472648  ...  1.429011  0.700225     0.758373  0.717630   \n",
       "SIG-M5     -2.619117  ...       NaN -0.308939    -0.064120       NaN   \n",
       "SK-HEP-1   -0.179036  ...  0.512288  3.015056          NaN       NaN   \n",
       "SKM-1            NaN  ...  1.214227       NaN     2.704731  0.326674   \n",
       "SNU-182    -0.682361  ...  1.778595  1.573550          NaN       NaN   \n",
       "SNU-387    -1.291804  ...       NaN  2.384474          NaN  1.039362   \n",
       "SNU-398    -0.556041  ...  1.302611  0.541763          NaN       NaN   \n",
       "SNU-423    -1.106258  ...  1.876159  2.568184          NaN       NaN   \n",
       "SNU-449     0.823246  ...  2.491209  2.782259          NaN       NaN   \n",
       "SNU-475    -0.311237  ...       NaN  0.515342          NaN       NaN   \n",
       "THP-1      -1.964665  ...  2.686216  1.571492     1.393290       NaN   \n",
       "\n",
       "DRUG_NAME   ZM447439   ZSTK474  Zibotentan  eEF2K Inhibitor, A-484954  \\\n",
       "CMK         2.327991 -1.569145    4.348476                   4.607164   \n",
       "COLO-680N   2.786317  2.637072    5.998495                   6.098361   \n",
       "GDM-1       3.944803 -2.732485    4.779900                   4.951323   \n",
       "HEL         1.877772  0.437604    4.329365                   4.893941   \n",
       "HL-60       0.933645 -0.935734    5.244023                   5.293992   \n",
       "JHH-2       3.867514  2.235465    5.593274                   5.498093   \n",
       "JHH-4       2.356895  0.038652    5.468000                   5.148859   \n",
       "KASUMI-1         NaN -3.322155         NaN                        NaN   \n",
       "KG-1        1.642640  0.480226    5.296632                   4.591654   \n",
       "KMOE-2      1.380753  0.057000    5.551606                   5.178670   \n",
       "KYSE-140    2.565944  0.170628    5.858229                   5.966919   \n",
       "KYSE-150    1.387340  2.151954    5.416370                   5.249545   \n",
       "KYSE-410    1.946019  1.795210    5.700520                   5.564766   \n",
       "KYSE-450    1.656379 -0.136961    5.299022                   5.415697   \n",
       "KYSE-510    0.899052  2.200386    5.009180                   4.805710   \n",
       "KYSE-520    3.449447 -0.004960    6.032887                   6.198309   \n",
       "KYSE-70     3.847021  2.251856    5.847354                   5.911172   \n",
       "ME-1        4.034769  2.430355    5.180761                   5.850990   \n",
       "ML-2        1.003397 -2.480524    4.633156                   5.202085   \n",
       "MOLM-13    -0.167851 -2.141005    4.537480                   5.383184   \n",
       "MONO-MAC-6  1.552777 -1.172579    5.190366                   5.452346   \n",
       "MV-4-11    -0.223299 -1.499318    4.950923                   4.956109   \n",
       "NB4         0.458815 -0.806139    4.661872                   4.301545   \n",
       "NOMO-1      0.343920 -0.191586    5.663278                   5.816351   \n",
       "OCI-AML2    1.393813  1.231421    4.478615                   4.228503   \n",
       "OCI-AML3    1.272822 -1.368075    5.052712                   5.217053   \n",
       "OCI-AML5    0.015744 -1.986312    5.015814                   4.881314   \n",
       "OCI-M1      2.697292 -1.831926    4.425442                   3.856172   \n",
       "OE19        2.270485  4.648866    5.914648                   5.963273   \n",
       "OE33        3.463503  0.825806    5.638868                   5.649411   \n",
       "P31-FUJ     0.094303  2.783472    4.735159                   4.852427   \n",
       "PL-21       1.221194 -1.886543    5.303540                   5.474018   \n",
       "SIG-M5           NaN -4.024837    4.256892                   4.142592   \n",
       "SK-HEP-1    1.337170  4.092128    5.296785                   5.310708   \n",
       "SKM-1       0.456698       NaN         NaN                   5.555885   \n",
       "SNU-182     1.696012 -0.592782    5.532561                   5.564559   \n",
       "SNU-387     3.372431 -0.723640    5.300638                   5.744224   \n",
       "SNU-398     1.966425  0.842154    5.015216                   5.679248   \n",
       "SNU-423     3.525796 -1.210798    5.632841                   5.677142   \n",
       "SNU-449     3.795701  0.154287    5.804827                   5.873908   \n",
       "SNU-475          NaN  1.563437    4.935431                        NaN   \n",
       "THP-1       3.638836  0.299794    4.874206                   4.883863   \n",
       "\n",
       "DRUG_NAME   kb NB 142-70    rTRAIL  \n",
       "CMK             1.816375 -0.475125  \n",
       "COLO-680N       2.709776  0.660982  \n",
       "GDM-1           1.217470 -1.530039  \n",
       "HEL             2.141834 -2.435046  \n",
       "HL-60           1.350463 -0.662189  \n",
       "JHH-2           1.677161 -0.590448  \n",
       "JHH-4           2.785413 -4.329280  \n",
       "KASUMI-1             NaN -1.806383  \n",
       "KG-1            1.126185 -0.319311  \n",
       "KMOE-2          2.245417 -0.429986  \n",
       "KYSE-140        2.051010       NaN  \n",
       "KYSE-150        1.339347 -0.391131  \n",
       "KYSE-410        3.278807 -0.174263  \n",
       "KYSE-450        1.514705 -0.621766  \n",
       "KYSE-510        3.085656 -0.128006  \n",
       "KYSE-520        2.835614  0.232361  \n",
       "KYSE-70         3.101272 -0.147438  \n",
       "ME-1            2.577133  0.310728  \n",
       "ML-2            1.211369 -2.439551  \n",
       "MOLM-13         1.039353 -1.253816  \n",
       "MONO-MAC-6      1.128982 -0.802139  \n",
       "MV-4-11         0.053818 -0.549276  \n",
       "NB4             0.870891 -0.944001  \n",
       "NOMO-1          1.299927 -2.055063  \n",
       "OCI-AML2        0.333252 -1.131128  \n",
       "OCI-AML3        1.920269 -0.615349  \n",
       "OCI-AML5        1.225742  0.009582  \n",
       "OCI-M1          1.636467 -1.514879  \n",
       "OE19            1.943778 -2.410936  \n",
       "OE33            2.329248 -1.887046  \n",
       "P31-FUJ         2.750824 -0.807437  \n",
       "PL-21           1.119345 -2.439226  \n",
       "SIG-M5         -0.533106       NaN  \n",
       "SK-HEP-1        5.022002 -0.804948  \n",
       "SKM-1           1.333064 -0.571629  \n",
       "SNU-182         2.360475 -0.617152  \n",
       "SNU-387         2.413022 -0.409098  \n",
       "SNU-398         1.402331  0.017235  \n",
       "SNU-423         1.776408  0.201070  \n",
       "SNU-449         2.681372  0.431085  \n",
       "SNU-475         1.846582       NaN  \n",
       "THP-1           1.350108 -0.430828  \n",
       "\n",
       "[42 rows x 345 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The above shows the phos data has 42 rows and 22804 columns. Thus, it gives the expression values for 42 cell lines for 22804 phosphopeptide. \n",
    "\n",
    "The y data gives the IC50 values for the 42 cell lines in the phos treated with 345 different drugs \n",
    "\n",
    "The input we want for drug response prediction is drug cell line pairs because we want to predict the efficacy of a given drug for a given cell. Therefore, the next step is to use the df we have to create inputs for all drug cell line pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for all drugs\n",
    "x_all_phos, x_drug, y_list = utils.create_all_drugs(\n",
    "    data.phos, data.marker_drugs, data.y_df)\n",
    "\n",
    "x_all_phos = x_all_phos.astype(np.float32)\n",
    "x_drug = x_drug.astype(np.float32)\n",
    "y_list = y_list.astype(np.float32)\n",
    "pairs_with_truth_vals = y_list.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col.name</th>\n",
       "      <th>KDM1A(S45);</th>\n",
       "      <th>KDM1A(T19);</th>\n",
       "      <th>ZFP91(S69);</th>\n",
       "      <th>INCENP(T150);</th>\n",
       "      <th>INCENP(T153);</th>\n",
       "      <th>INCENP(T153);INCENP(T135);</th>\n",
       "      <th>INCENP(M136);INCENP(T145);INCENP(S148);</th>\n",
       "      <th>EIF3J(S11);EIF3J(S13);</th>\n",
       "      <th>POLE4(S9);</th>\n",
       "      <th>SAMD1(T157);</th>\n",
       "      <th>...</th>\n",
       "      <th>CTDP1(T340);</th>\n",
       "      <th>EPS8L2(T572);</th>\n",
       "      <th>BEGAIN(S455);</th>\n",
       "      <th>HNRNPL(S52);</th>\n",
       "      <th>GMDS(T327);</th>\n",
       "      <th>BOD1L1(S482);BOD1L1(S484);</th>\n",
       "      <th>ARHGEF35(T193);</th>\n",
       "      <th>ARHGEF5(S184);</th>\n",
       "      <th>PSMB2(T148);</th>\n",
       "      <th>HSP90AA1(S476);</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CMK::(5Z)-7-Oxozeaenol</th>\n",
       "      <td>-9.751659</td>\n",
       "      <td>-9.751659</td>\n",
       "      <td>6.298313</td>\n",
       "      <td>3.897353</td>\n",
       "      <td>6.801432</td>\n",
       "      <td>6.270551</td>\n",
       "      <td>0.925999</td>\n",
       "      <td>2.077243</td>\n",
       "      <td>-9.751659</td>\n",
       "      <td>8.603255</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.751659</td>\n",
       "      <td>-8.751659</td>\n",
       "      <td>4.683472</td>\n",
       "      <td>4.285402</td>\n",
       "      <td>-9.751659</td>\n",
       "      <td>-0.388355</td>\n",
       "      <td>-9.751659</td>\n",
       "      <td>-9.751659</td>\n",
       "      <td>0.575312</td>\n",
       "      <td>1.627607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLO-680N::(5Z)-7-Oxozeaenol</th>\n",
       "      <td>-9.158429</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>4.479295</td>\n",
       "      <td>5.005041</td>\n",
       "      <td>6.620465</td>\n",
       "      <td>5.830401</td>\n",
       "      <td>0.765535</td>\n",
       "      <td>0.487229</td>\n",
       "      <td>-0.349235</td>\n",
       "      <td>7.013462</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>7.549977</td>\n",
       "      <td>5.488547</td>\n",
       "      <td>4.649615</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>-9.158429</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>1.263034</td>\n",
       "      <td>-2.403542</td>\n",
       "      <td>3.378512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GDM-1::(5Z)-7-Oxozeaenol</th>\n",
       "      <td>-9.522178</td>\n",
       "      <td>-9.522178</td>\n",
       "      <td>2.807355</td>\n",
       "      <td>4.263786</td>\n",
       "      <td>6.313452</td>\n",
       "      <td>5.388925</td>\n",
       "      <td>0.356144</td>\n",
       "      <td>1.062812</td>\n",
       "      <td>3.184280</td>\n",
       "      <td>8.247928</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.522178</td>\n",
       "      <td>-8.522178</td>\n",
       "      <td>7.215485</td>\n",
       "      <td>4.935460</td>\n",
       "      <td>-0.954557</td>\n",
       "      <td>-0.948976</td>\n",
       "      <td>-9.522178</td>\n",
       "      <td>-9.522178</td>\n",
       "      <td>1.952334</td>\n",
       "      <td>3.320485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEL::(5Z)-7-Oxozeaenol</th>\n",
       "      <td>-11.117787</td>\n",
       "      <td>0.641546</td>\n",
       "      <td>3.539779</td>\n",
       "      <td>3.805292</td>\n",
       "      <td>6.411765</td>\n",
       "      <td>5.724104</td>\n",
       "      <td>-11.117787</td>\n",
       "      <td>1.891419</td>\n",
       "      <td>-11.117787</td>\n",
       "      <td>8.733355</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.117787</td>\n",
       "      <td>0.333939</td>\n",
       "      <td>3.135535</td>\n",
       "      <td>4.209454</td>\n",
       "      <td>-1.577767</td>\n",
       "      <td>-11.117787</td>\n",
       "      <td>-11.117787</td>\n",
       "      <td>-11.117787</td>\n",
       "      <td>0.389567</td>\n",
       "      <td>3.279471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HL-60::(5Z)-7-Oxozeaenol</th>\n",
       "      <td>-11.200250</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>5.420314</td>\n",
       "      <td>3.594548</td>\n",
       "      <td>4.385697</td>\n",
       "      <td>4.070426</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>4.852998</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>5.044394</td>\n",
       "      <td>...</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>-10.200250</td>\n",
       "      <td>7.209457</td>\n",
       "      <td>4.678072</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>-11.200250</td>\n",
       "      <td>-2.011588</td>\n",
       "      <td>2.536053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-387::rTRAIL</th>\n",
       "      <td>-9.142035</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>3.607153</td>\n",
       "      <td>4.711592</td>\n",
       "      <td>5.925401</td>\n",
       "      <td>4.632371</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>-8.142035</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>6.383704</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>4.783980</td>\n",
       "      <td>6.199476</td>\n",
       "      <td>2.046142</td>\n",
       "      <td>3.837943</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>1.007195</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>-9.142035</td>\n",
       "      <td>3.632268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-398::rTRAIL</th>\n",
       "      <td>2.403268</td>\n",
       "      <td>1.713696</td>\n",
       "      <td>0.380585</td>\n",
       "      <td>4.009156</td>\n",
       "      <td>5.612441</td>\n",
       "      <td>4.875288</td>\n",
       "      <td>-9.062746</td>\n",
       "      <td>-8.062746</td>\n",
       "      <td>3.963474</td>\n",
       "      <td>8.393176</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.062746</td>\n",
       "      <td>6.139551</td>\n",
       "      <td>-8.062746</td>\n",
       "      <td>4.145678</td>\n",
       "      <td>-9.062746</td>\n",
       "      <td>-9.062746</td>\n",
       "      <td>0.863938</td>\n",
       "      <td>-9.062746</td>\n",
       "      <td>1.070389</td>\n",
       "      <td>2.653060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-423::rTRAIL</th>\n",
       "      <td>1.769772</td>\n",
       "      <td>0.790772</td>\n",
       "      <td>5.873050</td>\n",
       "      <td>4.087645</td>\n",
       "      <td>5.582560</td>\n",
       "      <td>4.832998</td>\n",
       "      <td>-1.123434</td>\n",
       "      <td>-7.868174</td>\n",
       "      <td>2.295723</td>\n",
       "      <td>8.499846</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.868174</td>\n",
       "      <td>8.450386</td>\n",
       "      <td>0.772308</td>\n",
       "      <td>4.017922</td>\n",
       "      <td>0.782409</td>\n",
       "      <td>-8.868174</td>\n",
       "      <td>4.217231</td>\n",
       "      <td>-8.868174</td>\n",
       "      <td>-8.868174</td>\n",
       "      <td>3.733354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNU-449::rTRAIL</th>\n",
       "      <td>-10.361713</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>-0.144010</td>\n",
       "      <td>5.004951</td>\n",
       "      <td>5.659725</td>\n",
       "      <td>4.160275</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>-9.361713</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>6.797013</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>7.923625</td>\n",
       "      <td>6.591290</td>\n",
       "      <td>3.572890</td>\n",
       "      <td>4.385431</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>1.744161</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>-10.361713</td>\n",
       "      <td>4.472488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THP-1::rTRAIL</th>\n",
       "      <td>3.560715</td>\n",
       "      <td>-12.012706</td>\n",
       "      <td>5.699885</td>\n",
       "      <td>4.348374</td>\n",
       "      <td>6.466468</td>\n",
       "      <td>5.350506</td>\n",
       "      <td>-12.012706</td>\n",
       "      <td>1.406124</td>\n",
       "      <td>3.523562</td>\n",
       "      <td>7.360188</td>\n",
       "      <td>...</td>\n",
       "      <td>3.158660</td>\n",
       "      <td>1.170080</td>\n",
       "      <td>2.313246</td>\n",
       "      <td>1.757023</td>\n",
       "      <td>-12.012706</td>\n",
       "      <td>-12.012706</td>\n",
       "      <td>-12.012706</td>\n",
       "      <td>-12.012706</td>\n",
       "      <td>-12.012706</td>\n",
       "      <td>1.646163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12903 rows × 22804 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col.name                      KDM1A(S45);  KDM1A(T19);  ZFP91(S69);  \\\n",
       "CMK::(5Z)-7-Oxozeaenol          -9.751659    -9.751659     6.298313   \n",
       "COLO-680N::(5Z)-7-Oxozeaenol    -9.158429    -9.158429     4.479295   \n",
       "GDM-1::(5Z)-7-Oxozeaenol        -9.522178    -9.522178     2.807355   \n",
       "HEL::(5Z)-7-Oxozeaenol         -11.117787     0.641546     3.539779   \n",
       "HL-60::(5Z)-7-Oxozeaenol       -11.200250   -11.200250     5.420314   \n",
       "...                                   ...          ...          ...   \n",
       "SNU-387::rTRAIL                 -9.142035    -9.142035     3.607153   \n",
       "SNU-398::rTRAIL                  2.403268     1.713696     0.380585   \n",
       "SNU-423::rTRAIL                  1.769772     0.790772     5.873050   \n",
       "SNU-449::rTRAIL                -10.361713   -10.361713    -0.144010   \n",
       "THP-1::rTRAIL                    3.560715   -12.012706     5.699885   \n",
       "\n",
       "col.name                      INCENP(T150);  INCENP(T153);  \\\n",
       "CMK::(5Z)-7-Oxozeaenol             3.897353       6.801432   \n",
       "COLO-680N::(5Z)-7-Oxozeaenol       5.005041       6.620465   \n",
       "GDM-1::(5Z)-7-Oxozeaenol           4.263786       6.313452   \n",
       "HEL::(5Z)-7-Oxozeaenol             3.805292       6.411765   \n",
       "HL-60::(5Z)-7-Oxozeaenol           3.594548       4.385697   \n",
       "...                                     ...            ...   \n",
       "SNU-387::rTRAIL                    4.711592       5.925401   \n",
       "SNU-398::rTRAIL                    4.009156       5.612441   \n",
       "SNU-423::rTRAIL                    4.087645       5.582560   \n",
       "SNU-449::rTRAIL                    5.004951       5.659725   \n",
       "THP-1::rTRAIL                      4.348374       6.466468   \n",
       "\n",
       "col.name                      INCENP(T153);INCENP(T135);  \\\n",
       "CMK::(5Z)-7-Oxozeaenol                          6.270551   \n",
       "COLO-680N::(5Z)-7-Oxozeaenol                    5.830401   \n",
       "GDM-1::(5Z)-7-Oxozeaenol                        5.388925   \n",
       "HEL::(5Z)-7-Oxozeaenol                          5.724104   \n",
       "HL-60::(5Z)-7-Oxozeaenol                        4.070426   \n",
       "...                                                  ...   \n",
       "SNU-387::rTRAIL                                 4.632371   \n",
       "SNU-398::rTRAIL                                 4.875288   \n",
       "SNU-423::rTRAIL                                 4.832998   \n",
       "SNU-449::rTRAIL                                 4.160275   \n",
       "THP-1::rTRAIL                                   5.350506   \n",
       "\n",
       "col.name                      INCENP(M136);INCENP(T145);INCENP(S148);  \\\n",
       "CMK::(5Z)-7-Oxozeaenol                                       0.925999   \n",
       "COLO-680N::(5Z)-7-Oxozeaenol                                 0.765535   \n",
       "GDM-1::(5Z)-7-Oxozeaenol                                     0.356144   \n",
       "HEL::(5Z)-7-Oxozeaenol                                     -11.117787   \n",
       "HL-60::(5Z)-7-Oxozeaenol                                   -11.200250   \n",
       "...                                                               ...   \n",
       "SNU-387::rTRAIL                                             -9.142035   \n",
       "SNU-398::rTRAIL                                             -9.062746   \n",
       "SNU-423::rTRAIL                                             -1.123434   \n",
       "SNU-449::rTRAIL                                            -10.361713   \n",
       "THP-1::rTRAIL                                              -12.012706   \n",
       "\n",
       "col.name                      EIF3J(S11);EIF3J(S13);  POLE4(S9);  \\\n",
       "CMK::(5Z)-7-Oxozeaenol                      2.077243   -9.751659   \n",
       "COLO-680N::(5Z)-7-Oxozeaenol                0.487229   -0.349235   \n",
       "GDM-1::(5Z)-7-Oxozeaenol                    1.062812    3.184280   \n",
       "HEL::(5Z)-7-Oxozeaenol                      1.891419  -11.117787   \n",
       "HL-60::(5Z)-7-Oxozeaenol                    4.852998  -11.200250   \n",
       "...                                              ...         ...   \n",
       "SNU-387::rTRAIL                            -8.142035   -9.142035   \n",
       "SNU-398::rTRAIL                            -8.062746    3.963474   \n",
       "SNU-423::rTRAIL                            -7.868174    2.295723   \n",
       "SNU-449::rTRAIL                            -9.361713  -10.361713   \n",
       "THP-1::rTRAIL                               1.406124    3.523562   \n",
       "\n",
       "col.name                      SAMD1(T157);  ...  CTDP1(T340);  EPS8L2(T572);  \\\n",
       "CMK::(5Z)-7-Oxozeaenol            8.603255  ...     -9.751659      -8.751659   \n",
       "COLO-680N::(5Z)-7-Oxozeaenol      7.013462  ...     -9.158429       7.549977   \n",
       "GDM-1::(5Z)-7-Oxozeaenol          8.247928  ...     -9.522178      -8.522178   \n",
       "HEL::(5Z)-7-Oxozeaenol            8.733355  ...    -11.117787       0.333939   \n",
       "HL-60::(5Z)-7-Oxozeaenol          5.044394  ...      3.584963     -10.200250   \n",
       "...                                    ...  ...           ...            ...   \n",
       "SNU-387::rTRAIL                   6.383704  ...     -9.142035       4.783980   \n",
       "SNU-398::rTRAIL                   8.393176  ...     -9.062746       6.139551   \n",
       "SNU-423::rTRAIL                   8.499846  ...     -8.868174       8.450386   \n",
       "SNU-449::rTRAIL                   6.797013  ...    -10.361713       7.923625   \n",
       "THP-1::rTRAIL                     7.360188  ...      3.158660       1.170080   \n",
       "\n",
       "col.name                      BEGAIN(S455);  HNRNPL(S52);  GMDS(T327);  \\\n",
       "CMK::(5Z)-7-Oxozeaenol             4.683472      4.285402    -9.751659   \n",
       "COLO-680N::(5Z)-7-Oxozeaenol       5.488547      4.649615    -9.158429   \n",
       "GDM-1::(5Z)-7-Oxozeaenol           7.215485      4.935460    -0.954557   \n",
       "HEL::(5Z)-7-Oxozeaenol             3.135535      4.209454    -1.577767   \n",
       "HL-60::(5Z)-7-Oxozeaenol           7.209457      4.678072   -11.200250   \n",
       "...                                     ...           ...          ...   \n",
       "SNU-387::rTRAIL                    6.199476      2.046142     3.837943   \n",
       "SNU-398::rTRAIL                   -8.062746      4.145678    -9.062746   \n",
       "SNU-423::rTRAIL                    0.772308      4.017922     0.782409   \n",
       "SNU-449::rTRAIL                    6.591290      3.572890     4.385431   \n",
       "THP-1::rTRAIL                      2.313246      1.757023   -12.012706   \n",
       "\n",
       "col.name                      BOD1L1(S482);BOD1L1(S484);  ARHGEF35(T193);  \\\n",
       "CMK::(5Z)-7-Oxozeaenol                         -0.388355        -9.751659   \n",
       "COLO-680N::(5Z)-7-Oxozeaenol                   -9.158429         0.214125   \n",
       "GDM-1::(5Z)-7-Oxozeaenol                       -0.948976        -9.522178   \n",
       "HEL::(5Z)-7-Oxozeaenol                        -11.117787       -11.117787   \n",
       "HL-60::(5Z)-7-Oxozeaenol                      -11.200250       -11.200250   \n",
       "...                                                  ...              ...   \n",
       "SNU-387::rTRAIL                                -9.142035         1.007195   \n",
       "SNU-398::rTRAIL                                -9.062746         0.863938   \n",
       "SNU-423::rTRAIL                                -8.868174         4.217231   \n",
       "SNU-449::rTRAIL                               -10.361713         1.744161   \n",
       "THP-1::rTRAIL                                 -12.012706       -12.012706   \n",
       "\n",
       "col.name                      ARHGEF5(S184);  PSMB2(T148);  HSP90AA1(S476);  \n",
       "CMK::(5Z)-7-Oxozeaenol             -9.751659      0.575312         1.627607  \n",
       "COLO-680N::(5Z)-7-Oxozeaenol        1.263034     -2.403542         3.378512  \n",
       "GDM-1::(5Z)-7-Oxozeaenol           -9.522178      1.952334         3.320485  \n",
       "HEL::(5Z)-7-Oxozeaenol            -11.117787      0.389567         3.279471  \n",
       "HL-60::(5Z)-7-Oxozeaenol          -11.200250     -2.011588         2.536053  \n",
       "...                                      ...           ...              ...  \n",
       "SNU-387::rTRAIL                    -9.142035     -9.142035         3.632268  \n",
       "SNU-398::rTRAIL                    -9.062746      1.070389         2.653060  \n",
       "SNU-423::rTRAIL                    -8.868174     -8.868174         3.733354  \n",
       "SNU-449::rTRAIL                   -10.361713    -10.361713         4.472488  \n",
       "THP-1::rTRAIL                     -12.012706    -12.012706         1.646163  \n",
       "\n",
       "[12903 rows x 22804 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all_phos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function src.utils.split(seed, _all_cls, _all_drugs, all_targets, train_size=0.8, split_type='cblind')>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42 * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cls in sets, relative to all clsbefore mising values are removed\n",
      "train fraction 0.7857142857142857, test fraction 0.21428571428571427\n",
      "------\n",
      "Fraction of cls in sets, relative to all cl drug pairs, after mising values are removed\n",
      "train fraction 0.6897860593512768, test fraction 0.20069013112491374\n",
      "------\n",
      "split test into a test and val set\n",
      "Fraction of cls in sets, relative to all clsbefore mising values are removed\n",
      "train fraction 0.4444444444444444, test fraction 0.5555555555555556\n",
      "------\n",
      "Fraction of cls in sets, relative to all cl drug pairs, after mising values are removed\n",
      "train fraction 0.40933977455716586, test fraction 0.5272141706924316\n"
     ]
    }
   ],
   "source": [
    "_all_cls = data.phos.index\n",
    "_all_drugs = data.all_drugs\n",
    "train_size=0.8\n",
    "rand_seed=42\n",
    "\n",
    "train_pairs, test_pairs = utils.split(\n",
    "    rand_seed, _all_cls, _all_drugs, pairs_with_truth_vals,\n",
    "    train_size=train_size, split_type='cblind')\n",
    "\n",
    "print('------')\n",
    "print('split test into a test and val set')\n",
    "\n",
    "test_cls = np.unique([cl.split('::')[0] for cl in test_pairs])\n",
    "val_pairs, test_pairs = utils.split(\n",
    "    rand_seed, pd.Index(test_cls), _all_drugs, test_pairs,\n",
    "    train_size=0.5, split_type='cblind')    \n",
    "\n",
    "xo_train_phos = x_all_phos.loc[train_pairs]\n",
    "xo_val_phos = x_all_phos.loc[val_pairs]\n",
    "xo_test_phos = x_all_phos.loc[test_pairs]\n",
    "\n",
    "xd_train = x_drug.loc[train_pairs]\n",
    "xd_val = x_drug.loc[val_pairs]\n",
    "xd_test = x_drug.loc[test_pairs]\n",
    "\n",
    "\n",
    "y_train = y_list[train_pairs]\n",
    "y_val = y_list[val_pairs]\n",
    "y_test = y_list[test_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dls = utils.into_dls([np.expand_dims(xo_train_phos.values, 1),\n",
    "                            xd_train.values, \n",
    "                            np.expand_dims(y_train, 1)])\n",
    "\n",
    "val_dls = utils.into_dls([np.expand_dims(xo_val_phos.values, 1), \n",
    "                          xd_val.values, \n",
    "                          np.expand_dims(y_val, 1)])\n",
    "\n",
    "test_dls = utils.into_dls([np.expand_dims(xo_test_phos.values, 1), \n",
    "                           xd_test.values, \n",
    "                           np.expand_dims(y_test, 1)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nik\\miniconda3\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improved from inf to 21.652568340301514\n",
      "Epoch 1\n",
      "-----------------\n",
      "Train loss: 7.252695, Val loss: 7.217523\n",
      "PearsonRResult(statistic=0.18983736705793305, pvalue=0.00273831252653817)\n",
      "loss improved from 21.652568340301514 to 21.514237880706787\n",
      "Epoch 2\n",
      "-----------------\n",
      "Train loss: 6.559753, Val loss: 7.171413\n",
      "PearsonRResult(statistic=0.20043029542595697, pvalue=0.001544333563999266)\n",
      "loss improved from 21.514237880706787 to 21.509610652923584\n",
      "Epoch 3\n",
      "-----------------\n",
      "Train loss: 6.493511, Val loss: 7.169870\n",
      "PearsonRResult(statistic=0.20152600240856036, pvalue=0.0014530869486731057)\n",
      "loss improved from 21.509610652923584 to 21.42800283432007\n",
      "Epoch 4\n",
      "-----------------\n",
      "Train loss: 6.465832, Val loss: 7.142668\n",
      "PearsonRResult(statistic=0.20356925150834704, pvalue=0.0012960018925774876)\n",
      "loss improved from 21.42800283432007 to 21.38790273666382\n",
      "Epoch 5\n",
      "-----------------\n",
      "Train loss: 6.452736, Val loss: 7.129301\n",
      "PearsonRResult(statistic=0.2052054672965301, pvalue=0.001181613305762213)\n",
      "loss improved from 21.38790273666382 to 21.374163150787354\n",
      "Epoch 6\n",
      "-----------------\n",
      "Train loss: 6.442203, Val loss: 7.124721\n",
      "PearsonRResult(statistic=0.2066966869090443, pvalue=0.0010855140873990423)\n",
      "loss improved from 21.374163150787354 to 21.33656883239746\n",
      "Epoch 7\n",
      "-----------------\n",
      "Train loss: 6.435420, Val loss: 7.112190\n",
      "PearsonRResult(statistic=0.20894509198195785, pvalue=0.0009541327853072591)\n",
      "loss improved from 21.33656883239746 to 21.303285598754883\n",
      "Epoch 8\n",
      "-----------------\n",
      "Train loss: 6.427942, Val loss: 7.101095\n",
      "PearsonRResult(statistic=0.21113704831114305, pvalue=0.0008402921420261472)\n",
      "loss improved from 21.303285598754883 to 21.287541389465332\n",
      "Epoch 9\n",
      "-----------------\n",
      "Train loss: 6.422050, Val loss: 7.095847\n",
      "PearsonRResult(statistic=0.21331364171094044, pvalue=0.0007397599629121739)\n",
      "loss improved from 21.287541389465332 to 21.264162063598633\n",
      "Epoch 10\n",
      "-----------------\n",
      "Train loss: 6.414836, Val loss: 7.088054\n",
      "PearsonRResult(statistic=0.2154688344279259, pvalue=0.0006512618864976828)\n",
      "loss improved from 21.264162063598633 to 21.241541862487793\n",
      "Epoch 11\n",
      "-----------------\n",
      "Train loss: 6.406879, Val loss: 7.080514\n",
      "PearsonRResult(statistic=0.21776630634607086, pvalue=0.0005677716148525635)\n",
      "loss improved from 21.241541862487793 to 21.200661659240723\n",
      "Epoch 12\n",
      "-----------------\n",
      "Train loss: 6.401992, Val loss: 7.066887\n",
      "PearsonRResult(statistic=0.2214980206082503, pvalue=0.00045298547963200386)\n",
      "Epoch 13\n",
      "-----------------\n",
      "Train loss: 6.391813, Val loss: 7.067430\n",
      "PearsonRResult(statistic=0.22419730017994288, pvalue=0.0003838090365583055)\n",
      "loss improved from 21.200661659240723 to 21.13668966293335\n",
      "Epoch 14\n",
      "-----------------\n",
      "Train loss: 6.380913, Val loss: 7.045563\n",
      "PearsonRResult(statistic=0.22819300055683206, pvalue=0.00029922831804623)\n",
      "loss improved from 21.13668966293335 to 21.08916139602661\n",
      "Epoch 15\n",
      "-----------------\n",
      "Train loss: 6.369759, Val loss: 7.029720\n",
      "PearsonRResult(statistic=0.23158039383809773, pvalue=0.00024147120863957398)\n",
      "loss improved from 21.08916139602661 to 21.053403854370117\n",
      "Epoch 16\n",
      "-----------------\n",
      "Train loss: 6.360699, Val loss: 7.017801\n",
      "PearsonRResult(statistic=0.2347710041339556, pvalue=0.00019673673458022776)\n",
      "loss improved from 21.053403854370117 to 21.046563625335693\n",
      "Epoch 17\n",
      "-----------------\n",
      "Train loss: 6.351951, Val loss: 7.015521\n",
      "PearsonRResult(statistic=0.2374520496082057, pvalue=0.0001652612970563612)\n",
      "loss improved from 21.046563625335693 to 21.022242546081543\n",
      "Epoch 18\n",
      "-----------------\n",
      "Train loss: 6.343364, Val loss: 7.007414\n",
      "PearsonRResult(statistic=0.24122507779374575, pvalue=0.00012886887309864113)\n",
      "loss improved from 21.022242546081543 to 20.96471071243286\n",
      "Epoch 19\n",
      "-----------------\n",
      "Train loss: 6.330660, Val loss: 6.988237\n",
      "PearsonRResult(statistic=0.245801110830973, pvalue=9.480077215246688e-05)\n",
      "loss improved from 20.96471071243286 to 20.935962200164795\n",
      "Epoch 20\n",
      "-----------------\n",
      "Train loss: 6.318987, Val loss: 6.978654\n",
      "PearsonRResult(statistic=0.2501793877138748, pvalue=7.028067154930076e-05)\n",
      "loss improved from 20.935962200164795 to 20.891250610351562\n",
      "Epoch 21\n",
      "-----------------\n",
      "Train loss: 6.304680, Val loss: 6.963750\n",
      "PearsonRResult(statistic=0.25493678491286426, pvalue=5.0456801578392705e-05)\n",
      "loss improved from 20.891250610351562 to 20.82327175140381\n",
      "Epoch 22\n",
      "-----------------\n",
      "Train loss: 6.289422, Val loss: 6.941091\n",
      "PearsonRResult(statistic=0.2598675799096558, pvalue=3.554516457706094e-05)\n",
      "loss improved from 20.82327175140381 to 20.782276153564453\n",
      "Epoch 23\n",
      "-----------------\n",
      "Train loss: 6.274780, Val loss: 6.927425\n",
      "PearsonRResult(statistic=0.26769048216663716, pvalue=2.0096393972289253e-05)\n",
      "loss improved from 20.782276153564453 to 20.72368049621582\n",
      "Epoch 24\n",
      "-----------------\n",
      "Train loss: 6.257077, Val loss: 6.907893\n",
      "PearsonRResult(statistic=0.27173189433255157, pvalue=1.4863409594020388e-05)\n",
      "Epoch 25\n",
      "-----------------\n",
      "Train loss: 6.241924, Val loss: 6.914539\n",
      "PearsonRResult(statistic=0.27979268594457196, pvalue=8.026741875017814e-06)\n",
      "loss improved from 20.72368049621582 to 20.612475872039795\n",
      "Epoch 26\n",
      "-----------------\n",
      "Train loss: 6.224228, Val loss: 6.870825\n",
      "PearsonRResult(statistic=0.28762459334849, pvalue=4.329342614909282e-06)\n",
      "loss improved from 20.612475872039795 to 20.535704135894775\n",
      "Epoch 27\n",
      "-----------------\n",
      "Train loss: 6.199655, Val loss: 6.845235\n",
      "PearsonRResult(statistic=0.29659936586091884, pvalue=2.0852389593075123e-06)\n",
      "loss improved from 20.535704135894775 to 20.438570976257324\n",
      "Epoch 28\n",
      "-----------------\n",
      "Train loss: 6.175631, Val loss: 6.812857\n",
      "PearsonRResult(statistic=0.3053164533560379, pvalue=1.0013156458754426e-06)\n",
      "loss improved from 20.438570976257324 to 20.385733127593994\n",
      "Epoch 29\n",
      "-----------------\n",
      "Train loss: 6.152430, Val loss: 6.795244\n",
      "PearsonRResult(statistic=0.31411332610527626, pvalue=4.660789292066412e-07)\n",
      "loss improved from 20.385733127593994 to 20.29321527481079\n",
      "Epoch 30\n",
      "-----------------\n",
      "Train loss: 6.122811, Val loss: 6.764405\n",
      "PearsonRResult(statistic=0.32345751090687425, pvalue=2.0127328397443525e-07)\n",
      "loss improved from 20.29321527481079 to 20.17570924758911\n",
      "Epoch 31\n",
      "-----------------\n",
      "Train loss: 6.093706, Val loss: 6.725236\n",
      "PearsonRResult(statistic=0.3328049141537761, pvalue=8.442594760159787e-08)\n",
      "loss improved from 20.17570924758911 to 20.0682315826416\n",
      "Epoch 32\n",
      "-----------------\n",
      "Train loss: 6.064499, Val loss: 6.689411\n",
      "PearsonRResult(statistic=0.34375760172279, pvalue=2.9382705250441528e-08)\n",
      "loss improved from 20.0682315826416 to 19.962161540985107\n",
      "Epoch 33\n",
      "-----------------\n",
      "Train loss: 6.030731, Val loss: 6.654054\n",
      "PearsonRResult(statistic=0.35567922156624826, pvalue=8.885794534480834e-09)\n",
      "loss improved from 19.962161540985107 to 19.867581367492676\n",
      "Epoch 34\n",
      "-----------------\n",
      "Train loss: 5.997563, Val loss: 6.622527\n",
      "PearsonRResult(statistic=0.3666334832031136, pvalue=2.832295287447531e-09)\n",
      "loss improved from 19.867581367492676 to 19.724194049835205\n",
      "Epoch 35\n",
      "-----------------\n",
      "Train loss: 5.960648, Val loss: 6.574731\n",
      "PearsonRResult(statistic=0.379591090460648, pvalue=6.921381365275235e-10)\n",
      "loss improved from 19.724194049835205 to 19.619971752166748\n",
      "Epoch 36\n",
      "-----------------\n",
      "Train loss: 5.924762, Val loss: 6.539991\n",
      "PearsonRResult(statistic=0.39133256325609644, pvalue=1.8280266753168254e-10)\n",
      "loss improved from 19.619971752166748 to 19.49481439590454\n",
      "Epoch 37\n",
      "-----------------\n",
      "Train loss: 5.886907, Val loss: 6.498271\n",
      "PearsonRResult(statistic=0.40230636980872636, pvalue=5.018456285208007e-11)\n",
      "loss improved from 19.49481439590454 to 19.3821964263916\n",
      "Epoch 38\n",
      "-----------------\n",
      "Train loss: 5.842675, Val loss: 6.460732\n",
      "PearsonRResult(statistic=0.4153138499265373, pvalue=1.0185452919198855e-11)\n",
      "loss improved from 19.3821964263916 to 19.25245189666748\n",
      "Epoch 39\n",
      "-----------------\n",
      "Train loss: 5.801116, Val loss: 6.417484\n",
      "PearsonRResult(statistic=0.42831752022837255, pvalue=1.92819401863921e-12)\n",
      "loss improved from 19.25245189666748 to 19.101019382476807\n",
      "Epoch 40\n",
      "-----------------\n",
      "Train loss: 5.751360, Val loss: 6.367006\n",
      "PearsonRResult(statistic=0.4380817293351589, pvalue=5.26857362422037e-13)\n",
      "loss improved from 19.101019382476807 to 18.927133560180664\n",
      "Epoch 41\n",
      "-----------------\n",
      "Train loss: 5.700589, Val loss: 6.309045\n",
      "PearsonRResult(statistic=0.4477430202842798, pvalue=1.4000327422202685e-13)\n",
      "loss improved from 18.927133560180664 to 18.7327880859375\n",
      "Epoch 42\n",
      "-----------------\n",
      "Train loss: 5.643850, Val loss: 6.244263\n",
      "PearsonRResult(statistic=0.4653073834078534, pvalue=1.1273543532997723e-14)\n",
      "loss improved from 18.7327880859375 to 18.555885314941406\n",
      "Epoch 43\n",
      "-----------------\n",
      "Train loss: 5.589856, Val loss: 6.185295\n",
      "PearsonRResult(statistic=0.4847025151899187, pvalue=5.872573445147337e-16)\n",
      "loss improved from 18.555885314941406 to 18.357669830322266\n",
      "Epoch 44\n",
      "-----------------\n",
      "Train loss: 5.530098, Val loss: 6.119223\n",
      "PearsonRResult(statistic=0.5005313950753549, pvalue=4.567186904366733e-17)\n",
      "loss improved from 18.357669830322266 to 18.237337112426758\n",
      "Epoch 45\n",
      "-----------------\n",
      "Train loss: 5.465881, Val loss: 6.079112\n",
      "PearsonRResult(statistic=0.5124515783345409, pvalue=6.1039629550194335e-18)\n",
      "loss improved from 18.237337112426758 to 17.963226318359375\n",
      "Epoch 46\n",
      "-----------------\n",
      "Train loss: 5.400673, Val loss: 5.987742\n",
      "PearsonRResult(statistic=0.5347873088602817, pvalue=1.1289319460262522e-19)\n",
      "loss improved from 17.963226318359375 to 17.740695476531982\n",
      "Epoch 47\n",
      "-----------------\n",
      "Train loss: 5.327110, Val loss: 5.913565\n",
      "PearsonRResult(statistic=0.5521534746020056, pvalue=4.109197400699943e-21)\n",
      "loss improved from 17.740695476531982 to 17.528259754180908\n",
      "Epoch 48\n",
      "-----------------\n",
      "Train loss: 5.250949, Val loss: 5.842753\n",
      "PearsonRResult(statistic=0.5634217335802415, pvalue=4.308383969749201e-22)\n",
      "loss improved from 17.528259754180908 to 17.21207094192505\n",
      "Epoch 49\n",
      "-----------------\n",
      "Train loss: 5.173034, Val loss: 5.737357\n",
      "PearsonRResult(statistic=0.5851497163972543, pvalue=4.331499895268902e-24)\n",
      "loss improved from 17.21207094192505 to 16.988301753997803\n",
      "Epoch 50\n",
      "-----------------\n",
      "Train loss: 5.086529, Val loss: 5.662767\n",
      "PearsonRResult(statistic=0.5929399823342246, pvalue=7.6437426997126315e-25)\n",
      "loss improved from 16.988301753997803 to 16.66543483734131\n",
      "Epoch 51\n",
      "-----------------\n",
      "Train loss: 5.000046, Val loss: 5.555145\n",
      "PearsonRResult(statistic=0.6094246420250259, pvalue=1.6598309130682844e-26)\n",
      "loss improved from 16.66543483734131 to 16.398250102996826\n",
      "Epoch 52\n",
      "-----------------\n",
      "Train loss: 4.911701, Val loss: 5.466083\n",
      "PearsonRResult(statistic=0.6202311746680744, pvalue=1.1909342848630466e-27)\n",
      "loss improved from 16.398250102996826 to 16.113436698913574\n",
      "Epoch 53\n",
      "-----------------\n",
      "Train loss: 4.822966, Val loss: 5.371146\n",
      "PearsonRResult(statistic=0.6314624087931056, pvalue=6.897074753226965e-29)\n",
      "loss improved from 16.113436698913574 to 15.823769569396973\n",
      "Epoch 54\n",
      "-----------------\n",
      "Train loss: 4.733088, Val loss: 5.274590\n",
      "PearsonRResult(statistic=0.6409665332787992, pvalue=5.640761419151391e-30)\n",
      "loss improved from 15.823769569396973 to 15.554017543792725\n",
      "Epoch 55\n",
      "-----------------\n",
      "Train loss: 4.636458, Val loss: 5.184673\n",
      "PearsonRResult(statistic=0.6530647628593875, pvalue=2.0443896458232746e-31)\n",
      "loss improved from 15.554017543792725 to 15.244190216064453\n",
      "Epoch 56\n",
      "-----------------\n",
      "Train loss: 4.542023, Val loss: 5.081397\n",
      "PearsonRResult(statistic=0.6662423054931388, pvalue=4.6170292863752335e-33)\n",
      "loss improved from 15.244190216064453 to 14.94602632522583\n",
      "Epoch 57\n",
      "-----------------\n",
      "Train loss: 4.443275, Val loss: 4.982009\n",
      "PearsonRResult(statistic=0.6792982890869965, pvalue=8.879575848161814e-35)\n",
      "loss improved from 14.94602632522583 to 14.62905740737915\n",
      "Epoch 58\n",
      "-----------------\n",
      "Train loss: 4.340517, Val loss: 4.876352\n",
      "PearsonRResult(statistic=0.6868636691506133, pvalue=8.179808152342998e-36)\n",
      "loss improved from 14.62905740737915 to 14.36325740814209\n",
      "Epoch 59\n",
      "-----------------\n",
      "Train loss: 4.241379, Val loss: 4.787752\n",
      "PearsonRResult(statistic=0.6960903513834019, pvalue=4.0373615548888986e-37)\n",
      "loss improved from 14.36325740814209 to 14.001923561096191\n",
      "Epoch 60\n",
      "-----------------\n",
      "Train loss: 4.139812, Val loss: 4.667308\n",
      "PearsonRResult(statistic=0.7060984115716862, pvalue=1.3537368272707033e-38)\n",
      "loss improved from 14.001923561096191 to 13.6817626953125\n",
      "Epoch 61\n",
      "-----------------\n",
      "Train loss: 4.037894, Val loss: 4.560588\n",
      "PearsonRResult(statistic=0.7140110412790304, pvalue=8.336568860133438e-40)\n",
      "loss improved from 13.6817626953125 to 13.34766960144043\n",
      "Epoch 62\n",
      "-----------------\n",
      "Train loss: 3.933854, Val loss: 4.449223\n",
      "PearsonRResult(statistic=0.7198467455872137, pvalue=1.0035012627887811e-40)\n",
      "loss improved from 13.34766960144043 to 13.098628520965576\n",
      "Epoch 63\n",
      "-----------------\n",
      "Train loss: 3.827432, Val loss: 4.366210\n",
      "PearsonRResult(statistic=0.7254621430829513, pvalue=1.242855617358107e-41)\n",
      "loss improved from 13.098628520965576 to 12.605737209320068\n",
      "Epoch 64\n",
      "-----------------\n",
      "Train loss: 3.714843, Val loss: 4.201912\n",
      "PearsonRResult(statistic=0.7327903294332447, pvalue=7.519844344421461e-43)\n",
      "loss improved from 12.605737209320068 to 12.31801438331604\n",
      "Epoch 65\n",
      "-----------------\n",
      "Train loss: 3.605217, Val loss: 4.106005\n",
      "PearsonRResult(statistic=0.736877768948044, pvalue=1.5103713945002601e-43)\n",
      "loss improved from 12.31801438331604 to 11.985521793365479\n",
      "Epoch 66\n",
      "-----------------\n",
      "Train loss: 3.503802, Val loss: 3.995174\n",
      "PearsonRResult(statistic=0.7431355089308546, pvalue=1.2196811686059625e-44)\n",
      "loss improved from 11.985521793365479 to 11.692487001419067\n",
      "Epoch 67\n",
      "-----------------\n",
      "Train loss: 3.408039, Val loss: 3.897496\n",
      "PearsonRResult(statistic=0.7483716761470438, pvalue=1.4031487567420833e-45)\n",
      "loss improved from 11.692487001419067 to 11.400355577468872\n",
      "Epoch 68\n",
      "-----------------\n",
      "Train loss: 3.309961, Val loss: 3.800119\n",
      "PearsonRResult(statistic=0.7527279471891997, pvalue=2.2279755069438296e-46)\n",
      "loss improved from 11.400355577468872 to 11.117796659469604\n",
      "Epoch 69\n",
      "-----------------\n",
      "Train loss: 3.216245, Val loss: 3.705932\n",
      "PearsonRResult(statistic=0.7573142911704702, pvalue=3.078301665962426e-47)\n",
      "loss improved from 11.117796659469604 to 10.831736326217651\n",
      "Epoch 70\n",
      "-----------------\n",
      "Train loss: 3.127996, Val loss: 3.610579\n",
      "PearsonRResult(statistic=0.7616923888752976, pvalue=4.4637508998104095e-48)\n",
      "loss improved from 10.831736326217651 to 10.536181449890137\n",
      "Epoch 71\n",
      "-----------------\n",
      "Train loss: 3.040311, Val loss: 3.512060\n",
      "PearsonRResult(statistic=0.7665860164762893, pvalue=4.905474233575383e-49)\n",
      "loss improved from 10.536181449890137 to 10.252121210098267\n",
      "Epoch 72\n",
      "-----------------\n",
      "Train loss: 2.959812, Val loss: 3.417374\n",
      "PearsonRResult(statistic=0.7721937333776778, pvalue=3.6510758905540577e-50)\n",
      "loss improved from 10.252121210098267 to 10.037624835968018\n",
      "Epoch 73\n",
      "-----------------\n",
      "Train loss: 2.872582, Val loss: 3.345875\n",
      "PearsonRResult(statistic=0.7738250728775713, pvalue=1.690903290271444e-50)\n",
      "loss improved from 10.037624835968018 to 9.745975732803345\n",
      "Epoch 74\n",
      "-----------------\n",
      "Train loss: 2.799458, Val loss: 3.248659\n",
      "PearsonRResult(statistic=0.777686885067794, pvalue=2.6635492074361684e-51)\n",
      "loss improved from 9.745975732803345 to 9.529534816741943\n",
      "Epoch 75\n",
      "-----------------\n",
      "Train loss: 2.725200, Val loss: 3.176512\n",
      "PearsonRResult(statistic=0.7804091990270643, pvalue=7.077527666592838e-52)\n",
      "loss improved from 9.529534816741943 to 9.310938596725464\n",
      "Epoch 76\n",
      "-----------------\n",
      "Train loss: 2.654809, Val loss: 3.103646\n",
      "PearsonRResult(statistic=0.7829279783202506, pvalue=2.0415081042948748e-52)\n",
      "loss improved from 9.310938596725464 to 9.083776235580444\n",
      "Epoch 77\n",
      "-----------------\n",
      "Train loss: 2.589657, Val loss: 3.027925\n",
      "PearsonRResult(statistic=0.7861521627598675, pvalue=4.056798709689537e-53)\n",
      "loss improved from 9.083776235580444 to 8.86184811592102\n",
      "Epoch 78\n",
      "-----------------\n",
      "Train loss: 2.525715, Val loss: 2.953949\n",
      "PearsonRResult(statistic=0.7886770839502809, pvalue=1.1222083040566464e-53)\n",
      "loss improved from 8.86184811592102 to 8.693371295928955\n",
      "Epoch 79\n",
      "-----------------\n",
      "Train loss: 2.465093, Val loss: 2.897790\n",
      "PearsonRResult(statistic=0.7893421198244338, pvalue=7.976278949912471e-54)\n",
      "loss improved from 8.693371295928955 to 8.490036249160767\n",
      "Epoch 80\n",
      "-----------------\n",
      "Train loss: 2.403992, Val loss: 2.830012\n",
      "PearsonRResult(statistic=0.7914073965823261, pvalue=2.740919141931779e-54)\n",
      "loss improved from 8.490036249160767 to 8.345277309417725\n",
      "Epoch 81\n",
      "-----------------\n",
      "Train loss: 2.345985, Val loss: 2.781759\n",
      "PearsonRResult(statistic=0.7946023040137236, pvalue=5.126342390981733e-55)\n",
      "loss improved from 8.345277309417725 to 8.141004085540771\n",
      "Epoch 82\n",
      "-----------------\n",
      "Train loss: 2.281616, Val loss: 2.713668\n",
      "PearsonRResult(statistic=0.7961077861560508, pvalue=2.3026550273194062e-55)\n",
      "loss improved from 8.141004085540771 to 8.008943319320679\n",
      "Epoch 83\n",
      "-----------------\n",
      "Train loss: 2.247309, Val loss: 2.669648\n",
      "PearsonRResult(statistic=0.7989860673324325, pvalue=4.892089090951113e-56)\n",
      "loss improved from 8.008943319320679 to 7.869499683380127\n",
      "Epoch 84\n",
      "-----------------\n",
      "Train loss: 2.192796, Val loss: 2.623167\n",
      "PearsonRResult(statistic=0.8011611074865319, pvalue=1.4921780446510458e-56)\n",
      "loss improved from 7.869499683380127 to 7.7548322677612305\n",
      "Epoch 85\n",
      "-----------------\n",
      "Train loss: 2.155786, Val loss: 2.584944\n",
      "PearsonRResult(statistic=0.8024725264996487, pvalue=7.240971351814763e-57)\n",
      "loss improved from 7.7548322677612305 to 7.617551326751709\n",
      "Epoch 86\n",
      "-----------------\n",
      "Train loss: 2.116255, Val loss: 2.539184\n",
      "PearsonRResult(statistic=0.8056256908615343, pvalue=1.2444914146348434e-57)\n",
      "loss improved from 7.617551326751709 to 7.520860195159912\n",
      "Epoch 87\n",
      "-----------------\n",
      "Train loss: 2.084751, Val loss: 2.506953\n",
      "PearsonRResult(statistic=0.8069850135525518, pvalue=5.766940041601797e-58)\n",
      "loss improved from 7.520860195159912 to 7.432176351547241\n",
      "Epoch 88\n",
      "-----------------\n",
      "Train loss: 2.049787, Val loss: 2.477392\n",
      "PearsonRResult(statistic=0.8094020320115958, pvalue=1.4466483304306161e-58)\n",
      "loss improved from 7.432176351547241 to 7.336792945861816\n",
      "Epoch 89\n",
      "-----------------\n",
      "Train loss: 2.014177, Val loss: 2.445598\n",
      "PearsonRResult(statistic=0.8103401017261196, pvalue=8.413047812834814e-59)\n",
      "loss improved from 7.336792945861816 to 7.282522916793823\n",
      "Epoch 90\n",
      "-----------------\n",
      "Train loss: 1.994543, Val loss: 2.427508\n",
      "PearsonRResult(statistic=0.8126665692413881, pvalue=2.164813474211685e-59)\n",
      "loss improved from 7.282522916793823 to 7.139090299606323\n",
      "Epoch 91\n",
      "-----------------\n",
      "Train loss: 1.955321, Val loss: 2.379697\n",
      "PearsonRResult(statistic=0.8138919145895677, pvalue=1.0509808033734612e-59)\n",
      "loss improved from 7.139090299606323 to 7.071390867233276\n",
      "Epoch 92\n",
      "-----------------\n",
      "Train loss: 1.947568, Val loss: 2.357130\n",
      "PearsonRResult(statistic=0.8165476661349972, pvalue=2.1547044047963252e-60)\n",
      "loss improved from 7.071390867233276 to 6.951289176940918\n",
      "Epoch 93\n",
      "-----------------\n",
      "Train loss: 1.910305, Val loss: 2.317096\n",
      "PearsonRResult(statistic=0.8176599225264072, pvalue=1.101115073817268e-60)\n",
      "loss improved from 6.951289176940918 to 6.886449098587036\n",
      "Epoch 94\n",
      "-----------------\n",
      "Train loss: 1.898358, Val loss: 2.295483\n",
      "PearsonRResult(statistic=0.8191179240138406, pvalue=4.535411863006e-61)\n",
      "loss improved from 6.886449098587036 to 6.845513820648193\n",
      "Epoch 95\n",
      "-----------------\n",
      "Train loss: 1.873453, Val loss: 2.281838\n",
      "PearsonRResult(statistic=0.8197272425152491, pvalue=3.1231949770091576e-61)\n",
      "loss improved from 6.845513820648193 to 6.7803730964660645\n",
      "Epoch 96\n",
      "-----------------\n",
      "Train loss: 1.850908, Val loss: 2.260124\n",
      "PearsonRResult(statistic=0.8210421681941937, pvalue=1.3895195531778986e-61)\n",
      "loss improved from 6.7803730964660645 to 6.720597743988037\n",
      "Epoch 97\n",
      "-----------------\n",
      "Train loss: 1.830536, Val loss: 2.240199\n",
      "PearsonRResult(statistic=0.8223484457191009, pvalue=6.174093445433828e-62)\n",
      "loss improved from 6.720597743988037 to 6.652996301651001\n",
      "Epoch 98\n",
      "-----------------\n",
      "Train loss: 1.813842, Val loss: 2.217665\n",
      "PearsonRResult(statistic=0.8240116469286085, pvalue=2.1767878641729206e-62)\n",
      "loss improved from 6.652996301651001 to 6.5948262214660645\n",
      "Epoch 99\n",
      "-----------------\n",
      "Train loss: 1.795689, Val loss: 2.198275\n",
      "PearsonRResult(statistic=0.8250297344176364, pvalue=1.1437002297641827e-62)\n",
      "loss improved from 6.5948262214660645 to 6.533956050872803\n",
      "Epoch 100\n",
      "-----------------\n",
      "Train loss: 1.780154, Val loss: 2.177985\n",
      "PearsonRResult(statistic=0.8269810851785898, pvalue=3.2922636277378356e-63)\n",
      "loss improved from 6.533956050872803 to 6.475472688674927\n",
      "Epoch 101\n",
      "-----------------\n",
      "Train loss: 1.761767, Val loss: 2.158491\n",
      "PearsonRResult(statistic=0.828103292039283, pvalue=1.5973233693954098e-63)\n",
      "loss improved from 6.475472688674927 to 6.436435699462891\n",
      "Epoch 102\n",
      "-----------------\n",
      "Train loss: 1.747547, Val loss: 2.145479\n",
      "PearsonRResult(statistic=0.8291366739115976, pvalue=8.168290570721891e-64)\n",
      "loss improved from 6.436435699462891 to 6.384682655334473\n",
      "Epoch 103\n",
      "-----------------\n",
      "Train loss: 1.732458, Val loss: 2.128228\n",
      "PearsonRResult(statistic=0.8304525264765767, pvalue=3.4547045930141085e-64)\n",
      "loss improved from 6.384682655334473 to 6.333674669265747\n",
      "Epoch 104\n",
      "-----------------\n",
      "Train loss: 1.717524, Val loss: 2.111225\n",
      "PearsonRResult(statistic=0.831664246798878, pvalue=1.5538505768371536e-64)\n",
      "loss improved from 6.333674669265747 to 6.30590295791626\n",
      "Epoch 105\n",
      "-----------------\n",
      "Train loss: 1.704456, Val loss: 2.101968\n",
      "PearsonRResult(statistic=0.8327237326592405, pvalue=7.68647531452599e-65)\n",
      "loss improved from 6.30590295791626 to 6.270353078842163\n",
      "Epoch 106\n",
      "-----------------\n",
      "Train loss: 1.692840, Val loss: 2.090118\n",
      "PearsonRResult(statistic=0.8337941297160969, pvalue=3.7558852069943127e-65)\n",
      "loss improved from 6.270353078842163 to 6.241000652313232\n",
      "Epoch 107\n",
      "-----------------\n",
      "Train loss: 1.677229, Val loss: 2.080334\n",
      "PearsonRResult(statistic=0.8340633382299354, pvalue=3.134311045038526e-65)\n",
      "loss improved from 6.241000652313232 to 6.205574154853821\n",
      "Epoch 108\n",
      "-----------------\n",
      "Train loss: 1.667608, Val loss: 2.068525\n",
      "PearsonRResult(statistic=0.8348600152388749, pvalue=1.8314635852202917e-65)\n",
      "loss improved from 6.205574154853821 to 6.193793177604675\n",
      "Epoch 109\n",
      "-----------------\n",
      "Train loss: 1.656119, Val loss: 2.064598\n",
      "PearsonRResult(statistic=0.8353487174604461, pvalue=1.315353374192179e-65)\n",
      "loss improved from 6.193793177604675 to 6.1585471630096436\n",
      "Epoch 110\n",
      "-----------------\n",
      "Train loss: 1.643859, Val loss: 2.052849\n",
      "PearsonRResult(statistic=0.8362480188982631, pvalue=7.132948703845248e-66)\n",
      "loss improved from 6.1585471630096436 to 6.126225709915161\n",
      "Epoch 111\n",
      "-----------------\n",
      "Train loss: 1.636648, Val loss: 2.042075\n",
      "PearsonRResult(statistic=0.837351792658988, pvalue=3.3485399927419134e-66)\n",
      "Epoch 112\n",
      "-----------------\n",
      "Train loss: 1.623103, Val loss: 2.043725\n",
      "PearsonRResult(statistic=0.836984058519956, pvalue=4.3106484947489005e-66)\n",
      "loss improved from 6.126225709915161 to 6.054945707321167\n",
      "Epoch 113\n",
      "-----------------\n",
      "Train loss: 1.614840, Val loss: 2.018315\n",
      "PearsonRResult(statistic=0.8388709516742462, pvalue=1.171670639844796e-66)\n",
      "Epoch 114\n",
      "-----------------\n",
      "Train loss: 1.606811, Val loss: 2.022188\n",
      "PearsonRResult(statistic=0.8387033974581325, pvalue=1.3162466729201083e-66)\n",
      "loss improved from 6.054945707321167 to 6.041006803512573\n",
      "Epoch 115\n",
      "-----------------\n",
      "Train loss: 1.596038, Val loss: 2.013669\n",
      "PearsonRResult(statistic=0.8398624821411825, pvalue=5.869284763833887e-67)\n",
      "loss improved from 6.041006803512573 to 6.000074505805969\n",
      "Epoch 116\n",
      "-----------------\n",
      "Train loss: 1.586834, Val loss: 2.000025\n",
      "PearsonRResult(statistic=0.8415361312641102, pvalue=1.8078219004668125e-67)\n",
      "loss improved from 6.000074505805969 to 5.981238603591919\n",
      "Epoch 117\n",
      "-----------------\n",
      "Train loss: 1.578438, Val loss: 1.993746\n",
      "PearsonRResult(statistic=0.8416995365820314, pvalue=1.610291114995758e-67)\n",
      "loss improved from 5.981238603591919 to 5.9761152267456055\n",
      "Epoch 118\n",
      "-----------------\n",
      "Train loss: 1.573569, Val loss: 1.992038\n",
      "PearsonRResult(statistic=0.8420326089477479, pvalue=1.2714502022224942e-67)\n",
      "loss improved from 5.9761152267456055 to 5.9639517068862915\n",
      "Epoch 119\n",
      "-----------------\n",
      "Train loss: 1.563305, Val loss: 1.987984\n",
      "PearsonRResult(statistic=0.8430831736571851, pvalue=6.013136489293974e-68)\n",
      "loss improved from 5.9639517068862915 to 5.937113046646118\n",
      "Epoch 120\n",
      "-----------------\n",
      "Train loss: 1.555538, Val loss: 1.979038\n",
      "PearsonRResult(statistic=0.8436680288091221, pvalue=3.9538746408055326e-68)\n",
      "Epoch 121\n",
      "-----------------\n",
      "Train loss: 1.553619, Val loss: 1.982844\n",
      "PearsonRResult(statistic=0.8443015398197555, pvalue=2.5058265958462804e-68)\n",
      "loss improved from 5.937113046646118 to 5.878542542457581\n",
      "Epoch 122\n",
      "-----------------\n",
      "Train loss: 1.540791, Val loss: 1.959514\n",
      "PearsonRResult(statistic=0.8447099260073017, pvalue=1.8655050007293585e-68)\n",
      "Epoch 123\n",
      "-----------------\n",
      "Train loss: 1.543372, Val loss: 1.967891\n",
      "PearsonRResult(statistic=0.8451097062336603, pvalue=1.3963157174559736e-68)\n",
      "loss improved from 5.878542542457581 to 5.870429039001465\n",
      "Epoch 124\n",
      "-----------------\n",
      "Train loss: 1.529321, Val loss: 1.956810\n",
      "PearsonRResult(statistic=0.8454635964010719, pvalue=1.0797295461888016e-68)\n",
      "Epoch 125\n",
      "-----------------\n",
      "Train loss: 1.528332, Val loss: 1.958855\n",
      "PearsonRResult(statistic=0.8462897423972626, pvalue=5.909251305190486e-69)\n",
      "Epoch 126\n",
      "-----------------\n",
      "Train loss: 1.518086, Val loss: 1.956836\n",
      "PearsonRResult(statistic=0.8461442624333977, pvalue=6.572683925655339e-69)\n",
      "loss improved from 5.870429039001465 to 5.868613839149475\n",
      "Epoch 127\n",
      "-----------------\n",
      "Train loss: 1.518046, Val loss: 1.956205\n",
      "PearsonRResult(statistic=0.8470055640772596, pvalue=3.4950887842526475e-69)\n",
      "loss improved from 5.868613839149475 to 5.770718216896057\n",
      "Epoch 128\n",
      "-----------------\n",
      "Train loss: 1.505320, Val loss: 1.923573\n",
      "PearsonRResult(statistic=0.8471073696591618, pvalue=3.242844115594079e-69)\n",
      "Epoch 129\n",
      "-----------------\n",
      "Train loss: 1.515252, Val loss: 1.944294\n",
      "PearsonRResult(statistic=0.8481456232417395, pvalue=1.5058756050675444e-69)\n",
      "loss improved from 5.770718216896057 to 5.732620120048523\n",
      "Epoch 130\n",
      "-----------------\n",
      "Train loss: 1.494767, Val loss: 1.910873\n",
      "PearsonRResult(statistic=0.8482358507320931, pvalue=1.408382821493929e-69)\n",
      "Epoch 131\n",
      "-----------------\n",
      "Train loss: 1.505135, Val loss: 1.936237\n",
      "PearsonRResult(statistic=0.8484641647637494, pvalue=1.1887231848959185e-69)\n",
      "loss improved from 5.732620120048523 to 5.708879709243774\n",
      "Epoch 132\n",
      "-----------------\n",
      "Train loss: 1.488125, Val loss: 1.902960\n",
      "PearsonRResult(statistic=0.8492343748121418, pvalue=6.695142353797283e-70)\n",
      "Epoch 133\n",
      "-----------------\n",
      "Train loss: 1.493821, Val loss: 1.925404\n",
      "PearsonRResult(statistic=0.8492945345087455, pvalue=6.400695445569787e-70)\n",
      "loss improved from 5.708879709243774 to 5.702202081680298\n",
      "Epoch 134\n",
      "-----------------\n",
      "Train loss: 1.481029, Val loss: 1.900734\n",
      "PearsonRResult(statistic=0.8501815891548559, pvalue=3.290214761676574e-70)\n",
      "loss improved from 5.702202081680298 to 5.700830459594727\n",
      "Epoch 135\n",
      "-----------------\n",
      "Train loss: 1.484962, Val loss: 1.900277\n",
      "PearsonRResult(statistic=0.8508151097468941, pvalue=2.0402120025859214e-70)\n",
      "loss improved from 5.700830459594727 to 5.671698093414307\n",
      "Epoch 136\n",
      "-----------------\n",
      "Train loss: 1.475898, Val loss: 1.890566\n",
      "PearsonRResult(statistic=0.8512290401585101, pvalue=1.4912339639412473e-70)\n",
      "loss improved from 5.671698093414307 to 5.662108063697815\n",
      "Epoch 137\n",
      "-----------------\n",
      "Train loss: 1.475200, Val loss: 1.887369\n",
      "PearsonRResult(statistic=0.8514510320876005, pvalue=1.2599943817185725e-70)\n",
      "loss improved from 5.662108063697815 to 5.658475637435913\n",
      "Epoch 138\n",
      "-----------------\n",
      "Train loss: 1.470336, Val loss: 1.886159\n",
      "PearsonRResult(statistic=0.8517138165461062, pvalue=1.0317870690984453e-70)\n",
      "loss improved from 5.658475637435913 to 5.634976029396057\n",
      "Epoch 139\n",
      "-----------------\n",
      "Train loss: 1.466193, Val loss: 1.878325\n",
      "PearsonRResult(statistic=0.851896843141374, pvalue=8.975330955141197e-71)\n",
      "loss improved from 5.634976029396057 to 5.626282095909119\n",
      "Epoch 140\n",
      "-----------------\n",
      "Train loss: 1.463908, Val loss: 1.875427\n",
      "PearsonRResult(statistic=0.8522911700754399, pvalue=6.642645918388811e-71)\n",
      "loss improved from 5.626282095909119 to 5.600222110748291\n",
      "Epoch 141\n",
      "-----------------\n",
      "Train loss: 1.458878, Val loss: 1.866741\n",
      "PearsonRResult(statistic=0.8529927040482042, pvalue=3.880217309312843e-71)\n",
      "Epoch 142\n",
      "-----------------\n",
      "Train loss: 1.457535, Val loss: 1.868455\n",
      "PearsonRResult(statistic=0.8534429685334012, pvalue=2.7438299786567353e-71)\n",
      "loss improved from 5.600222110748291 to 5.599032759666443\n",
      "Epoch 143\n",
      "-----------------\n",
      "Train loss: 1.453862, Val loss: 1.866344\n",
      "PearsonRResult(statistic=0.8538029918434666, pvalue=2.0780583399551254e-71)\n",
      "Epoch 144\n",
      "-----------------\n",
      "Train loss: 1.451551, Val loss: 1.872454\n",
      "PearsonRResult(statistic=0.8539778599929111, pvalue=1.8151619545884682e-71)\n",
      "loss improved from 5.599032759666443 to 5.5414674282073975\n",
      "Epoch 145\n",
      "-----------------\n",
      "Train loss: 1.445805, Val loss: 1.847156\n",
      "PearsonRResult(statistic=0.8548235052596352, pvalue=9.413621654839143e-72)\n",
      "Epoch 146\n",
      "-----------------\n",
      "Train loss: 1.447011, Val loss: 1.855832\n",
      "PearsonRResult(statistic=0.8542554784584855, pvalue=1.4638582845858017e-71)\n",
      "Epoch 147\n",
      "-----------------\n",
      "Train loss: 1.444252, Val loss: 1.848291\n",
      "PearsonRResult(statistic=0.855054617644621, pvalue=7.861558758449952e-72)\n",
      "Epoch 148\n",
      "-----------------\n",
      "Train loss: 1.440720, Val loss: 1.855020\n",
      "PearsonRResult(statistic=0.8548001947901429, pvalue=9.586089167505676e-72)\n",
      "loss improved from 5.5414674282073975 to 5.537529945373535\n",
      "Epoch 149\n",
      "-----------------\n",
      "Train loss: 1.438115, Val loss: 1.845843\n",
      "PearsonRResult(statistic=0.8555648197621986, pvalue=5.275777116767416e-72)\n",
      "Epoch 150\n",
      "-----------------\n",
      "Train loss: 1.434383, Val loss: 1.848515\n",
      "PearsonRResult(statistic=0.8552985224814231, pvalue=6.498032291168307e-72)\n",
      "loss improved from 5.537529945373535 to 5.52274477481842\n",
      "Epoch 151\n",
      "-----------------\n",
      "Train loss: 1.431515, Val loss: 1.840915\n",
      "PearsonRResult(statistic=0.8555480300130063, pvalue=5.345612110290464e-72)\n",
      "Epoch 152\n",
      "-----------------\n",
      "Train loss: 1.431596, Val loss: 1.844394\n",
      "PearsonRResult(statistic=0.8559384290770821, pvalue=3.9356506762583785e-72)\n",
      "loss improved from 5.52274477481842 to 5.506971001625061\n",
      "Epoch 153\n",
      "-----------------\n",
      "Train loss: 1.427004, Val loss: 1.835657\n",
      "PearsonRResult(statistic=0.8562290088586157, pvalue=3.1317127429426713e-72)\n",
      "loss improved from 5.506971001625061 to 5.49728536605835\n",
      "Epoch 154\n",
      "-----------------\n",
      "Train loss: 1.428197, Val loss: 1.832428\n",
      "PearsonRResult(statistic=0.8566430274485599, pvalue=2.2595109597588724e-72)\n",
      "loss improved from 5.49728536605835 to 5.494655251502991\n",
      "Epoch 155\n",
      "-----------------\n",
      "Train loss: 1.421738, Val loss: 1.831552\n",
      "PearsonRResult(statistic=0.8566087539219034, pvalue=2.321492242307556e-72)\n",
      "loss improved from 5.494655251502991 to 5.484739661216736\n",
      "Epoch 156\n",
      "-----------------\n",
      "Train loss: 1.421767, Val loss: 1.828247\n",
      "PearsonRResult(statistic=0.8570434984624299, pvalue=1.6461193890554322e-72)\n",
      "loss improved from 5.484739661216736 to 5.467514872550964\n",
      "Epoch 157\n",
      "-----------------\n",
      "Train loss: 1.419634, Val loss: 1.822505\n",
      "PearsonRResult(statistic=0.8571498431166091, pvalue=1.513086605205995e-72)\n",
      "loss improved from 5.467514872550964 to 5.44374144077301\n",
      "Epoch 158\n",
      "-----------------\n",
      "Train loss: 1.419544, Val loss: 1.814580\n",
      "PearsonRResult(statistic=0.8578269446500333, pvalue=8.833812493911106e-73)\n",
      "Epoch 159\n",
      "-----------------\n",
      "Train loss: 1.415975, Val loss: 1.818312\n",
      "PearsonRResult(statistic=0.8579661145195854, pvalue=7.906073542917574e-73)\n",
      "Epoch 160\n",
      "-----------------\n",
      "Train loss: 1.413033, Val loss: 1.817163\n",
      "PearsonRResult(statistic=0.8576746457367505, pvalue=9.972927655701615e-73)\n",
      "loss improved from 5.44374144077301 to 5.432194352149963\n",
      "Epoch 161\n",
      "-----------------\n",
      "Train loss: 1.410990, Val loss: 1.810731\n",
      "PearsonRResult(statistic=0.8587787291631743, pvalue=4.1263458289520867e-73)\n",
      "loss improved from 5.432194352149963 to 5.424442172050476\n",
      "Epoch 162\n",
      "-----------------\n",
      "Train loss: 1.408979, Val loss: 1.808147\n",
      "PearsonRResult(statistic=0.8584692266301075, pvalue=5.2884686939091113e-73)\n",
      "Epoch 163\n",
      "-----------------\n",
      "Train loss: 1.407465, Val loss: 1.811236\n",
      "PearsonRResult(statistic=0.8586343953025557, pvalue=4.632895411127835e-73)\n",
      "loss improved from 5.424442172050476 to 5.413328170776367\n",
      "Epoch 164\n",
      "-----------------\n",
      "Train loss: 1.404003, Val loss: 1.804443\n",
      "PearsonRResult(statistic=0.8585847061368433, pvalue=4.8211608406395075e-73)\n",
      "Epoch 165\n",
      "-----------------\n",
      "Train loss: 1.405352, Val loss: 1.807189\n",
      "PearsonRResult(statistic=0.858514327515943, pvalue=5.100848338573468e-73)\n",
      "loss improved from 5.413328170776367 to 5.391096353530884\n",
      "Epoch 166\n",
      "-----------------\n",
      "Train loss: 1.400572, Val loss: 1.797032\n",
      "PearsonRResult(statistic=0.8590322311989742, pvalue=3.3659565232208304e-73)\n",
      "Epoch 167\n",
      "-----------------\n",
      "Train loss: 1.402125, Val loss: 1.802555\n",
      "PearsonRResult(statistic=0.8589287844643352, pvalue=3.657851867091497e-73)\n",
      "Epoch 168\n",
      "-----------------\n",
      "Train loss: 1.397513, Val loss: 1.800378\n",
      "PearsonRResult(statistic=0.8591222791646256, pvalue=3.1307292708412474e-73)\n",
      "Epoch 169\n",
      "-----------------\n",
      "Train loss: 1.395718, Val loss: 1.797962\n",
      "PearsonRResult(statistic=0.8592841244791818, pvalue=2.748156030299816e-73)\n",
      "Epoch 170\n",
      "-----------------\n",
      "Train loss: 1.393288, Val loss: 1.798080\n",
      "PearsonRResult(statistic=0.8593144957531906, pvalue=2.6817074060025686e-73)\n",
      "loss improved from 5.391096353530884 to 5.388277053833008\n",
      "Epoch 171\n",
      "-----------------\n",
      "Train loss: 1.391709, Val loss: 1.796092\n",
      "PearsonRResult(statistic=0.8596815149092369, pvalue=1.9941447350088525e-73)\n",
      "loss improved from 5.388277053833008 to 5.379943370819092\n",
      "Epoch 172\n",
      "-----------------\n",
      "Train loss: 1.388611, Val loss: 1.793314\n",
      "PearsonRResult(statistic=0.8598732441757926, pvalue=1.7076646464454737e-73)\n",
      "Epoch 173\n",
      "-----------------\n",
      "Train loss: 1.389815, Val loss: 1.798590\n",
      "PearsonRResult(statistic=0.859943051022017, pvalue=1.6138186679711822e-73)\n",
      "loss improved from 5.379943370819092 to 5.361276149749756\n",
      "Epoch 174\n",
      "-----------------\n",
      "Train loss: 1.384092, Val loss: 1.787092\n",
      "PearsonRResult(statistic=0.8603438274687809, pvalue=1.1659033920928533e-73)\n",
      "Epoch 175\n",
      "-----------------\n",
      "Train loss: 1.386094, Val loss: 1.797603\n",
      "PearsonRResult(statistic=0.8600662666565914, pvalue=1.460471328288992e-73)\n",
      "Epoch 176\n",
      "-----------------\n",
      "Train loss: 1.381318, Val loss: 1.799765\n",
      "PearsonRResult(statistic=0.8597685322309905, pvalue=1.8586604923908265e-73)\n",
      "Epoch 177\n",
      "-----------------\n",
      "Train loss: 1.379839, Val loss: 1.795494\n",
      "PearsonRResult(statistic=0.8600098927509097, pvalue=1.5287523021973726e-73)\n",
      "Epoch 178\n",
      "-----------------\n",
      "Train loss: 1.379523, Val loss: 1.789405\n",
      "PearsonRResult(statistic=0.8602560959476551, pvalue=1.2520095837416452e-73)\n",
      "Epoch 179\n",
      "-----------------\n",
      "Train loss: 1.378747, Val loss: 1.793653\n",
      "PearsonRResult(statistic=0.8602388485722308, pvalue=1.2696638386083009e-73)\n",
      "Epoch 180\n",
      "-----------------\n",
      "Train loss: 1.374312, Val loss: 1.792260\n",
      "PearsonRResult(statistic=0.8601314101821124, pvalue=1.3853233490731142e-73)\n",
      "Epoch 181\n",
      "-----------------\n",
      "Train loss: 1.372316, Val loss: 1.790491\n",
      "PearsonRResult(statistic=0.8603648817173879, pvalue=1.1461278599967624e-73)\n",
      "Epoch 182\n",
      "-----------------\n",
      "Train loss: 1.372163, Val loss: 1.793098\n",
      "PearsonRResult(statistic=0.8604258270286226, pvalue=1.0907373855196294e-73)\n",
      "Epoch 183\n",
      "-----------------\n",
      "Train loss: 1.368257, Val loss: 1.796394\n",
      "PearsonRResult(statistic=0.8603474940436422, pvalue=1.1624353658433339e-73)\n",
      "Epoch 184\n",
      "-----------------\n",
      "Train loss: 1.366517, Val loss: 1.795895\n",
      "PearsonRResult(statistic=0.8604962317295952, pvalue=1.0300435705485209e-73)\n",
      "loss improved from 5.361276149749756 to 5.353600263595581\n",
      "Epoch 185\n",
      "-----------------\n",
      "Train loss: 1.364342, Val loss: 1.784533\n",
      "PearsonRResult(statistic=0.8610404200906168, pvalue=6.610064092138584e-74)\n",
      "Epoch 186\n",
      "-----------------\n",
      "Train loss: 1.365314, Val loss: 1.789089\n",
      "PearsonRResult(statistic=0.8610021037507045, pvalue=6.8201972554606365e-74)\n",
      "loss improved from 5.353600263595581 to 5.350878953933716\n",
      "Epoch 187\n",
      "-----------------\n",
      "Train loss: 1.360320, Val loss: 1.783626\n",
      "PearsonRResult(statistic=0.8613389473824002, pvalue=5.178154687225184e-74)\n",
      "loss improved from 5.350878953933716 to 5.315605282783508\n",
      "Epoch 188\n",
      "-----------------\n",
      "Train loss: 1.359667, Val loss: 1.771868\n",
      "PearsonRResult(statistic=0.8617797722863354, pvalue=3.607028668891239e-74)\n",
      "loss improved from 5.315605282783508 to 5.307430148124695\n",
      "Epoch 189\n",
      "-----------------\n",
      "Train loss: 1.358121, Val loss: 1.769143\n",
      "PearsonRResult(statistic=0.8620470451566634, pvalue=2.8952103974923174e-74)\n",
      "loss improved from 5.307430148124695 to 5.303120255470276\n",
      "Epoch 190\n",
      "-----------------\n",
      "Train loss: 1.358858, Val loss: 1.767707\n",
      "PearsonRResult(statistic=0.8620427239181019, pvalue=2.9055293325426516e-74)\n",
      "loss improved from 5.303120255470276 to 5.300822734832764\n",
      "Epoch 191\n",
      "-----------------\n",
      "Train loss: 1.354934, Val loss: 1.766941\n",
      "PearsonRResult(statistic=0.8623108769650714, pvalue=2.3293938234598444e-74)\n",
      "loss improved from 5.300822734832764 to 5.297809481620789\n",
      "Epoch 192\n",
      "-----------------\n",
      "Train loss: 1.353113, Val loss: 1.765936\n",
      "PearsonRResult(statistic=0.8622726935309792, pvalue=2.4039344126868776e-74)\n",
      "loss improved from 5.297809481620789 to 5.2937785387039185\n",
      "Epoch 193\n",
      "-----------------\n",
      "Train loss: 1.350980, Val loss: 1.764593\n",
      "PearsonRResult(statistic=0.8624858921888288, pvalue=2.0159922238821056e-74)\n",
      "loss improved from 5.2937785387039185 to 5.268502116203308\n",
      "Epoch 194\n",
      "-----------------\n",
      "Train loss: 1.351409, Val loss: 1.756167\n",
      "PearsonRResult(statistic=0.8629536702233814, pvalue=1.368784076524762e-74)\n",
      "Epoch 195\n",
      "-----------------\n",
      "Train loss: 1.349057, Val loss: 1.756497\n",
      "PearsonRResult(statistic=0.8629644704744821, pvalue=1.356579329782698e-74)\n",
      "loss improved from 5.268502116203308 to 5.264211535453796\n",
      "Epoch 196\n",
      "-----------------\n",
      "Train loss: 1.345087, Val loss: 1.754737\n",
      "PearsonRResult(statistic=0.8632027884870545, pvalue=1.1130879616901376e-74)\n",
      "Epoch 197\n",
      "-----------------\n",
      "Train loss: 1.343377, Val loss: 1.759324\n",
      "PearsonRResult(statistic=0.8630407883341764, pvalue=1.273355230801594e-74)\n",
      "loss improved from 5.264211535453796 to 5.245908141136169\n",
      "Epoch 198\n",
      "-----------------\n",
      "Train loss: 1.341793, Val loss: 1.748636\n",
      "PearsonRResult(statistic=0.8637008585010167, pvalue=7.352689122880304e-75)\n",
      "Epoch 199\n",
      "-----------------\n",
      "Train loss: 1.340248, Val loss: 1.749058\n",
      "PearsonRResult(statistic=0.8638352122713066, pvalue=6.572746558463116e-75)\n",
      "Epoch 200\n",
      "-----------------\n",
      "Train loss: 1.336495, Val loss: 1.749579\n",
      "PearsonRResult(statistic=0.8639220977536683, pvalue=6.112596422597253e-75)\n",
      "loss improved from 5.245908141136169 to 5.244665265083313\n",
      "Epoch 201\n",
      "-----------------\n",
      "Train loss: 1.334550, Val loss: 1.748222\n",
      "PearsonRResult(statistic=0.86415866715844, pvalue=5.015222404673106e-75)\n",
      "Epoch 202\n",
      "-----------------\n",
      "Train loss: 1.334024, Val loss: 1.757117\n",
      "PearsonRResult(statistic=0.8642404063752485, pvalue=4.683388366942762e-75)\n",
      "loss improved from 5.244665265083313 to 5.236636161804199\n",
      "Epoch 203\n",
      "-----------------\n",
      "Train loss: 1.327721, Val loss: 1.745545\n",
      "PearsonRResult(statistic=0.864541956445779, pvalue=3.636747408327258e-75)\n",
      "loss improved from 5.236636161804199 to 5.231732130050659\n",
      "Epoch 204\n",
      "-----------------\n",
      "Train loss: 1.329952, Val loss: 1.743911\n",
      "PearsonRResult(statistic=0.8646171426925668, pvalue=3.414156860128374e-75)\n",
      "Epoch 205\n",
      "-----------------\n",
      "Train loss: 1.330101, Val loss: 1.747872\n",
      "PearsonRResult(statistic=0.8644839621054535, pvalue=3.8182076961380454e-75)\n",
      "loss improved from 5.231732130050659 to 5.2098212242126465\n",
      "Epoch 206\n",
      "-----------------\n",
      "Train loss: 1.325058, Val loss: 1.736607\n",
      "PearsonRResult(statistic=0.8646162306097945, pvalue=3.416774505990689e-75)\n",
      "Epoch 207\n",
      "-----------------\n",
      "Train loss: 1.329293, Val loss: 1.739829\n",
      "PearsonRResult(statistic=0.8647238475051389, pvalue=3.121237323725067e-75)\n",
      "loss improved from 5.2098212242126465 to 5.192114949226379\n",
      "Epoch 208\n",
      "-----------------\n",
      "Train loss: 1.321735, Val loss: 1.730705\n",
      "PearsonRResult(statistic=0.8651476392139371, pvalue=2.184119653364558e-75)\n",
      "Epoch 209\n",
      "-----------------\n",
      "Train loss: 1.322854, Val loss: 1.734440\n",
      "PearsonRResult(statistic=0.8651445473442946, pvalue=2.1898256605344852e-75)\n",
      "Epoch 210\n",
      "-----------------\n",
      "Train loss: 1.318876, Val loss: 1.732660\n",
      "PearsonRResult(statistic=0.8647534880261538, pvalue=3.0443843585955405e-75)\n",
      "loss improved from 5.192114949226379 to 5.188783407211304\n",
      "Epoch 211\n",
      "-----------------\n",
      "Train loss: 1.318673, Val loss: 1.729594\n",
      "PearsonRResult(statistic=0.8654222992332288, pvalue=1.7318339242614852e-75)\n",
      "loss improved from 5.188783407211304 to 5.1739420890808105\n",
      "Epoch 212\n",
      "-----------------\n",
      "Train loss: 1.315060, Val loss: 1.724647\n",
      "PearsonRResult(statistic=0.8656301716542631, pvalue=1.4524185584816096e-75)\n",
      "Epoch 213\n",
      "-----------------\n",
      "Train loss: 1.312417, Val loss: 1.731432\n",
      "PearsonRResult(statistic=0.8652513908873236, pvalue=2.0009536471120502e-75)\n",
      "Epoch 214\n",
      "-----------------\n",
      "Train loss: 1.310749, Val loss: 1.734326\n",
      "PearsonRResult(statistic=0.8647169008358476, pvalue=3.1395250393993403e-75)\n",
      "Epoch 215\n",
      "-----------------\n",
      "Train loss: 1.309237, Val loss: 1.729283\n",
      "PearsonRResult(statistic=0.8653803775185664, pvalue=1.7943258175340318e-75)\n",
      "Epoch 216\n",
      "-----------------\n",
      "Train loss: 1.306233, Val loss: 1.727914\n",
      "PearsonRResult(statistic=0.8652397651085708, pvalue=2.0206963959499178e-75)\n",
      "Epoch 217\n",
      "-----------------\n",
      "Train loss: 1.306250, Val loss: 1.732195\n",
      "PearsonRResult(statistic=0.8650963052546802, pvalue=2.2807923405154817e-75)\n",
      "Epoch 218\n",
      "-----------------\n",
      "Train loss: 1.301801, Val loss: 1.732240\n",
      "PearsonRResult(statistic=0.865078847946291, pvalue=2.314624407391842e-75)\n",
      "Epoch 219\n",
      "-----------------\n",
      "Train loss: 1.301656, Val loss: 1.730984\n",
      "PearsonRResult(statistic=0.865103076245911, pvalue=2.2678024734646604e-75)\n",
      "Epoch 220\n",
      "-----------------\n",
      "Train loss: 1.297694, Val loss: 1.726116\n",
      "PearsonRResult(statistic=0.8655271158654754, pvalue=1.584861589773259e-75)\n",
      "Epoch 221\n",
      "-----------------\n",
      "Train loss: 1.296249, Val loss: 1.730370\n",
      "PearsonRResult(statistic=0.8653898831157971, pvalue=1.7799630449264764e-75)\n",
      "Epoch 222\n",
      "-----------------\n",
      "Train loss: 1.293618, Val loss: 1.726232\n",
      "PearsonRResult(statistic=0.8655761641941595, pvalue=1.5203982573060344e-75)\n",
      "loss improved from 5.1739420890808105 to 5.173010468482971\n",
      "Epoch 223\n",
      "-----------------\n",
      "Train loss: 1.292334, Val loss: 1.724337\n",
      "PearsonRResult(statistic=0.8656697563327098, pvalue=1.4045133291980364e-75)\n",
      "loss improved from 5.173010468482971 to 5.15168309211731\n",
      "Epoch 224\n",
      "-----------------\n",
      "Train loss: 1.289745, Val loss: 1.717228\n",
      "PearsonRResult(statistic=0.8664236622872311, pvalue=7.399845142211522e-76)\n",
      "loss improved from 5.15168309211731 to 5.147315144538879\n",
      "Epoch 225\n",
      "-----------------\n",
      "Train loss: 1.287116, Val loss: 1.715772\n",
      "PearsonRResult(statistic=0.8664250153950546, pvalue=7.391313246113826e-76)\n",
      "Epoch 226\n",
      "-----------------\n",
      "Train loss: 1.285374, Val loss: 1.723397\n",
      "PearsonRResult(statistic=0.8660468138282376, pvalue=1.0198759726400574e-75)\n",
      "Epoch 227\n",
      "-----------------\n",
      "Train loss: 1.284055, Val loss: 1.720583\n",
      "PearsonRResult(statistic=0.8660229854242425, pvalue=1.0407411246892865e-75)\n",
      "Epoch 228\n",
      "-----------------\n",
      "Train loss: 1.280046, Val loss: 1.721743\n",
      "PearsonRResult(statistic=0.8660934859322068, pvalue=9.802011611698598e-76)\n",
      "Epoch 229\n",
      "-----------------\n",
      "Train loss: 1.278453, Val loss: 1.720685\n",
      "PearsonRResult(statistic=0.8659726887297587, pvalue=1.0861812208727502e-75)\n",
      "Epoch 230\n",
      "-----------------\n",
      "Train loss: 1.278078, Val loss: 1.721294\n",
      "PearsonRResult(statistic=0.8660609070375525, pvalue=1.007730929055935e-75)\n",
      "Epoch 231\n",
      "-----------------\n",
      "Train loss: 1.274484, Val loss: 1.722616\n",
      "PearsonRResult(statistic=0.8661539095252452, pvalue=9.31099576970644e-76)\n",
      "Epoch 232\n",
      "-----------------\n",
      "Train loss: 1.271157, Val loss: 1.719249\n",
      "PearsonRResult(statistic=0.8662770910108688, pvalue=8.384206515655644e-76)\n",
      "Epoch 233\n",
      "-----------------\n",
      "Train loss: 1.271706, Val loss: 1.722771\n",
      "PearsonRResult(statistic=0.8660795105031842, pvalue=9.91918210977566e-76)\n",
      "Epoch 234\n",
      "-----------------\n",
      "Train loss: 1.268206, Val loss: 1.719914\n",
      "PearsonRResult(statistic=0.8663589487698513, pvalue=7.819483666724434e-76)\n",
      "Epoch 235\n",
      "-----------------\n",
      "Train loss: 1.265463, Val loss: 1.716452\n",
      "PearsonRResult(statistic=0.8664431012111197, pvalue=7.278205966369361e-76)\n",
      "Epoch 236\n",
      "-----------------\n",
      "Train loss: 1.264890, Val loss: 1.725713\n",
      "PearsonRResult(statistic=0.8661278425866499, pvalue=9.519759827067572e-76)\n",
      "Epoch 237\n",
      "-----------------\n",
      "Train loss: 1.262489, Val loss: 1.726781\n",
      "PearsonRResult(statistic=0.8664790703142747, pvalue=7.058328902579954e-76)\n",
      "Epoch 238\n",
      "-----------------\n",
      "Train loss: 1.259149, Val loss: 1.721165\n",
      "PearsonRResult(statistic=0.8663278787370605, pvalue=8.029250887659137e-76)\n",
      "Epoch 239\n",
      "-----------------\n",
      "Train loss: 1.259426, Val loss: 1.726283\n",
      "PearsonRResult(statistic=0.866574059570668, pvalue=6.50879434037384e-76)\n",
      "Epoch 240\n",
      "-----------------\n",
      "Train loss: 1.251823, Val loss: 1.720788\n",
      "PearsonRResult(statistic=0.8670295056310262, pvalue=4.4090311585885906e-76)\n",
      "Epoch 241\n",
      "-----------------\n",
      "Train loss: 1.254806, Val loss: 1.723292\n",
      "PearsonRResult(statistic=0.8669688214940179, pvalue=4.644275862379503e-76)\n",
      "Epoch 242\n",
      "-----------------\n",
      "Train loss: 1.253137, Val loss: 1.715815\n",
      "PearsonRResult(statistic=0.8677130510924804, pvalue=2.4506931370285595e-76)\n",
      "loss improved from 5.147315144538879 to 5.124357581138611\n",
      "Epoch 243\n",
      "-----------------\n",
      "Train loss: 1.248554, Val loss: 1.708119\n",
      "PearsonRResult(statistic=0.867816764096639, pvalue=2.2411230906615622e-76)\n",
      "Epoch 244\n",
      "-----------------\n",
      "Train loss: 1.248066, Val loss: 1.718211\n",
      "PearsonRResult(statistic=0.8673420001117652, pvalue=3.372228081580273e-76)\n",
      "Epoch 245\n",
      "-----------------\n",
      "Train loss: 1.242067, Val loss: 1.711772\n",
      "PearsonRResult(statistic=0.8676758628480469, pvalue=2.5304730969391895e-76)\n",
      "Epoch 246\n",
      "-----------------\n",
      "Train loss: 1.242973, Val loss: 1.730642\n",
      "PearsonRResult(statistic=0.8668266208693237, pvalue=5.2453428644473414e-76)\n",
      "Epoch 247\n",
      "-----------------\n",
      "Train loss: 1.238513, Val loss: 1.721890\n",
      "PearsonRResult(statistic=0.8672569069509706, pvalue=3.6278512826211276e-76)\n",
      "Epoch 248\n",
      "-----------------\n",
      "Train loss: 1.238533, Val loss: 1.720786\n",
      "PearsonRResult(statistic=0.8672784015679696, pvalue=3.561524043406169e-76)\n",
      "Epoch 249\n",
      "-----------------\n",
      "Train loss: 1.233793, Val loss: 1.718368\n",
      "PearsonRResult(statistic=0.86764260608502, pvalue=2.603994724655395e-76)\n",
      "Epoch 250\n",
      "-----------------\n",
      "Train loss: 1.233233, Val loss: 1.732267\n",
      "PearsonRResult(statistic=0.8669082748162218, pvalue=4.891371243931874e-76)\n",
      "Epoch 251\n",
      "-----------------\n",
      "Train loss: 1.228583, Val loss: 1.725378\n",
      "PearsonRResult(statistic=0.8674946179872963, pvalue=2.957660277616157e-76)\n",
      "Epoch 252\n",
      "-----------------\n",
      "Train loss: 1.228708, Val loss: 1.723174\n",
      "PearsonRResult(statistic=0.8679895783534863, pvalue=1.9306451585870306e-76)\n",
      "Epoch 253\n",
      "-----------------\n",
      "Train loss: 1.225700, Val loss: 1.718803\n",
      "PearsonRResult(statistic=0.8682854066556932, pvalue=1.494948182044995e-76)\n",
      "Epoch 254\n",
      "-----------------\n",
      "Train loss: 1.219479, Val loss: 1.716227\n",
      "PearsonRResult(statistic=0.8684574000868961, pvalue=1.288020901543819e-76)\n",
      "Epoch 255\n",
      "-----------------\n",
      "Train loss: 1.220989, Val loss: 1.717258\n",
      "PearsonRResult(statistic=0.8685731801913643, pvalue=1.1649719169024173e-76)\n",
      "Epoch 256\n",
      "-----------------\n",
      "Train loss: 1.217242, Val loss: 1.712415\n",
      "PearsonRResult(statistic=0.868940732091468, pvalue=8.464578937500699e-77)\n",
      "Epoch 257\n",
      "-----------------\n",
      "Train loss: 1.213197, Val loss: 1.712892\n",
      "PearsonRResult(statistic=0.8687598487599344, pvalue=9.90652085188119e-77)\n",
      "loss improved from 5.124357581138611 to 5.118334889411926\n",
      "Epoch 258\n",
      "-----------------\n",
      "Train loss: 1.213284, Val loss: 1.706112\n",
      "PearsonRResult(statistic=0.8691394003809471, pvalue=7.119593849732654e-77)\n",
      "Epoch 259\n",
      "-----------------\n",
      "Train loss: 1.210391, Val loss: 1.707883\n",
      "PearsonRResult(statistic=0.8692462662927702, pvalue=6.486048277791211e-77)\n",
      "loss improved from 5.118334889411926 to 5.087550640106201\n",
      "Epoch 260\n",
      "-----------------\n",
      "Train loss: 1.206179, Val loss: 1.695850\n",
      "PearsonRResult(statistic=0.8698515938902265, pvalue=3.819786600622374e-77)\n",
      "loss improved from 5.087550640106201 to 5.066404700279236\n",
      "Epoch 261\n",
      "-----------------\n",
      "Train loss: 1.206667, Val loss: 1.688802\n",
      "PearsonRResult(statistic=0.8704007378782557, pvalue=2.3574369723185567e-77)\n",
      "Epoch 262\n",
      "-----------------\n",
      "Train loss: 1.206708, Val loss: 1.692394\n",
      "PearsonRResult(statistic=0.8701630718615303, pvalue=2.9058320966310433e-77)\n",
      "loss improved from 5.066404700279236 to 5.063549637794495\n",
      "Epoch 263\n",
      "-----------------\n",
      "Train loss: 1.202989, Val loss: 1.687850\n",
      "PearsonRResult(statistic=0.870311602082659, pvalue=2.5499211358126263e-77)\n",
      "Epoch 264\n",
      "-----------------\n",
      "Train loss: 1.198603, Val loss: 1.702104\n",
      "PearsonRResult(statistic=0.869312698491276, pvalue=6.120702216718861e-77)\n",
      "Epoch 265\n",
      "-----------------\n",
      "Train loss: 1.196233, Val loss: 1.695704\n",
      "PearsonRResult(statistic=0.869163162971822, pvalue=6.973620597938179e-77)\n",
      "Epoch 266\n",
      "-----------------\n",
      "Train loss: 1.196069, Val loss: 1.701607\n",
      "PearsonRResult(statistic=0.8690936077464557, pvalue=7.409486057074351e-77)\n",
      "Epoch 267\n",
      "-----------------\n",
      "Train loss: 1.192243, Val loss: 1.692733\n",
      "PearsonRResult(statistic=0.8695282684288341, pvalue=5.069923442392924e-77)\n",
      "Epoch 268\n",
      "-----------------\n",
      "Train loss: 1.190253, Val loss: 1.699190\n",
      "PearsonRResult(statistic=0.8691682079523968, pvalue=6.943012979698531e-77)\n",
      "Epoch 269\n",
      "-----------------\n",
      "Train loss: 1.186131, Val loss: 1.706213\n",
      "PearsonRResult(statistic=0.8686612102740641, pvalue=1.0792747605978613e-76)\n",
      "Epoch 270\n",
      "-----------------\n",
      "Train loss: 1.185634, Val loss: 1.701715\n",
      "PearsonRResult(statistic=0.8687349357647141, pvalue=1.0123304634627136e-76)\n",
      "Epoch 271\n",
      "-----------------\n",
      "Train loss: 1.181546, Val loss: 1.695440\n",
      "PearsonRResult(statistic=0.8692592198524638, pvalue=6.4131536071651276e-77)\n",
      "Epoch 272\n",
      "-----------------\n",
      "Train loss: 1.179757, Val loss: 1.709656\n",
      "PearsonRResult(statistic=0.8682768016900364, pvalue=1.5061245799726556e-76)\n",
      "Epoch 273\n",
      "-----------------\n",
      "Train loss: 1.178061, Val loss: 1.698104\n",
      "PearsonRResult(statistic=0.8690656394737648, pvalue=7.592260042393678e-77)\n",
      "Epoch 274\n",
      "-----------------\n",
      "Train loss: 1.172736, Val loss: 1.698667\n",
      "PearsonRResult(statistic=0.8691667822017961, pvalue=6.951649415171472e-77)\n",
      "Epoch 275\n",
      "-----------------\n",
      "Train loss: 1.173625, Val loss: 1.702887\n",
      "PearsonRResult(statistic=0.8690532157861347, pvalue=7.674875244612858e-77)\n",
      "Epoch 276\n",
      "-----------------\n",
      "Train loss: 1.169739, Val loss: 1.698077\n",
      "PearsonRResult(statistic=0.8693226128670057, pvalue=6.0679549902234875e-77)\n",
      "Epoch 277\n",
      "-----------------\n",
      "Train loss: 1.168277, Val loss: 1.697401\n",
      "PearsonRResult(statistic=0.869304940918267, pvalue=6.162291157049801e-77)\n",
      "Epoch 278\n",
      "-----------------\n",
      "Train loss: 1.164517, Val loss: 1.714272\n",
      "PearsonRResult(statistic=0.8685026175280948, pvalue=1.2385031971258281e-76)\n",
      "Epoch 279\n",
      "-----------------\n",
      "Train loss: 1.162187, Val loss: 1.695358\n",
      "PearsonRResult(statistic=0.8696417284605957, pvalue=4.590811347043997e-77)\n",
      "Epoch 280\n",
      "-----------------\n",
      "Train loss: 1.160302, Val loss: 1.707971\n",
      "PearsonRResult(statistic=0.8687163718540445, pvalue=1.028789010706284e-76)\n",
      "Epoch 281\n",
      "-----------------\n",
      "Train loss: 1.157399, Val loss: 1.708133\n",
      "PearsonRResult(statistic=0.8689172368725588, pvalue=8.639423298345538e-77)\n",
      "Epoch 282\n",
      "-----------------\n",
      "Train loss: 1.156549, Val loss: 1.711167\n",
      "PearsonRResult(statistic=0.8689918060136907, pvalue=8.096501493787803e-77)\n",
      "Epoch 283\n",
      "-----------------\n",
      "Train loss: 1.153069, Val loss: 1.701171\n",
      "PearsonRResult(statistic=0.8697381357637741, pvalue=4.2191530705637915e-77)\n",
      "Epoch 284\n",
      "-----------------\n",
      "Train loss: 1.150723, Val loss: 1.703639\n",
      "PearsonRResult(statistic=0.8693789973145467, pvalue=5.776424560368617e-77)\n",
      "Epoch 285\n",
      "-----------------\n",
      "Train loss: 1.149245, Val loss: 1.716442\n",
      "PearsonRResult(statistic=0.8685287486140659, pvalue=1.2107516808122366e-76)\n",
      "Epoch 286\n",
      "-----------------\n",
      "Train loss: 1.145864, Val loss: 1.706272\n",
      "PearsonRResult(statistic=0.8691379024021901, pvalue=7.128896660444544e-77)\n",
      "Epoch 287\n",
      "-----------------\n",
      "Train loss: 1.141558, Val loss: 1.721713\n",
      "PearsonRResult(statistic=0.8680973465028672, pvalue=1.7590139889242946e-76)\n",
      "Epoch 288\n",
      "-----------------\n",
      "Train loss: 1.141974, Val loss: 1.732104\n",
      "PearsonRResult(statistic=0.8676033240661234, pvalue=2.6935660942728664e-76)\n",
      "Epoch 289\n",
      "-----------------\n",
      "Train loss: 1.139434, Val loss: 1.727950\n",
      "PearsonRResult(statistic=0.8678500221396919, pvalue=2.1777556699030072e-76)\n",
      "Epoch 290\n",
      "-----------------\n",
      "Train loss: 1.134989, Val loss: 1.716263\n",
      "PearsonRResult(statistic=0.8685349078458908, pvalue=1.2043007333361906e-76)\n",
      "Epoch 291\n",
      "-----------------\n",
      "Train loss: 1.134424, Val loss: 1.736709\n",
      "PearsonRResult(statistic=0.8673484849555392, pvalue=3.3534956083482604e-76)\n",
      "Epoch 292\n",
      "-----------------\n",
      "Train loss: 1.131496, Val loss: 1.738753\n",
      "PearsonRResult(statistic=0.8674177170853886, pvalue=3.159820665465011e-76)\n",
      "Epoch 293\n",
      "-----------------\n",
      "Train loss: 1.127476, Val loss: 1.732200\n",
      "PearsonRResult(statistic=0.8679356208561195, pvalue=2.022708051915282e-76)\n",
      "Epoch 294\n",
      "-----------------\n",
      "Train loss: 1.129061, Val loss: 1.730354\n",
      "PearsonRResult(statistic=0.8681875396377475, pvalue=1.627056406944077e-76)\n",
      "Epoch 295\n",
      "-----------------\n",
      "Train loss: 1.119344, Val loss: 1.760168\n",
      "PearsonRResult(statistic=0.8668022164877693, pvalue=5.3559786988638485e-76)\n",
      "Epoch 296\n",
      "-----------------\n",
      "Train loss: 1.123764, Val loss: 1.737643\n",
      "PearsonRResult(statistic=0.868246215414759, pvalue=1.546525071764836e-76)\n",
      "Epoch 297\n",
      "-----------------\n",
      "Train loss: 1.119745, Val loss: 1.741232\n",
      "PearsonRResult(statistic=0.868104181071736, pvalue=1.7486538639001e-76)\n",
      "Epoch 298\n",
      "-----------------\n",
      "Train loss: 1.112496, Val loss: 1.740072\n",
      "PearsonRResult(statistic=0.8684321519540248, pvalue=1.3165182164153522e-76)\n",
      "Epoch 299\n",
      "-----------------\n",
      "Train loss: 1.128605, Val loss: 1.753141\n",
      "PearsonRResult(statistic=0.8675817137676033, pvalue=2.7441365279634574e-76)\n",
      "Epoch 300\n",
      "-----------------\n",
      "Train loss: 1.112546, Val loss: 1.742993\n",
      "PearsonRResult(statistic=0.868187934897829, pvalue=1.626500262900076e-76)\n",
      "loading best model\n"
     ]
    }
   ],
   "source": [
    "hps = {'out_channels': 16,\n",
    " 'lr': 0.0001,\n",
    " 'linear_neurons2': 64,\n",
    " 'linear_neurons': 96,\n",
    " 'drop_p': 0}\n",
    "adphos = models.CnnDualInputs(hps).to(device)\n",
    "hist = traning.tl_multi_dls(\n",
    "    train_dls=train_dls[: 2],\n",
    "    y_train=train_dls[-1],\n",
    "    val_dls=val_dls[: 2],\n",
    "    model=adphos,\n",
    "    optimiser=torch.optim.RMSprop(adphos.parameters(), lr=hps['lr']), \n",
    "    epochs=300,\n",
    "    y_val=val_dls[-1],\n",
    "    early_stopping_dict={'patience': 50, 'delta': 0.0}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMetric(mean=1.6878498792648315, sd=0.0, index=262)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.plot_cv(hist['train_loss'], hist['val_loss'], epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCC': 0.8803749550435813,\n",
       " 'Rho': 0.8667655394598536,\n",
       " 'MSE': 1.6627933,\n",
       " 'R2': 0.7272763759312784}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model.find_metrics(eval_model.eval_torch(test_dls, adphos), y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function find_metrics in module src.eval_model:\n",
      "\n",
      "find_metrics(pred, true, m_list=['PCC', 'Rho', 'MSE', 'R2'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(eval_model.find_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCC': 0.8673017493034486,\n",
       " 'Rho': 0.849784246089046,\n",
       " 'MSE': 1.53767286989591,\n",
       " 'R2': 0.7477980414127396}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = models.MeanModel(y_train, _all_drugs)\n",
    "pred = mm.predict(y_test.index)\n",
    "eval_model.find_metrics(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.71244221,  1.15703557,  5.76956948, ..., -2.94816927,\n",
       "        4.05858427,  4.84269009])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
